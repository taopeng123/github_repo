1
00:00:00,630 --> 00:00:03,360
The core Hadoop project consists of a way to store

2
00:00:03,360 --> 00:00:07,990
data, known as the Hadoop distributed file system, or HDFS. And

3
00:00:07,990 --> 00:00:11,670
a way to process data with MapReduce. The key concept is

4
00:00:11,670 --> 00:00:13,790
that we split the data up and store it across the

5
00:00:13,790 --> 00:00:16,820
collection of machines known as a cluster. Then when we want

6
00:00:16,820 --> 00:00:20,680
to process the data, we process it where it's actually stored.

7
00:00:20,680 --> 00:00:23,400
Rather than retrieving the data from a central server, the data's

8
00:00:23,400 --> 00:00:26,840
already on the cluster, so we can process it in place.

9
00:00:26,840 --> 00:00:28,800
You can add more machines to the cluster

10
00:00:28,800 --> 00:00:31,090
as the amount of data you're storing grows.

11
00:00:31,090 --> 00:00:32,659
And, indeed, many people start with just a

12
00:00:32,659 --> 00:00:35,510
few machines, and add more as they're needed.

13
00:00:35,510 --> 00:00:37,400
The machines in your cluster don't need to

14
00:00:37,400 --> 00:00:40,580
be anything particularly high end. Although most clusters

15
00:00:40,580 --> 00:00:43,385
are built using rack-mounted servers, they are typically

16
00:00:43,385 --> 00:00:46,350
mid-range servers, rather than top of the range equipment.

