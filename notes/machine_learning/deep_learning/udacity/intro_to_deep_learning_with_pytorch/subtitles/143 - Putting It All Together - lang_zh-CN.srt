1
00:00:00,000 --> 00:00:02,370
就是这样 正如我们之前看到的

2
00:00:02,370 --> 00:00:05,878
这就是 LSTM 的结构 里面有四个门

3
00:00:05,878 --> 00:00:07,003
这是遗忘门

4
00:00:07,003 --> 00:00:09,993
会接受长期记忆并遗忘掉一部分

5
00:00:09,993 --> 00:00:12,599
学习门会把短期记忆和

6
00:00:12,599 --> 00:00:16,035
事件放到一起 作为我们最近学到的信息

7
00:00:16,035 --> 00:00:20,070
记忆门则把还没有遗忘的长期记忆

8
00:00:20,070 --> 00:00:24,760
和刚学到的新信息放到一起 以便更新长期记忆并将其输出

9
00:00:24,760 --> 00:00:27,629
最后 使用门也会把我们刚学到的信息

10
00:00:27,629 --> 00:00:30,719
和还没遗忘的长期记忆放到一起

11
00:00:30,719 --> 00:00:34,875
从而作出预测并更新短期记忆

12
00:00:34,875 --> 00:00:36,734
这就是把所有东西放到一起的样子

13
00:00:36,734 --> 00:00:38,993
并不复杂 对吗？

14
00:00:38,993 --> 00:00:40,695
你可能在想 等等

15
00:00:40,695 --> 00:00:42,350
看着太抽象了

16
00:00:42,350 --> 00:00:45,520
为什么有时候要用 tanh 有时候却要用 sigmoid？

17
00:00:45,520 --> 00:00:47,574
为什么有时候要相乘 有时候又要相加？

18
00:00:47,573 --> 00:00:50,369
有时候又要用更复杂的线性函数？

19
00:00:50,369 --> 00:00:52,169
你可能会想到别的结构

20
00:00:52,170 --> 00:00:54,329
一些更合理或更简单的结构

21
00:00:54,329 --> 00:00:55,908
你是对的

22
00:00:55,908 --> 00:00:57,613
这是个任意结构

23
00:00:57,613 --> 00:00:59,339
就像深度学习的很多事情一样

24
00:00:59,340 --> 00:01:03,170
之所以结构是这样 是因为这样行得通

25
00:01:03,170 --> 00:01:04,349
在下一节课中

26
00:01:04,349 --> 00:01:06,689
我们会看到其它结构 可能更简单

27
00:01:06,688 --> 00:01:09,818
也可能更复杂 但都行得通

28
00:01:09,819 --> 00:01:12,180
不过欢迎你寻找其它结构并动手实验

29
00:01:12,180 --> 00:01:14,819
这个领域还处于早期探索阶段 如果你

30
00:01:14,819 --> 00:01:18,000
想到了其它结构 而且该结构行得通 那就太棒了

