1
00:00:00,000 --> 00:00:02,205
Hello everyone and welcome back.

2
00:00:02,205 --> 00:00:05,100
So, in this notebook and series of videos,

3
00:00:05,100 --> 00:00:11,280
I'm going to be showing you a more powerful way to build neural networks and PyTorch.

4
00:00:11,280 --> 00:00:14,820
So, in the last notebook, you saw how you can calculate the output for

5
00:00:14,820 --> 00:00:18,465
network using tensors and matrix multiplication.

6
00:00:18,465 --> 00:00:21,510
But PyTorch has this nice module, nn,

7
00:00:21,510 --> 00:00:26,160
that has a lot of my classes and methods and

8
00:00:26,160 --> 00:00:31,050
functions that allow us to build large neural networks in a very efficient way.

9
00:00:31,050 --> 00:00:32,580
So, to show you how this works,

10
00:00:32,580 --> 00:00:35,145
we're going to be using a dataset called MNIST.

11
00:00:35,145 --> 00:00:39,920
So, MNIST it's a whole bunch of grayscale handwritten digits.

12
00:00:39,920 --> 00:00:41,270
So ,0, 1, 2, 3,

13
00:00:41,270 --> 00:00:43,350
4 and so on through nine.

14
00:00:43,350 --> 00:00:47,570
Each of these images is 28 by 28 pixels and the goal is

15
00:00:47,570 --> 00:00:51,970
to actually identify what the number is in these images.

16
00:00:51,970 --> 00:00:55,700
So, that dataset consists of each of these images and

17
00:00:55,700 --> 00:00:59,620
it's labeled with the digit that is in that image.

18
00:00:59,620 --> 00:01:01,380
So, ones are labeled one,

19
00:01:01,380 --> 00:01:03,120
twos are labeled two and so on.

20
00:01:03,120 --> 00:01:05,435
So, what we can do is we can actually show

21
00:01:05,435 --> 00:01:09,290
our network and image and the correct label and

22
00:01:09,290 --> 00:01:15,680
then it learns how to actually determine what the number and the image is.

23
00:01:15,680 --> 00:01:19,010
This dataset is available through the torchvision package.

24
00:01:19,010 --> 00:01:23,575
So, this is a package that sits alongside PyTorch,

25
00:01:23,575 --> 00:01:26,420
that provides a lot of nice utilities like

26
00:01:26,420 --> 00:01:29,990
datasets and models for doing computer vision problems.

27
00:01:29,990 --> 00:01:35,300
We can run this cell to download and load the MNIST dataset.

28
00:01:35,300 --> 00:01:38,930
What it does is it gives us back an object which I'm calling trainloader.

29
00:01:38,930 --> 00:01:43,625
So, with this trainloader we can turn into an iterator with iter and then

30
00:01:43,625 --> 00:01:45,650
this will allow us to start getting good at

31
00:01:45,650 --> 00:01:48,260
it or we can actually just use this in a loop,

32
00:01:48,260 --> 00:01:51,890
in a for loop and so we can get our images and labels out

33
00:01:51,890 --> 00:01:55,669
of this generator with four image,

34
00:01:55,669 --> 00:01:57,635
comma label and trainloader.

35
00:01:57,635 --> 00:02:00,500
One thing to notice is that when I created the trainloader,

36
00:02:00,500 --> 00:02:03,170
I set the batch size to 64.

37
00:02:03,170 --> 00:02:07,580
So, what that means and every time we get a set of images and labels out,

38
00:02:07,580 --> 00:02:12,205
we're actually getting 64 images out from our data loader.

39
00:02:12,205 --> 00:02:16,520
So, then if you look at the shape and the size of these images,

40
00:02:16,520 --> 00:02:20,620
we'll see that they are 64 by one by 28 by 28.

41
00:02:20,620 --> 00:02:25,325
So, 64 images and then one color channels so it's grayscale,

42
00:02:25,325 --> 00:02:31,090
and then it's 28 by 28 pixels is the shape of these images and so we can see that here.

43
00:02:31,090 --> 00:02:37,085
Then our labels have a shape of 64 so it's just a vector that's 64 elements which with

44
00:02:37,085 --> 00:02:39,980
a label for each of our images and we can see what

45
00:02:39,980 --> 00:02:42,980
one of these images looks like this is a nice number four.

46
00:02:42,980 --> 00:02:44,825
So, we're going to do here is build

47
00:02:44,825 --> 00:02:48,215
a multi-layer neural network using the methods that we saw before.

48
00:02:48,215 --> 00:02:52,850
By that I mean you're going to initialize some weight matrices and

49
00:02:52,850 --> 00:02:59,575
some bias vectors and use those to calculate the output of this multi-layer network.

50
00:02:59,575 --> 00:03:05,310
Specifically, we want to build this network with 784 input units,

51
00:03:05,310 --> 00:03:08,280
256 hidden units, and 10 output units.

52
00:03:08,280 --> 00:03:09,720
So, 10 output units,

53
00:03:09,720 --> 00:03:12,065
one for each of our classes.

54
00:03:12,065 --> 00:03:14,320
So, the 784 input units,

55
00:03:14,320 --> 00:03:17,740
this comes from the fact that with this type of network is

56
00:03:17,740 --> 00:03:21,825
called a fully connected network or a dense network.

57
00:03:21,825 --> 00:03:25,945
We want to think of our inputs as just one vector.

58
00:03:25,945 --> 00:03:29,920
So, our images are actually this 28 by 28 image,

59
00:03:29,920 --> 00:03:34,300
but we want to put a vector into our network and so what we need to do is

60
00:03:34,300 --> 00:03:39,100
actually convert this 28 by 28 image into a vector and so,

61
00:03:39,100 --> 00:03:41,935
784 is 28 times 28.

62
00:03:41,935 --> 00:03:46,295
When we actually take this 28 by 28 image and flatten it into

63
00:03:46,295 --> 00:03:50,610
a vector then it's going to be 784 elements long.

64
00:03:50,610 --> 00:03:53,570
So, now what we need to do is take each of our batches

65
00:03:53,570 --> 00:03:56,540
which is 64 by one by 28 by 28 and then

66
00:03:56,540 --> 00:04:03,090
convert it into a shape that is to another tensor which shapes 64 by 784.

67
00:04:03,090 --> 00:04:07,010
This is going to be the tensor that's the input to our network.

68
00:04:07,010 --> 00:04:09,155
So, go and give this a shot.

69
00:04:09,155 --> 00:04:12,380
So again, build the networks 784 input units,

70
00:04:12,380 --> 00:04:17,180
256 hidden units and 10 output units and you're going to be

71
00:04:17,180 --> 00:04:23,270
generating your own random initial weight and bias matrices. Cheers.

