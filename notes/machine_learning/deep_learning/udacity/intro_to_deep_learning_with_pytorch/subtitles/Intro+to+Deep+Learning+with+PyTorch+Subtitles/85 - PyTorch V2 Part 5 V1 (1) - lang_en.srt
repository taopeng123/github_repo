1
00:00:00,000 --> 00:00:01,695
Hey there. So now,

2
00:00:01,695 --> 00:00:04,785
we're going to start talking about inference and validation.

3
00:00:04,785 --> 00:00:06,915
So, when you have your trained network,

4
00:00:06,915 --> 00:00:09,555
you typically want to use it for making predictions.

5
00:00:09,555 --> 00:00:11,070
This is called inference,

6
00:00:11,070 --> 00:00:13,350
it's a term borrowed from statistics.

7
00:00:13,350 --> 00:00:16,620
However, neural networks have a tendency to perform too well on

8
00:00:16,620 --> 00:00:18,360
your training data and they aren't able to

9
00:00:18,360 --> 00:00:21,170
generalize the data that your network hasn't seen before.

10
00:00:21,170 --> 00:00:22,940
This is called overfitting.

11
00:00:22,940 --> 00:00:27,585
This happens because as you're training more and more and more on your training set,

12
00:00:27,585 --> 00:00:29,720
your network starts to pick up correlations and

13
00:00:29,720 --> 00:00:32,045
patterns that are in your training set but they aren't

14
00:00:32,045 --> 00:00:37,025
in the more general dataset of all possible handwritten digits.

15
00:00:37,025 --> 00:00:39,305
So, to test for overfitting,

16
00:00:39,305 --> 00:00:45,260
we measure the performance of the network on data that isn't in the training set.

17
00:00:45,260 --> 00:00:48,440
This data is usually called the validation set or the test set.

18
00:00:48,440 --> 00:00:52,370
So, while we measure the performance on the validation set,

19
00:00:52,370 --> 00:00:57,545
we also tried to reduce overfitting through regularization such as dropout.

20
00:00:57,545 --> 00:00:58,895
So, in this notebook,

21
00:00:58,895 --> 00:01:02,705
I'll show you how we can both look at

22
00:01:02,705 --> 00:01:06,985
our validation set and also use dropout to reduce overfitting.

23
00:01:06,985 --> 00:01:10,830
So, to get the training set for your data like from PyTorch,

24
00:01:10,830 --> 00:01:14,855
then we say train equals true and for fashionMNIST.

25
00:01:14,855 --> 00:01:16,070
To get our test set,

26
00:01:16,070 --> 00:01:18,395
we're actually going to set train equals false here.

27
00:01:18,395 --> 00:01:21,175
Here, I'm just defining the model like we did before.

28
00:01:21,175 --> 00:01:24,200
So, the goal of validation is to measure

29
00:01:24,200 --> 00:01:28,190
our model's performance on data that is not part of our training set.

30
00:01:28,190 --> 00:01:31,805
But what we mean by performance is up to you,

31
00:01:31,805 --> 00:01:34,105
up to the developer, the person who's writing the code.

32
00:01:34,105 --> 00:01:37,005
A lot of times, it'll just be the accuracy.

33
00:01:37,005 --> 00:01:40,970
So, like how many correct classifications did

34
00:01:40,970 --> 00:01:45,340
our model make compared to all of the predictions?

35
00:01:45,340 --> 00:01:48,500
And other options for metrics are precision and recall,

36
00:01:48,500 --> 00:01:50,615
and the top five error rate.

37
00:01:50,615 --> 00:01:55,475
So here, I'll show you how to actually measure the accuracy on the validation set.

38
00:01:55,475 --> 00:01:58,390
So first, I'm going to do a forward pass that is one batch from the test set.

39
00:01:58,390 --> 00:02:01,850
So, see in our test set we get our probabilities.

40
00:02:01,850 --> 00:02:05,210
So, just 64 examples in a batch.

41
00:02:05,210 --> 00:02:08,180
Then 10 columns like one for each of the classes.

42
00:02:08,180 --> 00:02:11,330
So, the accuracy, we want to see if our model made

43
00:02:11,330 --> 00:02:14,445
the correct prediction of the class given the image.

44
00:02:14,445 --> 00:02:19,220
The prediction we can consider it to be whichever class has the highest probability.

45
00:02:19,220 --> 00:02:24,780
So, for this, we can use this top-k method on our tensors.

46
00:02:24,780 --> 00:02:27,195
This returns the k highest values.

47
00:02:27,195 --> 00:02:29,265
So, if we pass in one,

48
00:02:29,265 --> 00:02:33,105
then this is going to give us the one highest value.

49
00:02:33,105 --> 00:02:38,560
This one highest value is the most likely class that our network is predicting.

50
00:02:38,560 --> 00:02:40,755
So, for the first ten examples,

51
00:02:40,755 --> 00:02:45,340
and this batch of test data that I grabbed,

52
00:02:45,340 --> 00:02:50,500
we see that the class four and class five are what are being predicted for these.

53
00:02:50,500 --> 00:02:53,090
So, remember that this network actually hasn't been trained yet,

54
00:02:53,090 --> 00:02:55,370
and so it's just making these guesses randomly because

55
00:02:55,370 --> 00:02:58,690
it doesn't really know anything about the data yet.

56
00:02:58,690 --> 00:03:01,670
So, top-k actually returns a tuple with two tensors.

57
00:03:01,670 --> 00:03:04,460
So, the first tensor is the actual probability values,

58
00:03:04,460 --> 00:03:07,760
and the second tensor are the class indices themselves.

59
00:03:07,760 --> 00:03:10,595
So typically, we just want this top class here.

60
00:03:10,595 --> 00:03:16,220
So, I'm calling top-k here and I'm separating out the probabilities in the classes.

61
00:03:16,220 --> 00:03:18,745
So, we'll just use this top class going forward.

62
00:03:18,745 --> 00:03:22,850
So, now that we have the predicted classes from our network,

63
00:03:22,850 --> 00:03:25,085
we can compare that with the true labels.

64
00:03:25,085 --> 00:03:28,590
So, we say, we can say like top class equals equals labels.

65
00:03:28,590 --> 00:03:31,310
The only trick here is that we need to make

66
00:03:31,310 --> 00:03:34,700
sure our top class tensor and the labels tensor has the same shape.

67
00:03:34,700 --> 00:03:39,520
So, this equality actually operates appropriately like we expect.

68
00:03:39,520 --> 00:03:47,480
So, labels from the test loader is actually a 1D tensor with 64 elements,

69
00:03:47,480 --> 00:03:52,240
but top class itself is a 2D tensor, 64 by one.

70
00:03:52,240 --> 00:03:57,845
So here, I'm just like changing the shape of labels to match the shape of top class.

71
00:03:57,845 --> 00:04:01,250
This gives us this equals tensor.

72
00:04:01,250 --> 00:04:03,015
We can actually see it looks like.

73
00:04:03,015 --> 00:04:04,520
So, it gives us a bunch of zeros and ones.

74
00:04:04,520 --> 00:04:05,990
So, zeros are where they don't match,

75
00:04:05,990 --> 00:04:07,745
and then ones are where they do match.

76
00:04:07,745 --> 00:04:10,985
Now, we have this tensor that's all just a bunch of zeros and ones.

77
00:04:10,985 --> 00:04:14,850
So, if we want to know the accuracy, right?

78
00:04:14,850 --> 00:04:17,355
We can just sum up all the correct things,

79
00:04:17,355 --> 00:04:18,600
all the correct predictions,

80
00:04:18,600 --> 00:04:20,960
and then divide by the total number of predictions.

81
00:04:20,960 --> 00:04:23,780
If you're tensor is all zeros and ones,

82
00:04:23,780 --> 00:04:25,955
that's actually equivalent to taking the mean.

83
00:04:25,955 --> 00:04:27,940
So for that, we can do torch.mean,

84
00:04:27,940 --> 00:04:32,650
but the problem is that equals is actually a byte tensor,

85
00:04:32,650 --> 00:04:36,100
and torch.mean won't work on byte tensors.

86
00:04:36,100 --> 00:04:39,335
So, we actually need to convert equals until a float tensor.

87
00:04:39,335 --> 00:04:42,050
If we do that, then we can actually see our accuracy for

88
00:04:42,050 --> 00:04:45,200
this one particular batch is 15.6 percent.

89
00:04:45,200 --> 00:04:47,180
So, this is roughly what we expect.

90
00:04:47,180 --> 00:04:49,010
So, our network hasn't been trained yet.

91
00:04:49,010 --> 00:04:51,590
It's making pretty much random guesses.

92
00:04:51,590 --> 00:04:56,060
That means that we should see our accuracy be about one in ten for

93
00:04:56,060 --> 00:05:01,910
any particular image because it's just uniformly guessing one of the classes, okay?

94
00:05:01,910 --> 00:05:05,105
So here, I'm going to have you actually implement this validation loop,

95
00:05:05,105 --> 00:05:07,970
where you'll pass in data from

96
00:05:07,970 --> 00:05:12,260
the test set through the network and calculate the loss and the accuracy.

97
00:05:12,260 --> 00:05:15,025
So, one thing to note, I think I mentioned this before.

98
00:05:15,025 --> 00:05:18,860
For the validation paths, we're not actually going to be doing any training.

99
00:05:18,860 --> 00:05:20,435
So, we don't need the gradients.

100
00:05:20,435 --> 00:05:24,695
So, you can actually speed up your code a little bit if you turn off the gradients.

101
00:05:24,695 --> 00:05:26,570
So, using this context,

102
00:05:26,570 --> 00:05:30,215
so with torch.no_grad, then you can put your validation pass in here.

103
00:05:30,215 --> 00:05:34,435
So, for images and labels in your test loader and then do the validation pass here.

104
00:05:34,435 --> 00:05:39,215
So, I've basically built a classifier for you, set all this up.

105
00:05:39,215 --> 00:05:43,460
Here's the training pass, and then it's up to you to implement the validation pass,

106
00:05:43,460 --> 00:05:45,590
and then print out the accuracy.

107
00:05:45,590 --> 00:05:47,070
All right. Good luck,

108
00:05:47,070 --> 00:05:49,680
and if you get stuck or want any help,

109
00:05:49,680 --> 00:05:51,600
be sure to check out my solution.

