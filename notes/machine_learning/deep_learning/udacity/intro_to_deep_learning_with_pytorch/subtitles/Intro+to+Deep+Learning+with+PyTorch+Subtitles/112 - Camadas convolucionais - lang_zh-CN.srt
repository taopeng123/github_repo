1
00:00:00,000 --> 00:00:02,819
看看这幅小狗图片

2
00:00:02,819 --> 00:00:05,009
图片中的单个区域

3
00:00:05,009 --> 00:00:08,734
可能具有很多需要我们检测的规律

4
00:00:08,734 --> 00:00:11,323
例如这个区域

5
00:00:11,323 --> 00:00:13,105
这个区域有牙齿

6
00:00:13,105 --> 00:00:15,685
几根胡须和舌头

7
00:00:15,685 --> 00:00:18,989
这样的话 要理解这幅图片

8
00:00:18,989 --> 00:00:23,135
我们就需要用于检测所有这三种特性的过滤器

9
00:00:23,135 --> 00:00:26,190
牙齿 胡须和舌头分别对应一个过滤器

10
00:00:26,190 --> 00:00:30,675
还记得之前的单个卷积过滤器吗

11
00:00:30,675 --> 00:00:35,219
添加另一个过滤器可能完全一样

12
00:00:35,219 --> 00:00:40,575
我们只需填充另一组卷积层中的节点

13
00:00:40,575 --> 00:00:43,079
这个集合具有自己的共享权重集

14
00:00:43,079 --> 00:00:47,158
与上方蓝色节点的权重不同

15
00:00:47,158 --> 00:00:51,268
实际上 在一个卷积层中拥有数十个或数百个

16
00:00:51,270 --> 00:00:55,960
这种节点集合是很常见的 每个都对应自己的过滤器

17
00:00:55,960 --> 00:01:00,478
我们现在运行一些代码 看看这些集合的代码如何

18
00:01:00,478 --> 00:01:04,078
毕竟 每个的形成方式都和图片的一样

19
00:01:04,078 --> 00:01:06,703
即值矩阵

20
00:01:06,703 --> 00:01:10,454
我们将可视化 Jupyter notebook 的输出

21
00:01:10,453 --> 00:01:14,518
如果你愿意的话 可以点击下面的链接跟着操作

22
00:01:14,519 --> 00:01:20,855
假设我们要处理的输入图片是优达学城的无人驾驶汽车

23
00:01:20,855 --> 00:01:22,469
我们使用四个过滤器

24
00:01:22,468 --> 00:01:26,503
每个都高 4 个像素 宽 4 个像素

25
00:01:26,504 --> 00:01:31,230
每个过滤器将在图片的宽和高上卷积

26
00:01:31,230 --> 00:01:36,564
以在卷积层中形成整个节点集合

27
00:01:36,563 --> 00:01:39,298
这里 因为我们有四个过滤器

28
00:01:39,299 --> 00:01:41,730
因此将有四组节点

29
00:01:41,730 --> 00:01:44,099
在实际操作中

30
00:01:44,099 --> 00:01:48,750
我们将这四个集合分别称为特征映射或激活映射

31
00:01:48,750 --> 00:01:51,075
当我们可视化这些特征映射时

32
00:01:51,075 --> 00:01:54,394
我们看到它们看起来像过滤后的图片

33
00:01:54,394 --> 00:01:58,530
即我们从原始图片中提取出

34
00:01:58,530 --> 00:02:01,140
所有复杂的密集信息

35
00:02:01,140 --> 00:02:06,165
并在每个集合中输出信息更少的更简单图片

36
00:02:06,165 --> 00:02:08,772
通过观察这些过滤器的结构

37
00:02:08,771 --> 00:02:12,519
可以发现前两个过滤器发现了垂直边缘

38
00:02:12,519 --> 00:02:16,979
后两个过滤器检测到图片中的水平边缘

39
00:02:16,979 --> 00:02:19,485
特征映射中浅色的值

40
00:02:19,485 --> 00:02:23,715
表示在图片中发现了过滤器中的规律

41
00:02:23,715 --> 00:02:27,150
你能将每个特征映射中的浅色区域

42
00:02:27,150 --> 00:02:31,319
与原始图片的相应区域进行匹配吗？

43
00:02:31,318 --> 00:02:33,810
例如在这个激活映射中

44
00:02:33,810 --> 00:02:39,319
我们可以看到一条清晰的白色线条 表示汽车的右侧边缘

45
00:02:39,318 --> 00:02:40,378
这是因为

46
00:02:40,377 --> 00:02:44,803
汽车图片中的所有对应区域与过滤器很相似

47
00:02:44,805 --> 00:02:48,090
垂直浅色像素的左侧是

48
00:02:48,090 --> 00:02:51,699
垂直深色像素线条

49
00:02:51,699 --> 00:02:55,530
如果思考下 会发现图片中的边缘

50
00:02:55,530 --> 00:03:00,544
显示为在深色像素旁边的浅色像素线条

51
00:03:00,544 --> 00:03:03,960
例如这个图片包含很多可以被之前定义的

52
00:03:03,960 --> 00:03:09,150
四个过滤器之一发现或检测到的区域

53
00:03:09,150 --> 00:03:12,150
在 CNN 中 充当边缘检测器的函数非常重要

54
00:03:12,150 --> 00:03:16,550
稍后我们会继续讲解

55
00:03:16,550 --> 00:03:23,530
现在我们知道什么是具有灰度图片输入的卷积层了

56
00:03:23,530 --> 00:03:26,063
那么彩色图片呢？

57
00:03:26,063 --> 00:03:29,608
我们知道灰度图片被计算机解读为

58
00:03:29,610 --> 00:03:34,485
具有宽和高的二维数组

59
00:03:34,485 --> 00:03:42,960
彩色图片则被计算机解读为具有宽度 高度和深度的三维数组

60
00:03:42,960 --> 00:03:45,224
对于 RGB 图片

61
00:03:45,223 --> 00:03:47,829
深度是 3

62
00:03:47,830 --> 00:03:55,395
这些三维矩阵可以理解为三个二维矩阵堆叠到了一起

63
00:03:55,395 --> 00:03:58,469
这些矩阵对应的是图片的红色

64
00:03:58,467 --> 00:04:02,007
绿色和蓝色通道

65
00:04:02,008 --> 00:04:05,473
那么如何对彩色图片进行卷积处理呢？

66
00:04:05,473 --> 00:04:08,688
和灰度图片一样

67
00:04:08,687 --> 00:04:13,530
依然在图片上水平及垂直地移动过滤器

68
00:04:13,530 --> 00:04:18,540
但是现在过滤器本身是三维的

69
00:04:18,540 --> 00:04:24,310
对于图片数组中每个水平和垂直位置的颜色通道都有一个值

70
00:04:24,310 --> 00:04:30,610
就像我们将彩色图片看做三个二维矩阵的堆叠一样

71
00:04:30,610 --> 00:04:35,189
也可以将过滤器看做三个二维矩阵的堆叠

72
00:04:35,189 --> 00:04:38,610
彩色图片和过滤器都拥有红色

73
00:04:38,610 --> 00:04:41,125
绿色和蓝色通道

74
00:04:41,125 --> 00:04:46,694
要从特征映射中获取对应于该过滤器的节点值

75
00:04:46,694 --> 00:04:50,278
流程和之前的差不多

76
00:04:50,278 --> 00:04:54,509
只是现在求和的项是之前的三倍

77
00:04:54,509 --> 00:04:59,220
这里计算的是彩色图片上一个过滤器的

78
00:04:59,220 --> 00:05:05,220
卷积层中一个节点的值

79
00:05:05,220 --> 00:05:10,004
如果要表示具有多个过滤器的彩色图片

80
00:05:10,004 --> 00:05:12,990
而不是对应一个过滤器的

81
00:05:12,990 --> 00:05:15,165
一个三维数组

82
00:05:15,165 --> 00:05:20,675
我们需要定义多个三维数组 每个定义一个过滤器

83
00:05:20,675 --> 00:05:23,129
这里我们描绘了三个过滤器

84
00:05:23,129 --> 00:05:29,329
每个都是一个三维数组 可以看做三个二维数组的堆叠

85
00:05:29,329 --> 00:05:32,459
现在到了精彩的部分了

86
00:05:32,459 --> 00:05:36,660
你可以将沿着相同线条的卷积层中的每个特征映射

87
00:05:36,660 --> 00:05:42,264
看做一个图片通道 将它们堆叠就能获得三维数组

88
00:05:42,264 --> 00:05:45,750
然后可以将此三维数组当做输入

89
00:05:45,750 --> 00:05:49,620
依然形成另一个卷积层

90
00:05:49,620 --> 00:05:55,329
以便从我们在第一个卷积层中发现的规律中发现规律

91
00:05:55,329 --> 00:06:01,824
然后可以继续这么做 从规律中发现规律 然后继续从规律中发现规律

92
00:06:01,824 --> 00:06:05,040
注意 从某种程度上来说

93
00:06:05,040 --> 00:06:10,095
卷积层和你在上一部分见到的密集层区别不大

94
00:06:10,095 --> 00:06:13,319
密集层是完全连接的

95
00:06:13,319 --> 00:06:17,415
意味着节点与前一层级中的每个节点相连

96
00:06:17,415 --> 00:06:20,759
卷积层是局部相连的

97
00:06:20,759 --> 00:06:25,845
节点仅与上一层级中的一小部分节点相连

98
00:06:25,845 --> 00:06:30,420
卷积层还具有参数共享特性

99
00:06:30,420 --> 00:06:31,980
但是对于卷积层

100
00:06:31,980 --> 00:06:34,410
和密集层来说

101
00:06:34,410 --> 00:06:36,824
推理的工作原理是一样的

102
00:06:36,824 --> 00:06:42,160
二者的权重和偏差一开始都是随机生成的

103
00:06:42,160 --> 00:06:46,903
对于 CNN 来说 权重是卷积过滤器形式

104
00:06:46,903 --> 00:06:49,588
这些过滤器是随机生成的

105
00:06:49,588 --> 00:06:53,264
一开始检测的规律也是随机的

106
00:06:53,264 --> 00:06:59,410
和 MLP 一样 当我们构建 CNN 时 始终会指定损失函数

107
00:06:59,410 --> 00:07:02,338
对于多类别分类

108
00:07:02,338 --> 00:07:05,593
将是分类交叉熵损失

109
00:07:05,595 --> 00:07:09,285
然后通过反向传播训练模型

110
00:07:09,285 --> 00:07:15,634
在每个 epoch 都会更新过滤器 以便设定可以最小化损失函数的值

111
00:07:15,634 --> 00:07:19,079
换句话说 CNN 根据损失函数

112
00:07:19,079 --> 00:07:22,783
确定它需要检测什么样的规律

113
00:07:22,783 --> 00:07:27,223
稍后我们将可视化这些规律

114
00:07:27,225 --> 00:07:29,199
例如查看我们的数据集是否包含狗狗

115
00:07:29,199 --> 00:07:31,060
CNN 能够自己学习

116
00:07:31,060 --> 00:07:35,069
看起来像狗狗的过滤器

117
00:07:35,069 --> 00:07:37,963
强调下 对于 CNN

118
00:07:37,963 --> 00:07:41,084
我们不会指定过滤器值

119
00:07:41,084 --> 00:07:44,903
或者告诉 CNN 它需要检测什么样的规律

120
00:07:44,903 --> 00:07:47,759
而是从数据中学习

