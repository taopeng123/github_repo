1
00:00:00,400 --> 00:00:02,502
Certo. Nós temos
os minilotes de dados.

2
00:00:02,535 --> 00:00:04,637
Agora é hora
de definir o modelo.

3
00:00:04,804 --> 00:00:08,274
Este é um pequeno diagrama
de como o modelo vai ficar.

4
00:00:08,307 --> 00:00:10,843
Os caracteres vão ficar
na camada de input

5
00:00:10,877 --> 00:00:12,945
e uma pilha de células LSTM.

6
00:00:12,979 --> 00:00:16,616
Estas células formam a camada
recorrente oculta.

7
00:00:16,649 --> 00:00:19,051
E quando olham um minilote
de dados como input,

8
00:00:19,085 --> 00:00:20,753
elas olham um caractere
por vez

9
00:00:20,786 --> 00:00:23,289
e produzem um output
e um estado oculto.

10
00:00:23,322 --> 00:00:25,224
Vamos passar
um caractere de input

11
00:00:25,258 --> 00:00:27,026
para a primeira célula LSTM,

12
00:00:27,059 --> 00:00:28,861
que produz um estado oculto.

13
00:00:28,895 --> 00:00:30,363
No próximo instante de tempo,

14
00:00:30,396 --> 00:00:32,665
vamos ver o próximo caractere
na sequência

15
00:00:32,698 --> 00:00:34,934
e passá-lo
para esta célula LSTM,

16
00:00:34,967 --> 00:00:37,637
que verá o estado anterior
como input.

17
00:00:37,670 --> 00:00:41,407
Você já viu este comportamento
em uma RNN de uma camada,

18
00:00:41,440 --> 00:00:43,943
mas, aqui, vamos usar
um modelo de duas camadas

19
00:00:43,976 --> 00:00:46,445
que tem camadas
LSTM empilhadas.

20
00:00:46,479 --> 00:00:48,915
Isto significa que o output
desta camada LSTM

21
00:00:48,948 --> 00:00:51,117
vai para a próxima como input.

22
00:00:51,150 --> 00:00:53,753
E cada célula compartilha
seu estado oculto

23
00:00:53,786 --> 00:00:56,422
com a célula na sequência.

24
00:00:56,455 --> 00:00:59,292
O output da última camada LSTM

25
00:00:59,325 --> 00:01:01,627
vai incluir algumas
pontuações de classe.

26
00:01:01,661 --> 00:01:03,830
Elas serão o comprimento
do vocabulário.

27
00:01:03,863 --> 00:01:06,933
Vamos usar uma função
de ativação softmax

28
00:01:06,966 --> 00:01:09,535
para obter
a distribuição de probabilidade

29
00:01:09,569 --> 00:01:12,071
para prever qual deve
ser o próximo caractere.

30
00:01:12,104 --> 00:01:14,440
Para começar nesta tarefa,

31
00:01:14,474 --> 00:01:17,376
você recebeu um código esqueleto
para criar um modelo.

32
00:01:17,410 --> 00:01:20,947
Primeiro vamos ver se uma GPU
está disponível para treino.

33
00:01:20,980 --> 00:01:23,649
E você verá
esta classe CharRNN.

34
00:01:23,683 --> 00:01:28,521
Veja que a classe CharRNN tem
a função init e a função forward.

35
00:01:28,554 --> 00:01:30,323
Depois, você recebeu um código

36
00:01:30,356 --> 00:01:33,459
para inicializar o estado oculto
de uma camada LSTM.

37
00:01:33,493 --> 00:01:35,361
E vou falar disto em breve.

38
00:01:35,394 --> 00:01:37,797
Você pode dar uma olhada
no código

39
00:01:37,830 --> 00:01:40,599
e em como criamos os dicionários
de caracteres iniciais.

40
00:01:40,632 --> 00:01:42,001
Mas não precisa mudá-lo.

41
00:01:42,034 --> 00:01:44,637
Também há vários parâmetros
que vamos passar

42
00:01:44,670 --> 00:01:47,106
quando CharRNN
for instanciada.

43
00:01:47,140 --> 00:01:49,876
Salvei alguns deles
como variáveis de classe.

44
00:01:49,909 --> 00:01:52,278
Usando estes parâmetros
de input e variáveis,

45
00:01:52,311 --> 00:01:54,580
caberá a você criar
as camadas do modelo

46
00:01:54,614 --> 00:01:56,282
e completar a função forward.

47
00:01:56,315 --> 00:01:58,117
Primeiro você criará
uma camada LSTM

48
00:01:58,151 --> 00:02:00,653
sobre a qual você pode ler
no anexo aqui.

49
00:02:00,686 --> 00:02:02,388
Podemos ver
que uma camada LSTM

50
00:02:02,421 --> 00:02:04,657
é criada usando
os parâmetros usuais.

51
00:02:04,690 --> 00:02:06,459
Tamanho de input,
tamanho oculto,

52
00:02:06,492 --> 00:02:09,095
número de camadas
e um parâmetro batch_first.

53
00:02:09,128 --> 00:02:11,464
Também vamos adicionar
um valor de dropout.

54
00:02:11,497 --> 00:02:13,199
Isto introduz
uma camada dropout

55
00:02:13,232 --> 00:02:15,568
entre os outputs
das camadas LSTM,

56
00:02:15,601 --> 00:02:17,937
se você decidiu empilhar
múltiplas camadas.

57
00:02:17,970 --> 00:02:20,273
Depois de definir
uma camada LSTM,

58
00:02:20,306 --> 00:02:22,708
vou pedir para você definir
mais duas camadas:

59
00:02:22,742 --> 00:02:25,444
uma camada dropout
e uma completamente conectada

60
00:02:25,478 --> 00:02:27,513
para obter o output desejado.

61
00:02:27,547 --> 00:02:31,184
Quando definir estas camadas,
você define a função forward.

62
00:02:31,217 --> 00:02:33,920
Ela contém um input X
e um estado oculto.

63
00:02:33,953 --> 00:02:36,656
Você vai passar este input
pelas camadas do modelo

64
00:02:36,689 --> 00:02:39,325
e retornar um output final
e um estado oculto.

65
00:02:39,358 --> 00:02:42,495
Formule o output LSTM
para ele ser alimentado

66
00:02:42,528 --> 00:02:44,729
para a última camada
completamente conectada.

67
00:02:44,763 --> 00:02:47,133
Aqui embaixo, você verá
esta função

68
00:02:47,166 --> 00:02:50,136
para inicializar o estado oculto
de uma LSTM.

69
00:02:50,169 --> 00:02:52,772
Uma LSTM tem um estado oculto
e um estado de célula

70
00:02:52,805 --> 00:02:55,141
que são salvos
como uma tupla: hidden.

71
00:02:55,174 --> 00:02:57,210
O formato do estado oculto
e do da célula

72
00:02:57,243 --> 00:03:00,179
é definido pelo número
de camadas no modelo,

73
00:03:00,213 --> 00:03:01,781
o tamanho do lote do input

74
00:03:01,814 --> 00:03:04,884
e pela dimensão oculta
que definimos na criação do modelo.

75
00:03:04,917 --> 00:03:08,454
Nesta função, vamos inicializar
os pesos ocultos todos como zero

76
00:03:08,488 --> 00:03:10,723
e movê-los para a GPU,
se estiver disponível.

77
00:03:10,756 --> 00:03:13,526
Todo o código que você vê,
você não precisa mudar.

78
00:03:13,559 --> 00:03:17,063
Apenas defina as camadas do modelo
e seu comportamento.

79
00:03:17,096 --> 00:03:18,698
Se implementou corretamente,

80
00:03:18,731 --> 00:03:21,400
conseguirá configurar
os hiperparâmetros do modelo

81
00:03:21,434 --> 00:03:24,337
e treinar e gerar
alguns textos de amostra.

82
00:03:24,370 --> 00:03:25,771
Tente sozinho.

83
00:03:25,805 --> 00:03:27,773
Em seguida,
mostro minha solução.

