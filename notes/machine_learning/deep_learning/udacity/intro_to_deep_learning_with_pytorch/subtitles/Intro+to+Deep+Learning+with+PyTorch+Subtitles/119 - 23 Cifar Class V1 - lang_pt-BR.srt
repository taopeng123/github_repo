1
00:00:00,437 --> 00:00:02,505
O Cifar-10 é
um conhecido banco de dados

2
00:00:02,538 --> 00:00:04,599
com 64 mil imagens
minúsculas.

3
00:00:04,632 --> 00:00:07,875
Cada imagem retrata um objeto
de uma entre 10 classes.

4
00:00:07,908 --> 00:00:10,177
Vemos que cada imagem
é realmente minúscula,

5
00:00:10,210 --> 00:00:12,751
com apenas 32 pixels
de altura e de largura.

6
00:00:12,784 --> 00:00:15,435
Por serem coloridas,
são interpretadas pelo computador

7
00:00:15,468 --> 00:00:18,983
como arrays com profundidade de 3
para canais RGB.

8
00:00:19,016 --> 00:00:21,794
Como as imagens são coloridas,
e há muitas delas,

9
00:00:21,827 --> 00:00:25,690
a 1ª coisa que vou mostrar é a opção
de usar uma GPU para o treinamento.

10
00:00:25,723 --> 00:00:30,073
A GPU nos permite fazer
processamento de dados em paralelo,

11
00:00:30,106 --> 00:00:33,268
então pode ser útil para acelerar
o tempo de treinamento.

12
00:00:33,301 --> 00:00:35,881
Aqui eu carreguei
as bibliotecas de sempre,

13
00:00:35,914 --> 00:00:39,942
e o PyTorch nos permite verificar
se há uma GPU disponível.

14
00:00:40,298 --> 00:00:41,960
Torch.cuda está disponível

15
00:00:41,993 --> 00:00:44,632
e retornará uma variável booleana
True ou False,

16
00:00:44,665 --> 00:00:47,019
havendo ou não
uma GPU disponível.

17
00:00:47,052 --> 00:00:50,168
Armazenaremos isto e, mais tarde,
se houver uma GPU disponível,

18
00:00:50,201 --> 00:00:53,017
poderemos mover os dados
e o modelo para esse dispositivo

19
00:00:53,050 --> 00:00:54,465
para acelerar o treinamento.

20
00:00:54,498 --> 00:00:56,420
Por ora, só vou visualizar
alguns dados

21
00:00:56,453 --> 00:00:58,856
e apresentar o problema,
então usarei meu laptop.

22
00:00:58,889 --> 00:01:00,473
Quando executo esta célula,

23
00:01:00,506 --> 00:01:02,899
vemos que estou treinando
numa CPU.

24
00:01:02,932 --> 00:01:06,043
Depois, quando eu tentar criar
uma solução e treinar o modelo,

25
00:01:06,076 --> 00:01:07,583
mudarei para a GPU.

26
00:01:08,103 --> 00:01:10,498
Em geral, é útil
saber usar isso.

27
00:01:11,098 --> 00:01:13,858
Em seguida, carregarei
meus dados, como sempre.

28
00:01:13,891 --> 00:01:16,055
O Cifar, assim como o MNIST,
está disponível

29
00:01:16,088 --> 00:01:18,599
na biblioteca de conjuntos de dados
do torchvision.

30
00:01:18,632 --> 00:01:20,745
Definirei o treinamento
e os dados de teste

31
00:01:20,778 --> 00:01:23,057
chamando datasets.CIFAR10.

32
00:01:23,090 --> 00:01:26,153
Também vou converter estes dados
em tensores

33
00:01:26,186 --> 00:01:27,999
e normalizar
os valores de RGB,

34
00:01:28,032 --> 00:01:31,347
para que os valores de pixel
variem de aproximadamente 0 a 1.

35
00:01:31,783 --> 00:01:34,537
Finalmente, posso carregar
meus dados em lotes,

36
00:01:34,570 --> 00:01:37,182
através da classe DataLoader
do PyTorch.

37
00:01:37,215 --> 00:01:40,320
Estas linhas do código são
quase iguais às do código MNIST,

38
00:01:40,353 --> 00:01:43,685
no qual carregamos os dados,
os convertemos em tensores

39
00:01:43,718 --> 00:01:47,437
e os separamos em conjuntos
de treinamento, validação e teste.

40
00:01:47,904 --> 00:01:51,982
Aqui defini as 10 classes de imagens
que vou usar.

41
00:01:52,015 --> 00:01:55,585
Todas as imagens Cifar vão pertencer
a uma destas categorias.

42
00:01:55,618 --> 00:01:57,347
Os dados podem demorar
a carregar,

43
00:01:57,380 --> 00:02:00,237
mas, feito isso, podemos visualizar
um lote desses dados.

44
00:02:00,713 --> 00:02:04,764
Aqui defini uma função helper,
que vai desnormalizar as imagens

45
00:02:04,797 --> 00:02:09,684
e transformá-las de imagens tensor
em imagens NumPy para visualização.

46
00:02:09,717 --> 00:02:13,056
Em seguida, vou carregar
e exibir um lote de imagens.

47
00:02:13,089 --> 00:02:16,733
Aqui vemos que as imagens
são exatamente como esperávamos.

48
00:02:16,766 --> 00:02:20,919
Há imagens de gatos, sapos,
cervos e automóveis.

49
00:02:21,815 --> 00:02:24,677
Podemos até ver uma imagem
mais detalhadamente.

50
00:02:25,524 --> 00:02:28,244
Aqui exibi os canais de cor
vermelho, verde e azul

51
00:02:28,277 --> 00:02:31,224
como valores de cinza
de uma única imagem.

52
00:02:31,257 --> 00:02:35,144
Podemos ver que os valores de pixel
mais claros se aproximam do valor 1,

53
00:02:35,177 --> 00:02:37,159
e os escuros
se aproximam de 0.

54
00:02:37,559 --> 00:02:40,130
Em seguida, você deverá definir
e treinar uma CNN,

55
00:02:40,163 --> 00:02:41,809
para classificar
essas imagens.

56
00:02:41,842 --> 00:02:44,163
Você também pode testar
uma abordagem de MLP,

57
00:02:44,196 --> 00:02:46,502
analisar as duas
e comparar os resultados.

58
00:02:46,535 --> 00:02:49,644
Imagino que você queira
definir uma arquitetura de CNN,

59
00:02:49,677 --> 00:02:51,722
então incluí links
para a documentação

60
00:02:51,755 --> 00:02:54,673
sobre camadas convolucionais
e max pooling no PyTorch.

61
00:02:54,706 --> 00:02:56,069
Este é um diagrama simples

62
00:02:56,102 --> 00:02:59,514
que mostra como uma imagem de input
passa por algumas destas camadas.

63
00:02:59,547 --> 00:03:00,772
Se rolar para baixo,

64
00:03:00,805 --> 00:03:04,353
verá que defini um exemplo
de camada convolucional para você.

65
00:03:04,386 --> 00:03:07,146
Eu a defini na função init
da nossa rede.

66
00:03:07,179 --> 00:03:09,043
Para definir
uma camada convolucional,

67
00:03:09,076 --> 00:03:12,979
usei nn.Conv2d
e passei alguns parâmetros.

68
00:03:13,012 --> 00:03:15,772
Na 1ª camada convolucional,
esse será o número de inputs

69
00:03:15,805 --> 00:03:18,248
visto como a profundidade
da imagem de input.

70
00:03:18,281 --> 00:03:21,263
Lembre-se de que os inputs
são imagens de 32x32,

71
00:03:21,296 --> 00:03:24,609
com uma profundidade de 3
para os canais de cor RGB.

72
00:03:24,642 --> 00:03:26,091
Então defini o input

73
00:03:26,124 --> 00:03:29,130
e especifiquei que ele deve produzir
uma camada convolucional

74
00:03:29,163 --> 00:03:30,798
com uma profundidade de 16.

75
00:03:30,831 --> 00:03:33,124
Então essa camada deve pegar
a nossa imagem

76
00:03:33,157 --> 00:03:35,980
e produzir 16 imagens filtradas
como output.

77
00:03:36,013 --> 00:03:40,029
Eu também defini que usei filtros
cujo tamanho é 3x3.

78
00:03:40,062 --> 00:03:42,781
E, para que a camada de output
tenha o mesmo tamanho XY

79
00:03:42,814 --> 00:03:43,995
da camada de input,

80
00:03:44,028 --> 00:03:46,699
adicionarei um padding de 1 pixel
à borda.

81
00:03:46,732 --> 00:03:49,805
Eu também defini uma camada
max pooling chamada "pool",

82
00:03:49,838 --> 00:03:52,617
cujo tamanho do Kernel
e do stride é 2,

83
00:03:52,650 --> 00:03:54,712
então todo input
ao qual ela seja aplicada

84
00:03:54,745 --> 00:03:58,279
terá sua dimensão XY reduzida
por um fator de 2.

85
00:03:58,312 --> 00:04:02,090
Na função forward, podemos ver
como tudo isso se encaixa.

86
00:04:02,123 --> 00:04:03,794
Dada uma imagem de input X,

87
00:04:03,827 --> 00:04:06,537
eu passo essa imagem
para a 1ª camada convolucional

88
00:04:06,570 --> 00:04:09,436
e aplico
uma função de ativação ReLU.

89
00:04:09,469 --> 00:04:11,940
O output será passado
a uma camada de pooling,

90
00:04:11,973 --> 00:04:15,644
resultando num X reduzido,
que eu vou retornar.

91
00:04:15,677 --> 00:04:18,014
Para completar este modelo,
você pode adicionar

92
00:04:18,047 --> 00:04:20,325
várias camadas
convolucionais e de pooling,

93
00:04:20,358 --> 00:04:23,120
depois achatar e aplicar
uma camada totalmente conectada

94
00:04:23,153 --> 00:04:26,354
para produzir o número desejado
de outputs de pontuações de classe.

95
00:04:26,387 --> 00:04:28,119
Depois de definir
a CNN completa,

96
00:04:28,152 --> 00:04:31,890
pode instanciá-la e até movê-la
para a GPU, caso esteja disponível.

97
00:04:31,923 --> 00:04:36,075
Depois você pode tentar definir
uma função de perda e de otimização

98
00:04:36,108 --> 00:04:37,664
para esta tarefa
de treinamento.

99
00:04:37,697 --> 00:04:40,562
Por fim, disponibilizei
um loop de treinamento para você.

100
00:04:40,595 --> 00:04:44,141
Mesmo que você aumente o número
de epochs em que treinará o modelo,

101
00:04:44,174 --> 00:04:47,979
este loop rastreará
a perda de treinamento e validação.

102
00:04:48,012 --> 00:04:50,523
Se a perda de validação diminuir
após 1 epoch,

103
00:04:50,556 --> 00:04:52,261
seu modelo será salvo.

104
00:04:52,294 --> 00:04:54,127
Depois você poderá
testar sua rede

105
00:04:54,160 --> 00:04:57,656
e ver seu desempenho
para cada tipo de imagem de teste.

106
00:04:57,689 --> 00:05:00,471
O maior desafio será definir
uma CNN completa,

107
00:05:00,504 --> 00:05:04,320
e eu sugiro que você pesquise
antes de definir o modelo,

108
00:05:04,353 --> 00:05:06,969
para fazer escolhas conscientes
à medida que avança.

109
00:05:07,002 --> 00:05:08,757
Tente resolver
este desafio sozinho

110
00:05:08,790 --> 00:05:12,650
e, se quiser conferir seu trabalho,
a seguir mostrarei uma solução.

