1
00:00:00,000 --> 00:00:01,685
在上个示例中

2
00:00:01,685 --> 00:00:05,250
通过查看训练期间交叉熵损失是如何越来越小的

3
00:00:05,250 --> 00:00:07,320
我们获得了很高的分类准确率

4
00:00:07,320 --> 00:00:09,855
交叉熵损失衡量的是

5
00:00:09,855 --> 00:00:11,145
预测类别与真实类别之间的差异

6
00:00:11,145 --> 00:00:14,295
我估算了何时适合停止训练

7
00:00:14,295 --> 00:00:17,185
即训练损失停止下降时

8
00:00:17,185 --> 00:00:18,460
但是你已经知道

9
00:00:18,460 --> 00:00:22,990
我们可以使用验证集 自动化地来判断何时停止训练

10
00:00:22,990 --> 00:00:25,250
我将演示如何向代码中添加验证集功能

11
00:00:25,250 --> 00:00:26,755
首先

12
00:00:26,755 --> 00:00:31,450
像创建训练集和测试集一样创建验证集

13
00:00:31,450 --> 00:00:35,790
我将从训练集中拿出一定比例的数据

14
00:00:35,790 --> 00:00:38,550
将变量 valid_size 设为 0.2

15
00:00:38,550 --> 00:00:41,440
表示拿出 20% 的训练数据作为验证数据

16
00:00:41,440 --> 00:00:45,155
这个比例应该足够了 因为 MNIST 数据集很庞大

17
00:00:45,155 --> 00:00:46,910
然后使用

18
00:00:46,910 --> 00:00:50,960
SubsetRandomSampler 拆分训练数据

19
00:00:50,960 --> 00:00:54,289
首先 记录有多少张训练图像

20
00:00:54,289 --> 00:00:56,900
然后决定使用训练集中的哪些索引

21
00:00:56,900 --> 00:01:00,229
创建训练集和验证集

22
00:01:00,229 --> 00:01:04,930
我将通过获取整个训练集的长度 列出所有可能的索引

23
00:01:04,930 --> 00:01:07,670
这些索引将指向

24
00:01:07,670 --> 00:01:10,600
训练集中的每张图像（共 70,000 张）

25
00:01:10,600 --> 00:01:15,080
然后重排这些索引 这样的话 从这个列表中选择的任何索引

26
00:01:15,080 --> 00:01:17,080
将引用随机的数据

27
00:01:17,080 --> 00:01:18,995
接着定义拆分界限

28
00:01:18,995 --> 00:01:21,140
也就是我希望在验证集中

29
00:01:21,140 --> 00:01:23,420
包含的样本数量

30
00:01:23,420 --> 00:01:26,615
它等于 20% 的训练数据

31
00:01:26,615 --> 00:01:31,125
然后在训练数据和验证数据之间按 80/20 比例划分

32
00:01:31,125 --> 00:01:33,860
最后 使用 SubsetRandomSampler

33
00:01:33,860 --> 00:01:37,155
为训练数据和验证数据创建数据抽样器

34
00:01:37,155 --> 00:01:41,370
这样会向 train_loader 和 validation_loader 中添加一个参数

35
00:01:41,370 --> 00:01:44,930
之前只有训练和测试数据加载器

36
00:01:44,930 --> 00:01:48,740
现在通过重排训练数据并使用数据抽样器选出 20% 的数据作为验证集

37
00:01:48,740 --> 00:01:53,170
将训练集拆分成了两部分

38
00:01:53,170 --> 00:01:56,375
正式创建验证集加载器后

39
00:01:56,375 --> 00:02:00,665
在训练循环中向下滚动并使用这个验证集

40
00:02:00,665 --> 00:02:03,305
Ok这是训练循环

41
00:02:03,305 --> 00:02:05,720
现在 除了跟踪训练损失之外

42
00:02:05,720 --> 00:02:08,210
我还将跟踪验证损失

43
00:02:08,210 --> 00:02:11,210
当训练损失在下降 但是验证损失没有下降的时候

44
00:02:11,210 --> 00:02:14,470
就是停止训练的最佳时刻

45
00:02:14,470 --> 00:02:17,990
我将跟踪验证损失的变化

46
00:02:17,990 --> 00:02:21,140
特别是跟踪最低验证损失

47
00:02:21,140 --> 00:02:24,230
以便将其与当前验证损失进行比较

48
00:02:24,230 --> 00:02:27,995
看看一个周期之后它比最低损失大还是小

49
00:02:27,995 --> 00:02:29,320
在周期循环里

50
00:02:29,320 --> 00:02:33,885
这些是正常的训练批次循环 还有一个验证批次循环

51
00:02:33,885 --> 00:02:37,630
该循环会遍历验证集中的所有数据和标签

52
00:02:37,630 --> 00:02:41,680
将模型应用到该数据上并记录损失

53
00:02:41,680 --> 00:02:44,840
注意 现在不执行反向传播步骤

54
00:02:44,840 --> 00:02:47,295
只有训练数据需要执行反向传播

55
00:02:47,295 --> 00:02:50,360
然后在输出语句中添加一些内容

56
00:02:50,360 --> 00:02:53,570
并且在每个周期之后 输出平均验证损失

57
00:02:53,570 --> 00:02:55,280
此外 在每个周期结束时

58
00:02:55,280 --> 00:02:57,260
我将检查验证损失

59
00:02:57,260 --> 00:02:59,720
看看它是否比当前记录的最低值小

60
00:02:59,720 --> 00:03:02,180
如果比最低值小 则保存模型

61
00:03:02,180 --> 00:03:04,400
因为这表明验证损失降低了

62
00:03:04,400 --> 00:03:07,050
我将该损失记录为新的最低值

63
00:03:07,050 --> 00:03:10,870
我将初始最低值设成了无穷大

64
00:03:10,870 --> 00:03:15,575
这么高的值可以保证在第一个周期之后该损失将更新

65
00:03:15,575 --> 00:03:18,575
注意这行代码 它的作用是

66
00:03:18,575 --> 00:03:22,075
根据名称 model.pt 保存模型及其当前参数

67
00:03:22,075 --> 00:03:25,250
Ok然后运行 50 个周期

68
00:03:25,250 --> 00:03:28,920
查看每个周期之后的训练损失和验证损失

69
00:03:28,920 --> 00:03:30,980
可以看出 在前 30 个周期左右

70
00:03:30,980 --> 00:03:34,895
训练和验证损失都降低了

71
00:03:34,895 --> 00:03:37,190
所以在验证损失降低的每个周期之后

72
00:03:37,190 --> 00:03:39,695
模型都会保存

73
00:03:39,695 --> 00:03:43,620
还可以看出在这个周期左右 降低速度变慢了

74
00:03:43,620 --> 00:03:47,580
实际上 模型最后一次保存是在第 37 个周期之后

75
00:03:47,580 --> 00:03:51,140
在验证和训练损失开始分离时保存模型

76
00:03:51,140 --> 00:03:55,000
可以防止模型过拟合训练数据

77
00:03:55,000 --> 00:03:57,200
还可以提高效率

78
00:03:57,200 --> 00:04:02,510
在最后 10-15 个周期 验证损失保持不变

79
00:04:02,510 --> 00:04:05,720
验证损失不再降低表明

80
00:04:05,720 --> 00:04:09,125
甚至在第 30 个周期左右模型就达到最佳状态了

81
00:04:09,125 --> 00:04:11,105
在第 37 个周期前肯定达到了

82
00:04:11,105 --> 00:04:15,155
下一步是查看模型在测试数据上的效果

83
00:04:15,155 --> 00:04:17,840
在这里将之前按名称保存的模型

84
00:04:17,840 --> 00:04:20,630
加载到实例化的 model 中

85
00:04:20,630 --> 00:04:22,895
然后照常测试模型

86
00:04:22,895 --> 00:04:27,005
将测试数据传入模型中并记录类别准确率

87
00:04:27,005 --> 00:04:29,865
总体准确率是 97%

88
00:04:29,865 --> 00:04:32,270
和上个没有验证集的模型

89
00:04:32,270 --> 00:04:33,640
效果很像

90
00:04:33,640 --> 00:04:36,950
所以即使再训练该模型 15 个周期

91
00:04:36,950 --> 00:04:38,735
结果也差不多

92
00:04:38,735 --> 00:04:42,320
这很合理 因为验证损失变化不大

93
00:04:42,320 --> 00:04:45,625
所以无论是在第 37 个周期还是第 50 个周期之后保存模型

94
00:04:45,625 --> 00:04:47,595
模型都应该很相似

95
00:04:47,595 --> 00:04:52,800
发生这种行为还有一个原因：大多数图像很相似

96
00:04:52,800 --> 00:04:56,765
所有图像都经过预处理并且所有数字看起来很像

97
00:04:56,765 --> 00:04:58,735
对于没有验证集的情形

98
00:04:58,735 --> 00:05:01,790
模型训练更长时间影响不大

99
00:05:01,790 --> 00:05:03,125
但是在某些情形下

100
00:05:03,125 --> 00:05:05,780
模型会过拟合

101
00:05:05,780 --> 00:05:09,160
根据验证损失选择模型变得更重要

102
00:05:09,160 --> 00:05:12,230
所以模型验证很有用

103
00:05:12,230 --> 00:05:15,270
有助于选择最佳模型并决定何时停止训练

