1
00:00:01,000 --> 00:00:04,901
No último vídeo, nós utilizamos
as MLPs para codificar imagens

2
00:00:04,934 --> 00:00:07,234
de dígitos escritos à mão.

3
00:00:07,267 --> 00:00:10,133
Antes de fornecer a imagem
em escala de cinza para a MLP

4
00:00:10,167 --> 00:00:13,534
nós precisamos converter
a matriz em um vetor.

5
00:00:13,567 --> 00:00:16,934
O vetor foi dado
como entrada para uma MLP

6
00:00:16,968 --> 00:00:18,968
com duas camadas ocultas.

7
00:00:19,000 --> 00:00:21,334
Esse foi um modelo válido

8
00:00:21,367 --> 00:00:24,167
para classificar imagens
do conjunto de dados MNIST.

9
00:00:24,200 --> 00:00:29,100
Nós tivemos menos de 2% de erro
nas imagens teste.

10
00:00:29,133 --> 00:00:31,968
Para a classificação
de outras imagens,

11
00:00:32,000 --> 00:00:36,167
ao analisar imagens
mais sofisticadas

12
00:00:36,200 --> 00:00:38,133
com padrões
mais complicados,

13
00:00:38,167 --> 00:00:40,267
nós precisaremos
de outra técnica.

14
00:00:40,300 --> 00:00:44,033
Neste vídeo, para motivar
e definir as CNNs,

15
00:00:44,067 --> 00:00:47,834
nós faremos algumas melhorias
que eliminam algumas falhas

16
00:00:47,868 --> 00:00:49,634
e limitações que encontramos

17
00:00:49,667 --> 00:00:53,601
na hora de classificar
imagens com as MLPs.

18
00:00:53,634 --> 00:00:57,000
Nós ajustaremos
dois problemas importantes.

19
00:00:57,801 --> 00:01:02,534
Vimos que as MLPs usam
muitos parâmetros.

20
00:01:02,567 --> 00:01:04,901
Na MLP do vídeo anterior,

21
00:01:04,934 --> 00:01:08,534
para as pequenas imagens
de 28x28,

22
00:01:08,567 --> 00:01:12,801
já havia mais
de meio milhão de parâmetros.

23
00:01:12,834 --> 00:01:15,567
Podemos imaginar
que a complexidade computacional

24
00:01:15,601 --> 00:01:18,200
de imagens
de tamanho moderado

25
00:01:18,234 --> 00:01:21,801
poderia fugir do controle
rapidamente.

26
00:01:21,834 --> 00:01:24,400
Outro problema é
que nós descartamos

27
00:01:24,434 --> 00:01:27,767
as informações 2D
de uma imagem

28
00:01:27,801 --> 00:01:30,868
ao transformar a matriz
em um vetor.

29
00:01:30,901 --> 00:01:32,934
Esta informação espacial

30
00:01:32,968 --> 00:01:35,934
ou conhecimento sobre onde
os pixels estão localizados

31
00:01:35,968 --> 00:01:37,767
em referência um ao outro,

32
00:01:37,801 --> 00:01:40,367
é importante para entender
a imagem,

33
00:01:40,400 --> 00:01:42,434
e pode ajudar muito

34
00:01:42,467 --> 00:01:46,767
no momento de encontrar
os padrões dos valores do pixel.

35
00:01:46,801 --> 00:01:51,734
Nós precisamos de uma nova forma
para processar imagens,

36
00:01:51,767 --> 00:01:55,968
na qual as informações em 2D
não se percam completamente.

37
00:01:56,000 --> 00:01:59,567
As CNNs resolvem os problemas
utilizando camadas

38
00:01:59,601 --> 00:02:01,901
que são conectadas
mais esparsamente,

39
00:02:01,934 --> 00:02:06,267
e as conexões entre camadas
são informadas pela estrutura 2D

40
00:02:06,300 --> 00:02:08,167
da matriz da imagem.

41
00:02:08,200 --> 00:02:12,901
As CNNs aceitam
a matriz como entrada.

42
00:02:12,934 --> 00:02:17,601
Considere o exemplo da amostra
de imagens de 4x4

43
00:02:17,634 --> 00:02:19,334
de dígitos escritos à mão.

44
00:02:19,367 --> 00:02:21,334
O objetivo continua o mesmo.

45
00:02:21,367 --> 00:02:25,667
Nós queremos classificar
o dígito representado na imagem.

46
00:02:25,701 --> 00:02:31,334
Após converter a matriz 4x4
em um vetor com 16 dimensões,

47
00:02:31,367 --> 00:02:35,701
nós utilizamos o vetor
como entrada da MLP.

48
00:02:35,734 --> 00:02:37,300
Nós construímos uma MLP

49
00:02:37,334 --> 00:02:40,767
com uma única camada oculta
com quatro nós.

50
00:02:40,801 --> 00:02:43,567
A camada de saída
possui dez nós.

51
00:02:44,534 --> 00:02:47,901
Na MLP do vídeo anterior,

52
00:02:47,934 --> 00:02:51,434
a saída possui uma função
de ativação softmax

53
00:02:51,467 --> 00:02:53,868
e retorna um vetor
com 10 dimensões

54
00:02:53,901 --> 00:02:56,801
contendo a probabilidade
de que a imagem representa

55
00:02:56,834 --> 00:03:00,467
cada um dos dígitos possíveis
entre zero e nove.

56
00:03:00,501 --> 00:03:02,400
Se treinarmos bem o modelo,

57
00:03:02,434 --> 00:03:06,167
o vetor vai prever
que há um sete na imagem

58
00:03:06,200 --> 00:03:08,167
com grande probabilidade.

59
00:03:08,200 --> 00:03:09,801
Vamos limpar este valor

60
00:03:09,834 --> 00:03:14,434
substituindo a representação
com a camada de saída sugerida.

61
00:03:15,100 --> 00:03:18,567
A informação
que diz que é um sete

62
00:03:18,601 --> 00:03:21,467
é só uma anotação
da camada de saída

63
00:03:21,501 --> 00:03:23,567
que prevê que seja um sete.

64
00:03:23,601 --> 00:03:25,334
Observando esta MLP

65
00:03:25,367 --> 00:03:29,234
notamos que pode haver
alguma redundância.

66
00:03:29,267 --> 00:03:32,400
Todo nó oculto precisa
estar conectado

67
00:03:32,434 --> 00:03:35,901
a cada pixel
da imagem original?

68
00:03:35,934 --> 00:03:37,300
Talvez não.

69
00:03:37,334 --> 00:03:40,534
Divida a imagem
em quatro regiões.

70
00:03:40,567 --> 00:03:42,968
Aqui elas estão codificadas
como vermelha,

71
00:03:43,000 --> 00:03:45,467
verde, amarelo e azul.

72
00:03:45,501 --> 00:03:48,167
Cada nó oculto
pode estar conectado

73
00:03:48,200 --> 00:03:52,534
somente aos pixels
de uma das quatro regiões.

74
00:03:52,567 --> 00:03:58,133
Cada nó oculto só vê
um quarto da imagem original.

75
00:03:58,167 --> 00:04:01,968
No caso da camada totalmente
conectada anterior,

76
00:04:02,000 --> 00:04:05,868
cada nó oculto foi responsável
por compreender

77
00:04:05,901 --> 00:04:09,167
toda a imagem de uma só vez.

78
00:04:09,200 --> 00:04:11,634
Com esta quebra regional

79
00:04:11,667 --> 00:04:14,467
e designação de grupos
de pixels locais

80
00:04:14,501 --> 00:04:16,434
para diferentes nós ocultos,

81
00:04:16,467 --> 00:04:18,534
cada nó oculto
encontra padrões

82
00:04:18,567 --> 00:04:21,868
em apenas uma das quatro
regiões da imagem.

83
00:04:21,901 --> 00:04:26,267
Cada nó oculto ainda relata
para a camada de saída,

84
00:04:26,300 --> 00:04:30,100
que combina as descobertas
dos padrões descobertos

85
00:04:30,133 --> 00:04:33,000
aprendidos de forma separada
em cada região.

86
00:04:33,033 --> 00:04:36,767
Esta camada
localmente conectada

87
00:04:36,801 --> 00:04:38,667
usa muito menos parâmetros

88
00:04:38,701 --> 00:04:40,901
do que uma camada
densamente conectada.

89
00:04:40,934 --> 00:04:42,968
Isso causa menos
sobrecarregamento

90
00:04:43,000 --> 00:04:48,200
e sabe como provocar os padrões
dos dados da imagem.

91
00:04:49,067 --> 00:04:52,734
Nós podemos reorganizar
os vetores como matrizes.

92
00:04:52,767 --> 00:04:58,400
A relação entre os nós
e as camadas é mais óbvia.

93
00:04:58,434 --> 00:05:00,701
Nós podemos expandir
a quantidade de padrões

94
00:05:00,734 --> 00:05:02,334
a serem detectados

95
00:05:02,367 --> 00:05:05,067
e ainda utilizar
a estrutura 2D

96
00:05:05,100 --> 00:05:09,033
para adicionar pesos
de forma seletiva e conservadora

97
00:05:09,067 --> 00:05:11,367
introduzindo
mais nós ocultos.

98
00:05:11,400 --> 00:05:13,434
Cada um continua confinado

99
00:05:13,467 --> 00:05:17,267
a analisar uma pequena
região da imagem.

100
00:05:17,968 --> 00:05:20,000
Os nós vermelhos
na camada oculta

101
00:05:20,033 --> 00:05:22,334
continuam conectados
aos nós vermelhos

102
00:05:22,367 --> 00:05:24,067
da camada de entrada,

103
00:05:24,100 --> 00:05:27,801
com a mesma codificação de cor
para todas as outras cores.

104
00:05:28,434 --> 00:05:32,200
Afinal nós vimos nos vídeos
anteriores sobre redes neurais

105
00:05:32,234 --> 00:05:35,400
que, ao expandir os nós
da camada oculta,

106
00:05:35,434 --> 00:05:38,767
nós descobrimos padrões
mais complexos nos dados.

107
00:05:39,501 --> 00:05:42,434
Nós temos duas coleções
de nós ocultos,

108
00:05:42,467 --> 00:05:44,934
e cada coleção contém nós

109
00:05:44,968 --> 00:05:49,367
que examinam uma região
diferente da imagem.

110
00:05:49,400 --> 00:05:53,334
Os nós ocultos
de uma coleção

111
00:05:53,367 --> 00:05:55,767
devem compartilhar
um grupo comum de pesos.

112
00:05:55,801 --> 00:05:58,667
Regiões diferentes da imagem

113
00:05:58,701 --> 00:06:01,834
podem possuir
o mesmo tipo de informação.

114
00:06:01,868 --> 00:06:06,534
Em outras palavras, todo padrão
relevante para entender a imagem

115
00:06:06,567 --> 00:06:09,667
pode estar em qualquer lugar
na imagem.

116
00:06:09,701 --> 00:06:13,734
A forma mais simples de ver como
o compartilhamento de parâmetros

117
00:06:13,767 --> 00:06:16,634
auxilia a rede neural
a classificar objetos

118
00:06:16,667 --> 00:06:20,400
é com um exemplo de imagem
com maior resolução.

119
00:06:21,133 --> 00:06:22,901
Digamos que você tenha
uma imagem

120
00:06:22,934 --> 00:06:26,567
e queira que a rede
a identifique como um gato.

121
00:06:26,601 --> 00:06:28,601
Não importa onde
o gato esteja,

122
00:06:28,634 --> 00:06:31,133
ele continuará sendo
a imagem de um gato.

123
00:06:31,167 --> 00:06:34,501
Se sua rede precisa aprender
sobre gatos no canto esquerdo

124
00:06:34,534 --> 00:06:37,234
e direito
de forma independente,

125
00:06:37,267 --> 00:06:39,934
ela precisará
trabalhar muito.

126
00:06:39,968 --> 00:06:43,067
Mas nós dizemos à rede,
de forma explícita,

127
00:06:43,100 --> 00:06:46,334
que objetos e imagens
são os mesmos

128
00:06:46,367 --> 00:06:49,801
estando à esquerda
ou à direita da foto.

129
00:06:49,834 --> 00:06:53,534
Isso é parcialmente possível
com o compartilhamento de peso.

130
00:06:53,567 --> 00:06:58,234
Tudo isso motivará
as camadas convolucionais,

131
00:06:58,267 --> 00:07:01,334
que apresentaremos
no próximo vídeo.

