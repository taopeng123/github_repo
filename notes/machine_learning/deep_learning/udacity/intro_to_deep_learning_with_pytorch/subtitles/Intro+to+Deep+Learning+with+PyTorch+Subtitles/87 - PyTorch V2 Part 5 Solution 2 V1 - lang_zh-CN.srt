1
00:00:00,000 --> 00:00:05,670
欢迎回来下面说说我是如何使用丢弃构建和训练此网络的

2
00:00:05,670 --> 00:00:06,975
首先

3
00:00:06,975 --> 00:00:10,590
将丢弃模块设为 self.dropout

4
00:00:10,590 --> 00:00:14,985
self.dropout = nn.dropout 设定丢弃概率

5
00:00:14,985 --> 00:00:16,320
我设为 20%

6
00:00:16,320 --> 00:00:20,895
添加到 forward 方法中 经过每个隐藏层

7
00:00:20,895 --> 00:00:23,960
验证代码看起来和之前的基本一样

8
00:00:23,960 --> 00:00:26,750
但是现在我们使用 model.eval

9
00:00:26,750 --> 00:00:29,315
将模型变成评估/推理模式

10
00:00:29,315 --> 00:00:32,725
这样会关闭丢弃

11
00:00:32,725 --> 00:00:34,890
然后和之前一样

12
00:00:34,890 --> 00:00:37,255
传入测试集中的数据

13
00:00:37,255 --> 00:00:40,820
计算损失和准确率

14
00:00:40,820 --> 00:00:44,465
然后运行 model.train 将模型设回训练模式

15
00:00:44,465 --> 00:00:47,080
开启丢弃

16
00:00:47,080 --> 00:00:48,860
继续训练更多数据

17
00:00:48,860 --> 00:00:52,775
现在我们使用了丢弃

18
00:00:52,775 --> 00:00:57,460
查看这些周期之后的训练损失和验证损失

19
00:00:57,460 --> 00:01:00,140
可以看出当我们继续训练之后

20
00:01:00,140 --> 00:01:03,445
验证损失和训练损失很接近

21
00:01:03,445 --> 00:01:07,805
因此使用丢弃后 至少减少了过拟合现象

22
00:01:07,805 --> 00:01:15,395
虽然验证损失没有达到不使用丢弃时那么低

23
00:01:15,395 --> 00:01:17,610
但是依然降低了

24
00:01:17,610 --> 00:01:19,840
如果我们训练更长时间

25
00:01:19,840 --> 00:01:25,600
很有可能验证损失会比不使用丢弃时更低

