1
00:00:00,000 --> 00:00:01,695
现在我们将讨论

2
00:00:01,695 --> 00:00:04,785
推理和验证过程

3
00:00:04,785 --> 00:00:06,915
训练好网络后

4
00:00:06,915 --> 00:00:09,555
我们会用它做预测

5
00:00:09,555 --> 00:00:11,070
这个过程称之为推理

6
00:00:11,070 --> 00:00:13,350
这个词来自统计学

7
00:00:13,350 --> 00:00:16,620
但是

8
00:00:16,620 --> 00:00:18,360
神经网络往往在训练数据上表现太好

9
00:00:18,360 --> 00:00:21,170
以至于无法泛化到网络尚未见过的数据

10
00:00:21,170 --> 00:00:22,940
这个问题称之为过拟合

11
00:00:22,940 --> 00:00:27,585
当我们在训练集上训练的时间越来越长

12
00:00:27,585 --> 00:00:29,720
网络会开始发现并学习一些仅适用于该训练集的关系和规律

13
00:00:29,720 --> 00:00:32,045
但是这些关系和规律并不适用于泛化数据集 即

14
00:00:32,045 --> 00:00:37,025
包含所有其他任何手写数字的数据集

15
00:00:37,025 --> 00:00:39,305
要检测过拟合问题

16
00:00:39,305 --> 00:00:45,260
我们使用非训练集中的数据衡量网络的效果

17
00:00:45,260 --> 00:00:48,440
这种数据通常称为验证集或测试集

18
00:00:48,440 --> 00:00:52,370
在用验证集衡量效果时

19
00:00:52,370 --> 00:00:57,545
我们还会通过丢弃等正则化方法减少过拟合现象

20
00:00:57,545 --> 00:00:58,895
在此 notebook 中

21
00:00:58,895 --> 00:01:02,705
我将演示如何查看验证集

22
00:01:02,705 --> 00:01:06,985
以及如何使用丢弃减少过拟合现象

23
00:01:06,985 --> 00:01:10,830
要从 PyTorch 中获取训练集

24
00:01:10,830 --> 00:01:14,855
先将 fashionMNIST 设置为 train=true

25
00:01:14,855 --> 00:01:16,070
要获取测试集

26
00:01:16,070 --> 00:01:18,395
在这里设置为 train=false

27
00:01:18,395 --> 00:01:21,175
在这里像之前一样定义模型

28
00:01:21,175 --> 00:01:24,200
验证的目标是

29
00:01:24,200 --> 00:01:28,190
衡量模型在非训练集中的数据上的效果

30
00:01:28,190 --> 00:01:31,805
效果标准由开发者来决定

31
00:01:31,805 --> 00:01:34,105
即由写代码的人来决定

32
00:01:34,105 --> 00:01:37,005
很多时候我们会使用准确率来衡量

33
00:01:37,005 --> 00:01:40,970
即在所有模型预测中

34
00:01:40,970 --> 00:01:45,340
正确预测所占的百分比

35
00:01:45,340 --> 00:01:48,500
其他衡量指标包括精确率和召回率

36
00:01:48,500 --> 00:01:50,615
以及 top-5 错误率

37
00:01:50,615 --> 00:01:55,475
我将演示如何衡量在验证集上的准确率

38
00:01:55,475 --> 00:01:58,390
首先 我将对测试集中的一批数据进行前向传播

39
00:01:58,390 --> 00:02:01,850
在测试集中获得概率

40
00:02:01,850 --> 00:02:05,210
一批数据有 64 个样本

41
00:02:05,210 --> 00:02:08,180
然后是 10 列 每个类别对应一列

42
00:02:08,180 --> 00:02:11,330
准确率衡量的是

43
00:02:11,330 --> 00:02:14,445
模型对给定图像的类别是否预测正确

44
00:02:14,445 --> 00:02:19,220
预测结果可以看做概率最高的类别

45
00:02:19,220 --> 00:02:24,780
我们可以对张量使用 top-k 方法

46
00:02:24,780 --> 00:02:27,195
它会返回前 k 个值

47
00:02:27,195 --> 00:02:29,265
如果传入 1

48
00:02:29,265 --> 00:02:33,105
那么将返回最高的值

49
00:02:33,105 --> 00:02:38,560
这个最高值表示网络预测的概率最高的类别

50
00:02:38,560 --> 00:02:40,755
对于我获取的这批测试数据

51
00:02:40,755 --> 00:02:45,340
这十个样本来说

52
00:02:45,340 --> 00:02:50,500
我们看到类别 4 和 5 是预测结果

53
00:02:50,500 --> 00:02:53,090
注意 这个网络尚未经过训练

54
00:02:53,090 --> 00:02:55,370
只是随机地做出预测

55
00:02:55,370 --> 00:02:58,690
因为它对数据还完全不了解

56
00:02:58,690 --> 00:03:01,670
top-k 返回一个包含两个张量的元组

57
00:03:01,670 --> 00:03:04,460
第一个张量是实际概率值

58
00:03:04,460 --> 00:03:07,760
第二个张量是类别索引本身

59
00:03:07,760 --> 00:03:10,595
通常我们希望获得这个 top_class

60
00:03:10,595 --> 00:03:16,220
在这里调用 topk 并将概率和类别分开

61
00:03:16,220 --> 00:03:18,745
接下来我们将使用这个 top_class

62
00:03:18,745 --> 00:03:22,850
获得网络的预测类别后

63
00:03:22,850 --> 00:03:25,085
我们可以用它与真实标签进行比较

64
00:03:25,085 --> 00:03:28,590
输入 top_class == labels

65
00:03:28,590 --> 00:03:31,310
这里需要注意的是

66
00:03:31,310 --> 00:03:34,700
需要确保 top_class 张量和 labels 张量形状一样

67
00:03:34,700 --> 00:03:39,520
这样才能进行相等性判断

68
00:03:39,520 --> 00:03:47,480
来自 testloader 的 labels 是一个一维张量 有 64 个元素

69
00:03:47,480 --> 00:03:52,240
但是 top_class 本身是一个二维张量 大小是 64 x 1

70
00:03:52,240 --> 00:03:57,845
我在这里更改了 labels 的形状

71
00:03:57,845 --> 00:04:01,250
使其与 top_class 的形状一样

72
00:04:01,250 --> 00:04:03,015
看看结果怎么样

73
00:04:03,015 --> 00:04:04,520
里面有大量 0 和 1

74
00:04:04,520 --> 00:04:05,990
0 表示不匹配

75
00:04:05,990 --> 00:04:07,745
1 表示匹配

76
00:04:07,745 --> 00:04:10,985
这个张量由大量 0 和 1 组成

77
00:04:10,985 --> 00:04:14,850
如果要计算准确率

78
00:04:14,850 --> 00:04:17,355
我们可以算出

79
00:04:17,355 --> 00:04:18,600
所有正确的预测数量之和

80
00:04:18,600 --> 00:04:20,960
然后除以预测总数

81
00:04:20,960 --> 00:04:23,780
如果张量全是 0 和 1

82
00:04:23,780 --> 00:04:25,955
就相当于取均值

83
00:04:25,955 --> 00:04:27,940
因此输入 torch.mean

84
00:04:27,940 --> 00:04:32,650
但问题是 equals 是字节张量

85
00:04:32,650 --> 00:04:36,100
而 torch.mean 不适用于字节张量

86
00:04:36,100 --> 00:04:39,335
因此我们需要将 equals 转换为浮点数张量

87
00:04:39,335 --> 00:04:42,050
然后可以看出

88
00:04:42,050 --> 00:04:45,200
这个批次的准确率是 15.6%

89
00:04:45,200 --> 00:04:47,180
在我们的预期范围内

90
00:04:47,180 --> 00:04:49,010
网络尚未训练

91
00:04:49,010 --> 00:04:51,590
只是随机地做出猜测

92
00:04:51,590 --> 00:04:56,060
因此对于任何特定图像 准确率应该约为 1/10

93
00:04:56,060 --> 00:05:01,910
即 只是均匀地猜测其中一个类别

94
00:05:01,910 --> 00:05:05,105
下面你的任务是实现这个验证循环

95
00:05:05,105 --> 00:05:07,970
将测试集中的数据传入网络中

96
00:05:07,970 --> 00:05:12,260
并计算损失和准确率

97
00:05:12,260 --> 00:05:15,025
要注意的一点是

98
00:05:15,025 --> 00:05:18,860
对于验证流程 我们不进行任何训练操作

99
00:05:18,860 --> 00:05:20,435
因此不需要梯度

100
00:05:20,435 --> 00:05:24,695
如果关闭梯度的话 代码运行速度会稍微加快

101
00:05:24,695 --> 00:05:26,570
通过 with torch.no_grad 设置上下文

102
00:05:26,570 --> 00:05:30,215
将验证流程放入这个上下文里

103
00:05:30,215 --> 00:05:34,435
输入 for images, labels in testloader 然后在这里执行验证流程

104
00:05:34,435 --> 00:05:39,215
基本就是这样

105
00:05:39,215 --> 00:05:43,460
这是训练流程 你需要实现验证流程

106
00:05:43,460 --> 00:05:45,590
然后输出准确率

107
00:05:45,590 --> 00:05:47,070
试试吧加油

108
00:05:47,070 --> 00:05:49,680
如果遇到问题或需要帮助

109
00:05:49,680 --> 00:05:51,600
请参阅我的解决方案

