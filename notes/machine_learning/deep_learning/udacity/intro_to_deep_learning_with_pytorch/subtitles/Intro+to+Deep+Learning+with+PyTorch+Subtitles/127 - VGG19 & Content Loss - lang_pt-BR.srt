1
00:00:00,500 --> 00:00:04,341
Neste código de exemplo, recriaremos
um método de transferência de estilo

2
00:00:04,374 --> 00:00:07,063
que é descrito no artigo
"Image Style Transfer"

3
00:00:07,096 --> 00:00:09,321
Using Convolutional
Neural Networks".

4
00:00:09,354 --> 00:00:11,672
Nesse artigo, o método usa
as características

5
00:00:11,705 --> 00:00:14,167
encontradas numa rede VGG
com 19 camadas,

6
00:00:14,200 --> 00:00:16,223
que chamarei de "VGG19".

7
00:00:16,256 --> 00:00:18,677
Essa rede recebe
uma imagem colorida como input

8
00:00:18,710 --> 00:00:22,151
e a passa por uma série de camadas
convolucionais e de pooling,

9
00:00:22,184 --> 00:00:24,667
seguidas por 3 camadas
totalmente conectadas

10
00:00:24,700 --> 00:00:26,881
que classificam
a imagem recebida.

11
00:00:26,914 --> 00:00:28,684
Entre as 5 camadas
de pooling,

12
00:00:28,717 --> 00:00:31,825
há pilhas
de 2 ou 4 camadas convolucionais.

13
00:00:31,858 --> 00:00:34,748
A profundidade dessas camadas
segue o padrão da pilha,

14
00:00:34,781 --> 00:00:37,373
mas aumenta
depois de cada camada de pooling.

15
00:00:37,406 --> 00:00:40,415
O nome delas deriva da pilha
e da ordem da camada na pilha.

16
00:00:40,448 --> 00:00:44,180
conv1_1 é a 1ª camada convolucional,
por qual a imagem passa,

17
00:00:44,213 --> 00:00:45,523
da 1ª pilha.

18
00:00:45,556 --> 00:00:49,142
conv2_1 é a 1ª camada convolucional
da 2ª pilha.

19
00:00:49,175 --> 00:00:53,357
A camada convolucional mais profunda
da rede é conv5_4.

20
00:00:53,390 --> 00:00:56,142
A transferência de estilo
quer criar uma imagem

21
00:00:56,175 --> 00:00:59,195
que tenha o conteúdo de uma imagem
e o estilo da outra.

22
00:00:59,228 --> 00:01:02,052
Para criar essa imagem,
que chamarei de "imagem alvo",

23
00:01:02,085 --> 00:01:05,093
o método passará primeiro
as imagens de conteúdo e de estilo

24
00:01:05,126 --> 00:01:07,620
pela rede VGG19.

25
00:01:07,653 --> 00:01:10,009
Primeiro, quando a rede vir
a imagem de conteúdo,

26
00:01:10,042 --> 00:01:12,093
passará
pelo processo feedforward

27
00:01:12,126 --> 00:01:14,313
até chegar
a uma camada convolucional

28
00:01:14,346 --> 00:01:16,251
de uma parte profunda
da rede.

29
00:01:16,284 --> 00:01:18,951
O output dessa camada será
a representação do conteúdo

30
00:01:18,984 --> 00:01:20,510
da imagem de input.

31
00:01:20,543 --> 00:01:24,151
Depois, ao vir a imagem de estilo,
extrairá características diferentes

32
00:01:24,184 --> 00:01:27,568
de várias camadas que representam
o estilo dessa imagem.

33
00:01:27,601 --> 00:01:30,946
Por fim, ela usará as representações
do conteúdo e do estilo

34
00:01:30,979 --> 00:01:33,646
para permitir a criação
da imagem alvo.

35
00:01:33,679 --> 00:01:36,521
O desafio é descobrir
como criar a imagem alvo.

36
00:01:36,554 --> 00:01:38,258
Como podemos pegar
uma imagem alvo,

37
00:01:38,291 --> 00:01:40,841
que costuma começar
como uma tela em branco

38
00:01:40,874 --> 00:01:43,096
ou como uma cópia
da imagem de conteúdo,

39
00:01:43,129 --> 00:01:45,058
e manipulá-la
de modo que seu conteúdo

40
00:01:45,091 --> 00:01:46,972
se pareça
com o da imagem de conteúdo

41
00:01:47,005 --> 00:01:49,965
e seu estilo se pareça
com o da imagem de estilo?

42
00:01:49,998 --> 00:01:52,194
Vamos começar
falando do conteúdo.

43
00:01:53,378 --> 00:01:56,153
No artigo, a representação
do conteúdo de uma imagem

44
00:01:56,186 --> 00:01:59,478
é obtida como output
da 4ª pilha convolucional,

45
00:01:59,511 --> 00:02:00,812
conv4_2.

46
00:02:00,845 --> 00:02:02,664
Ao gerar
nossa nova imagem alvo,

47
00:02:02,697 --> 00:02:04,651
comparamos
a representação do seu conteúdo

48
00:02:04,684 --> 00:02:06,413
com a da imagem de conteúdo.

49
00:02:06,446 --> 00:02:09,059
Essas duas representações
devem ser parecidas,

50
00:02:09,092 --> 00:02:12,064
mesmo que a imagem alvo
mude de estilo.

51
00:02:12,097 --> 00:02:15,662
Para formular essa comparação,
definiremos uma perda de conteúdo,

52
00:02:15,695 --> 00:02:17,274
que calculará a diferença

53
00:02:17,307 --> 00:02:20,171
entre as representações
das imagens de conteúdo e alvo,

54
00:02:20,204 --> 00:02:23,612
que chamarei de "Cc" e "Tc",
respectivamente.

55
00:02:23,645 --> 00:02:26,079
Neste caso, calculamos
a diferença média quadrática

56
00:02:26,112 --> 00:02:28,208
entre as 2 representações.

57
00:02:28,241 --> 00:02:29,619
Esta é a perda de conteúdo,

58
00:02:29,652 --> 00:02:32,069
e ela calcula o quanto
as 2 representações

59
00:02:32,102 --> 00:02:33,813
são diferentes uma da outra.

60
00:02:33,846 --> 00:02:36,161
Ao tentarmos criar
a melhor imagem alvo,

61
00:02:36,194 --> 00:02:38,693
nosso objetivo será
minimizar essa perda.

62
00:02:38,726 --> 00:02:41,291
É similar ao modo como usamos
a perda e a otimização

63
00:02:41,324 --> 00:02:43,995
para determinar os pesos da CNN
durante o treinamento.

64
00:02:44,028 --> 00:02:47,413
Mas, desta vez, o objetivo não é
minimizar o erro de classificação.

65
00:02:47,446 --> 00:02:50,019
Aliás, nós nem sequer
vamos treinar a CNN.

66
00:02:50,052 --> 00:02:53,065
Em vez disso, nosso objetivo é
mudar apenas a imagem alvo,

67
00:02:53,098 --> 00:02:56,063
atualizando seu aspecto
até a representação do seu conteúdo

68
00:02:56,096 --> 00:02:58,114
coincidir
com a da imagem de conteúdo.

69
00:02:58,147 --> 00:03:01,612
Então não usaremos a rede VGG19
de forma tradicional.

70
00:03:01,645 --> 00:03:04,356
Não vamos treiná-la
para produzir um output específico.

71
00:03:04,389 --> 00:03:06,766
Nós a usaremos
como um extrator de características,

72
00:03:06,799 --> 00:03:08,192
usando a retropropagação

73
00:03:08,225 --> 00:03:10,354
para minimizar
uma função de perda definida

74
00:03:10,387 --> 00:03:12,833
entre a imagem alvo
e a imagem de conteúdo.

75
00:03:12,866 --> 00:03:14,948
Teremos que definir
uma função de perda

76
00:03:14,981 --> 00:03:17,051
entre a imagem alvo
e a imagem de estilo,

77
00:03:17,084 --> 00:03:19,910
para produzirmos uma imagem
com o estilo que queremos.

78
00:03:19,943 --> 00:03:23,032
A seguir, veremos como representar
o estilo de uma imagem.

