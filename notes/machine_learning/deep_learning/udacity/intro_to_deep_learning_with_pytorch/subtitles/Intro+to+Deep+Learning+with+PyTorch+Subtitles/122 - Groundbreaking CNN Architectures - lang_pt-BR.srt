1
00:00:00,200 --> 00:00:02,933
ImageNet é um banco de dados
com mais de 10 milhões

2
00:00:02,967 --> 00:00:04,600
de imagens rotuladas à mão

3
00:00:04,633 --> 00:00:08,200
retiradas de mil categorias
diferentes de imagem.

4
00:00:08,233 --> 00:00:10,700
Desde 2010, o projeto ImageNet

5
00:00:10,733 --> 00:00:13,000
tem organizado a competição

6
00:00:13,033 --> 00:00:15,500
de reconhecimento visual
em larga escala,

7
00:00:15,533 --> 00:00:18,400
uma competição anual
na qual equipes tentam construir

8
00:00:18,433 --> 00:00:21,200
a melhor CNN
de reconhecimento de objeto

9
00:00:21,233 --> 00:00:23,033
e de classificação.

10
00:00:23,067 --> 00:00:26,233
A primeira inovação
ocorreu em 2012.

11
00:00:26,267 --> 00:00:28,533
A rede chamada AlexNet

12
00:00:28,567 --> 00:00:32,200
foi desenvolvida por uma equipe
na Universidade de Toronto.

13
00:00:32,933 --> 00:00:36,500
Utilizando as melhores GPUs
disponíveis em 2012,

14
00:00:36,533 --> 00:00:40,533
a equipe AlexNet treinou
a rede em uma semana.

15
00:00:40,567 --> 00:00:42,433
AlexNet foi
pioneira na utilização

16
00:00:42,467 --> 00:00:44,900
da função de ativação ReLU

17
00:00:44,933 --> 00:00:48,767
e no dropout como técnica
para evitar o sobreajuste.

18
00:00:49,500 --> 00:00:52,200
Em 2014, duas equipes

19
00:00:52,233 --> 00:00:55,000
quase empataram na competição.

20
00:00:55,867 --> 00:00:59,800
Uma das redes,
chamada VGGNet,

21
00:00:59,833 --> 00:01:03,100
frequentemente
chamada somente de VGG,

22
00:01:03,133 --> 00:01:07,433
surgiu da equipe de geometria
visual da Universidade de Oxford.

23
00:01:08,100 --> 00:01:12,667
A VGG possui duas versões
chamadas de VGG-16

24
00:01:12,700 --> 00:01:14,867
e VGG-19,

25
00:01:14,900 --> 00:01:19,067
com 16 e 19 camadas
respectivamente.

26
00:01:19,100 --> 00:01:22,700
Ambas possuem arquitetura
simples e elegante,

27
00:01:22,733 --> 00:01:26,567
com uma sequência longa
de convoluções de 3x3

28
00:01:26,600 --> 00:01:29,267
separadas por camadas
de pooling de 2x2

29
00:01:29,300 --> 00:01:33,100
e finalizadas com três camadas
completamente conectadas.

30
00:01:33,133 --> 00:01:36,300
A VGG foi pioneira
na utilização

31
00:01:36,333 --> 00:01:39,633
de pequenas janelas
convolucionais de 3x3,

32
00:01:39,667 --> 00:01:44,833
diferente das janelas maiores
da AlexNet, de 11x11.

33
00:01:45,467 --> 00:01:48,100
Em 2015,
o vencedor da ImageNet

34
00:01:48,133 --> 00:01:52,033
foi uma rede da Microsoft
Research chamada de ResNet.

35
00:01:52,067 --> 00:01:54,567
A ResNet se parece com a VGG,

36
00:01:54,600 --> 00:01:57,700
mas não tem a mesma estrutura
que se repete

37
00:01:57,733 --> 00:01:59,700
camada após camada.

38
00:01:59,733 --> 00:02:03,033
Assim como a VGG,
a ResNet possui versões diferentes

39
00:02:03,067 --> 00:02:05,200
que variam
na quantidade de camadas.

40
00:02:05,233 --> 00:02:09,967
A maior possui 152 camadas.

41
00:02:10,700 --> 00:02:14,167
Pesquisadores tentaram tornar
suas CNNs profundas assim,

42
00:02:14,200 --> 00:02:17,600
mas encontravam problemas,
pois, ao adicionar camadas,

43
00:02:17,633 --> 00:02:23,033
o desempenho chegava
a um ponto e depois caía.

44
00:02:23,067 --> 00:02:27,167
Isso é devido ao problema
da dissipação do gradiente,

45
00:02:27,200 --> 00:02:31,733
que surgiu ao treinarmos a rede
usando a retropropagação.

46
00:02:31,767 --> 00:02:37,500
O sinal de gradiente
precisa passar por toda a rede.

47
00:02:37,533 --> 00:02:39,433
Quanto mais profunda
se torna a rede,

48
00:02:39,467 --> 00:02:44,667
mais fraco o sinal pode ficar
antes de chegar ao destino.

49
00:02:44,700 --> 00:02:47,167
A equipe ResNet
adicionou conexões

50
00:02:47,200 --> 00:02:50,800
à CNN profunda
que pulava camadas,

51
00:02:50,833 --> 00:02:53,933
assim o sinal de gradiente
andava menos.

52
00:02:54,667 --> 00:02:57,100
A ResNet teve desempenho
de um super-humano

53
00:02:57,133 --> 00:02:58,833
ao classificar imagens

54
00:02:58,867 --> 00:03:00,667
no banco de dados ImageNet.

