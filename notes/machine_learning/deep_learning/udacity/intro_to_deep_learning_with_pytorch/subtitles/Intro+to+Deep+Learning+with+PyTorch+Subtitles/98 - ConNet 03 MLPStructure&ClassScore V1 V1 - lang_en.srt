1
00:00:00,000 --> 00:00:02,920
After looking at and normalizing our image data,

2
00:00:02,920 --> 00:00:07,095
we'll then create a neural network for discovering the patterns in our training data.

3
00:00:07,095 --> 00:00:09,570
After training, our network should be able to look at

4
00:00:09,570 --> 00:00:12,150
totally new images that it hasn't trained on,

5
00:00:12,150 --> 00:00:14,930
and classify the digits contained in those images.

6
00:00:14,930 --> 00:00:18,890
This previously unseen data is often called test data.

7
00:00:18,890 --> 00:00:24,030
At this point, our images have been converted into vectors with 784 entries.

8
00:00:24,030 --> 00:00:28,630
So, the first input layer in our MLP should have 784 nodes.

9
00:00:28,630 --> 00:00:31,410
We also know that we want the output layer to distinguish

10
00:00:31,410 --> 00:00:34,590
between 10 different digit types, zero through nine.

11
00:00:34,590 --> 00:00:37,385
So, we'll want the last layer to have 10 nodes.

12
00:00:37,385 --> 00:00:41,690
So, our model will take in a flattened image and produce 10 output values,

13
00:00:41,690 --> 00:00:44,540
one for each possible class, zero through nine.

14
00:00:44,540 --> 00:00:47,500
These output values are often called class scores.

15
00:00:47,500 --> 00:00:50,570
A high class score indicates that a network is very

16
00:00:50,570 --> 00:00:53,930
certain that a given input image falls into a certain class.

17
00:00:53,930 --> 00:00:57,760
You can imagine that the class score for a 103, for example,

18
00:00:57,760 --> 00:01:02,020
will have a high score for the class three and a low score for the classes zero,

19
00:01:02,020 --> 00:01:03,680
one, and so on.

20
00:01:03,680 --> 00:01:06,140
But it may also have a small score for

21
00:01:06,140 --> 00:01:10,205
an eight or any other class that looks kind of similar in shape to a three.

22
00:01:10,205 --> 00:01:13,625
The class scores are often represented as a vector of values

23
00:01:13,625 --> 00:01:17,635
or even as a bar graph indicating the relative strengths of the scores.

24
00:01:17,635 --> 00:01:20,840
Now, the part of this MLP architecture that's up to you to

25
00:01:20,840 --> 00:01:24,425
define is really in between the input and output layers.

26
00:01:24,425 --> 00:01:28,830
How many hidden layers do you want to include and how many nodes should be in each one?

27
00:01:28,830 --> 00:01:31,550
This is a question you'll come across a lot as you define

28
00:01:31,550 --> 00:01:34,350
neural networks to approach a variety of tasks.

29
00:01:34,350 --> 00:01:36,860
I usually start by looking at any papers or

30
00:01:36,860 --> 00:01:39,755
related work I can find that may act as a good guide.

31
00:01:39,755 --> 00:01:43,260
In this case, I would search for MLP for MNIST,

32
00:01:43,260 --> 00:01:44,360
or even more generally,

33
00:01:44,360 --> 00:01:47,215
MLP for classifying small greyscale images.

34
00:01:47,215 --> 00:01:49,670
Next, I'm going to ask you to perform a search like

35
00:01:49,670 --> 00:01:51,800
this and see if you can find a good place to

36
00:01:51,800 --> 00:01:56,440
start when it comes to defining the hidden layers of an MLP for image classification.

