1
00:00:00,000 --> 00:00:02,395
在上个视频中

2
00:00:02,395 --> 00:00:07,153
我们使用 MLP 来解码手写数字图像

3
00:00:07,152 --> 00:00:10,119
在向 MLP 提供灰度图像之前

4
00:00:10,118 --> 00:00:13,750
我们首先需要将其矩阵转换为向量

5
00:00:13,750 --> 00:00:18,969
然后将此向量输入到具有两个隐藏层的 MLP 中

6
00:00:18,969 --> 00:00:24,320
我们发现该模型非常适合分类 MNIST 数据集中的图像

7
00:00:24,320 --> 00:00:28,804
实际上 测试图像的误差低于 2%

8
00:00:28,803 --> 00:00:32,024
但是对于其他图像分类问题

9
00:00:32,024 --> 00:00:33,990
我们可能需要分析更复杂的现实图像

10
00:00:33,990 --> 00:00:38,075
这些图像的规律更复杂

11
00:00:38,075 --> 00:00:39,939
我们需要采用其他技巧

12
00:00:39,939 --> 00:00:44,070
在此视频中 在构建和定义 CNN 时

13
00:00:44,070 --> 00:00:48,060
我们做出了一些改进 并消除了

14
00:00:48,060 --> 00:00:53,439
在用 MLP 进行图像分类时遇到的一些不足和限制情况

15
00:00:53,439 --> 00:00:57,090
具体而言 我们将调整两个重要问题

16
00:00:57,090 --> 00:01:02,545
首先 我们看到 MLP 使用了很多参数

17
00:01:02,545 --> 00:01:04,890
上个视频中的 MLP

18
00:01:04,890 --> 00:01:08,700
处理的是非常小的 28 x 28 图像

19
00:01:08,700 --> 00:01:12,509
就已经包含了超过 50 万的参数

20
00:01:12,509 --> 00:01:15,810
可以想象即使是中等大小的图像

21
00:01:15,810 --> 00:01:21,609
计算复杂程度也会很快就失控

22
00:01:21,608 --> 00:01:25,158
另一个问题是当我们将图像矩阵展平为向量时

23
00:01:25,159 --> 00:01:31,094
丢失了图像中包含的所有二维信息

24
00:01:31,093 --> 00:01:34,399
这种空间信息或

25
00:01:34,400 --> 00:01:38,224
像素相互之间的位置信息

26
00:01:38,224 --> 00:01:41,299
可以帮助我们理解图像

27
00:01:41,299 --> 00:01:47,000
并非常有助于发现像素值中包含的规律

28
00:01:47,000 --> 00:01:51,745
这表明我们需要一种全新的方式来处理图像输入

29
00:01:51,745 --> 00:01:56,055
这样才不会完全丢失二维信息

30
00:01:56,055 --> 00:02:01,685
CNN 将通过使用更加稀疏互联的层级来解决这些问题

31
00:02:01,685 --> 00:02:04,129
层级之间的连接

32
00:02:04,129 --> 00:02:08,419
由图像矩阵的二维结构确定

33
00:02:08,419 --> 00:02:12,800
此外 CNN 将接受矩阵输入

34
00:02:12,800 --> 00:02:19,610
假设有个 4x4 的手写数字图像小例子

35
00:02:19,610 --> 00:02:21,335
我们的目标保持不变

36
00:02:21,335 --> 00:02:25,909
我们想要对图像中的数字进行分类

37
00:02:25,907 --> 00:02:31,113
将 4x4 的矩阵转换为 16 维向量后

38
00:02:31,115 --> 00:02:35,840
我们可以将向量当做输入提供给 MLP

39
00:02:35,840 --> 00:02:40,604
我们构建一个具有一个隐藏层（四个节点）的 MLP

40
00:02:40,604 --> 00:02:44,168
输出层有 10 个节点

41
00:02:44,169 --> 00:02:48,044
和上个视频中的 MLP 一样

42
00:02:48,044 --> 00:02:53,770
输出有一个 softmax 激活函数并返回一个十维向量

43
00:02:53,770 --> 00:02:56,740
包含图像描述的 0 到 9 数字

44
00:02:56,740 --> 00:03:00,564
每个数字的可能概率

45
00:03:00,562 --> 00:03:02,377
如果对模型训练的很好

46
00:03:02,377 --> 00:03:07,839
向量将预测图像中的数字为 7 的概率很高

47
00:03:07,840 --> 00:03:10,840
但是我们对此图处理下

48
00:03:10,840 --> 00:03:15,074
将详细的描绘替换为建议的输出层

49
00:03:15,074 --> 00:03:18,594
这里 包含“it's a 7!”的方框

50
00:03:18,592 --> 00:03:23,662
是描绘 7 的输出层的快捷记法

51
00:03:23,663 --> 00:03:25,329
直接看下这个 MLP

52
00:03:25,330 --> 00:03:29,284
就很清楚可能存在多余的内容

53
00:03:29,282 --> 00:03:36,063
每个隐藏节点都需要与原始图像中的每个像素相连吗？

54
00:03:36,063 --> 00:03:40,467
或许不需要 可以将图像分成四个区域

55
00:03:40,467 --> 00:03:42,937
用红色 绿色

56
00:03:42,937 --> 00:03:45,627
黄色和蓝色表示

57
00:03:45,627 --> 00:03:48,562
每个隐藏节点都可能

58
00:03:48,562 --> 00:03:52,185
仅与这四个区域中的某个区域的像素相连

59
00:03:52,185 --> 00:03:58,270
每个隐藏节点仅看到原始图像的四分之一

60
00:03:58,270 --> 00:04:01,794
对于刚才的完全连接层

61
00:04:01,794 --> 00:04:04,960
每个隐藏节点都需要

62
00:04:04,960 --> 00:04:09,305
同时了解整个图像

63
00:04:09,305 --> 00:04:12,400
现在 经过新的细分

64
00:04:12,400 --> 00:04:16,278
并将一小部分像素分配给不同的隐藏节点

65
00:04:16,278 --> 00:04:21,670
每个隐藏节点都发现图像四个区域之一存在的规律

66
00:04:21,670 --> 00:04:26,528
然后 每个隐藏节点依然向输出层汇报

67
00:04:26,528 --> 00:04:28,959
输出层将从每个区域单独发现的规律

68
00:04:28,959 --> 00:04:32,689
结合到一起

69
00:04:32,689 --> 00:04:36,694
这个所谓的局部连接层

70
00:04:36,694 --> 00:04:40,949
比密集连接层使用的参数少了很多

71
00:04:40,949 --> 00:04:43,910
更不容易过拟合

72
00:04:43,910 --> 00:04:48,754
并且真正的了解如何发现图像数据中包含的规律

73
00:04:48,754 --> 00:04:52,665
我们可以将每个向量重新排列成矩阵

74
00:04:52,665 --> 00:04:58,845
现在每层中的节点之间的关系更清晰

75
00:04:58,845 --> 00:05:01,430
我们可以扩展我们能够发现的规律数量

76
00:05:01,430 --> 00:05:04,040
同时依然利用

77
00:05:04,040 --> 00:05:07,490
二维结构选择性并谨慎地

78
00:05:07,490 --> 00:05:11,329
向模型增加权重 方法是引入更多隐藏节点

79
00:05:11,329 --> 00:05:18,050
每个节点依然只需分析图像中的一个小区域

80
00:05:18,050 --> 00:05:20,689
隐藏层中的红色节点

81
00:05:20,689 --> 00:05:23,884
依然只与输出层中的红色节点相连

82
00:05:23,884 --> 00:05:28,220
其他所有颜色也同样

83
00:05:28,220 --> 00:05:33,810
毕竟在看了之前关于神经网络的视频后 我们发现

84
00:05:33,810 --> 00:05:39,694
通过增加隐藏层中的节点数量 我们能够从数据中发现更复杂的规律

85
00:05:39,694 --> 00:05:43,870
我们现在拥有两组隐藏节点

86
00:05:43,870 --> 00:05:49,384
每组包含的节点都负责检查图像的不同区域

87
00:05:49,384 --> 00:05:52,360
事实证明让一组中的每个隐藏节点

88
00:05:52,360 --> 00:05:55,680
都具有共同的权重很有用

89
00:05:55,680 --> 00:05:58,269
原理是图像中的不同区域

90
00:05:58,269 --> 00:06:01,774
可能会具有相同种类的信息

91
00:06:01,774 --> 00:06:05,394
换句话说 每个有助于理解图像的规律

92
00:06:05,394 --> 00:06:09,800
都可能出现在图像的某个位置

93
00:06:09,800 --> 00:06:14,485
了解这一参数共享模式可以如何帮助神经网络

94
00:06:14,485 --> 00:06:21,329
分类对象的最简单方式是查看一个高分辨率图像示例

95
00:06:21,329 --> 00:06:22,720
假设有一个图像

96
00:06:22,720 --> 00:06:26,689
你想要网络表示它是一个包含猫咪的图像

97
00:06:26,689 --> 00:06:28,610
无论猫在何处

98
00:06:28,610 --> 00:06:31,329
依然是含有猫的图像

99
00:06:31,329 --> 00:06:33,430
如果网络需要单独了解在左上角

100
00:06:33,430 --> 00:06:37,348
和右上角的猫咪

101
00:06:37,348 --> 00:06:39,829
那么工作量会很大

102
00:06:39,829 --> 00:06:44,560
相反 我们明确告诉网络无论对象位于左边还是右边

103
00:06:44,560 --> 00:06:49,735
对象和图像都基本一样

104
00:06:49,735 --> 00:06:53,454
通过权重共享可以部分实现这一效果

105
00:06:53,454 --> 00:06:58,314
所有这些理论都朝着卷积层发展

106
00:06:58,314 --> 00:07:01,730
我们将在下个视频中介绍卷积层

