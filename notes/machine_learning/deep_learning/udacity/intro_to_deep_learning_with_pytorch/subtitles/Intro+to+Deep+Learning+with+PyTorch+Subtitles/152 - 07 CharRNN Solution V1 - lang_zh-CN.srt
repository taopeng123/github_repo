1
00:00:00,000 --> 00:00:04,510
我们想要定义一个字符 RNN 它有两个 LSTM 层级

2
00:00:04,510 --> 00:00:07,200
在我的解决答案中 我在 GPU 上运行代码

3
00:00:07,200 --> 00:00:11,275
下面说说我是如何定义字符级 RNN 的

4
00:00:11,275 --> 00:00:15,255
首先定义一个 LSTM 层级 self.lstm

5
00:00:15,255 --> 00:00:17,020
第一个参数是输入大小

6
00:00:17,020 --> 00:00:18,555
该大小是独热编码的

7
00:00:18,555 --> 00:00:20,700
输入字符的长度

8
00:00:20,700 --> 00:00:23,365
也就是所有唯一字符的长度

9
00:00:23,365 --> 00:00:25,940
后面的参数是隐藏维度

10
00:00:25,940 --> 00:00:29,030
层级数量以及指定的丢弃概率

11
00:00:29,030 --> 00:00:33,685
此参数将在多个 LSTM 层级之间创建丢弃层

12
00:00:33,685 --> 00:00:36,335
在创建 RNN 时 会将所有这些参数

13
00:00:36,335 --> 00:00:39,190
传入该 RNN 中

14
00:00:39,190 --> 00:00:43,340
将 batch_first 设为 True 因为在创建批次数据时

15
00:00:43,340 --> 00:00:45,270
第一个维度是批次大小

16
00:00:45,270 --> 00:00:47,215
而不是序列长度

17
00:00:47,215 --> 00:00:49,835
Ok接下来 我在 LSTM 和最终线性层级之间

18
00:00:49,835 --> 00:00:52,940
定义了丢弃层

19
00:00:52,940 --> 00:00:56,510
接着是 fc 即最终全连接线性层级

20
00:00:56,510 --> 00:00:59,120
它的参数是 LSTM 输入

21
00:00:59,120 --> 00:01:01,045
维度是 n_hidden

22
00:01:01,045 --> 00:01:05,555
输出最有可能的下个字符的字符类别分数

23
00:01:05,555 --> 00:01:08,970
这些是每个潜在下个字符的类别分数

24
00:01:08,970 --> 00:01:11,480
这个输出大小和输入大小一样

25
00:01:11,480 --> 00:01:13,605
即字符词汇表的长度

26
00:01:13,605 --> 00:01:15,935
然后是 forward 函数

27
00:01:15,935 --> 00:01:20,275
向这里的 LSTM 层级传入输入 x 和隐藏状态

28
00:01:20,275 --> 00:01:23,810
生成 LSTM 输出和新的隐藏状态

29
00:01:23,810 --> 00:01:26,270
将 LSTM 输出

30
00:01:26,270 --> 00:01:29,120
传入在这里定义的丢弃层并获得新的输出

31
00:01:29,120 --> 00:01:31,345
然后变形此输出

32
00:01:31,345 --> 00:01:33,845
使最后一个维度是隐藏维度

33
00:01:33,845 --> 00:01:38,610
这个 -1 表示我将堆叠 LSTM 的输出

34
00:01:38,610 --> 00:01:42,735
最后 将这个变形后的输出传入最终全连接层

35
00:01:42,735 --> 00:01:45,080
然后返回此最终输出

36
00:01:45,080 --> 00:01:47,595
以及 LSTM 生成的隐藏状态

37
00:01:47,595 --> 00:01:51,915
这两个函数以及 init_hidden 函数构成了我的模型

38
00:01:51,915 --> 00:01:57,475
接下来训练模型 我们看看提供的训练循环

39
00:01:57,475 --> 00:02:00,740
这个函数的参数是要训练的模型、数据

40
00:02:00,740 --> 00:02:02,320
训练周期数

41
00:02:02,320 --> 00:02:03,650
以及定义迷你批次大小的

42
00:02:03,650 --> 00:02:06,330
批次大小和序列长度

43
00:02:06,330 --> 00:02:09,140
还有其他几个训练参数

44
00:02:09,140 --> 00:02:13,140
首先在这里定义优化器和损失函数

45
00:02:13,140 --> 00:02:16,055
优化器是标准 Adam 优化器

46
00:02:16,055 --> 00:02:19,070
学习速率设为在这里传入的学习速率

47
00:02:19,070 --> 00:02:21,360
最后一个函数是交叉熵损失

48
00:02:21,360 --> 00:02:24,775
用于输出字符类别分数

49
00:02:24,775 --> 00:02:26,960
这部分代码用于创建验证数据

50
00:02:26,960 --> 00:02:31,105
并将模型移到 GPU 上（如果有）

51
00:02:31,105 --> 00:02:33,775
这是周期循环的开头

52
00:02:33,775 --> 00:02:35,460
在每个周期开始时 

53
00:02:35,460 --> 00:02:38,255
我将初始化 LSTM 的隐藏状态

54
00:02:38,255 --> 00:02:41,750
参数是数据的批次大小 用于定义隐藏状态的大小

55
00:02:41,750 --> 00:02:45,970
返回全为 0 的隐藏单元状态

56
00:02:45,970 --> 00:02:47,695
在此周期循环里

57
00:02:47,695 --> 00:02:49,105
是批次循环

58
00:02:49,105 --> 00:02:53,335
从 get_batches 生成器中获取 x y 迷你批次

59
00:02:53,335 --> 00:02:57,090
此函数会遍历编码数据

60
00:02:57,090 --> 00:02:59,810
并返回批次输入 x 和目标 y

61
00:02:59,810 --> 00:03:04,390
然后将输入转换为独热编码表示法

62
00:03:04,390 --> 00:03:06,925
将输入 x 和目标 y 转换为

63
00:03:06,925 --> 00:03:10,335
能够传入模型中的张量

64
00:03:10,335 --> 00:03:14,920
如果有 GPU 则将这些输入和目标转移到 GPU 设备上

65
00:03:14,920 --> 00:03:17,875
下一步是确保将传入的隐藏状态

66
00:03:17,875 --> 00:03:20,590
与其历史记录分离

67
00:03:20,590 --> 00:03:23,530
LSTM 层级的隐藏状态是一个元组

68
00:03:23,530 --> 00:03:25,630
所以这里的数据是元组

69
00:03:25,630 --> 00:03:28,815
然后执行反向传播

70
00:03:28,815 --> 00:03:34,615
清零积累的梯度并将输入张量传入模型中

71
00:03:34,615 --> 00:03:37,090
并且在这里传入最新的隐藏状态

72
00:03:37,090 --> 00:03:40,820
返回最终输出和新的隐藏状态

73
00:03:40,820 --> 00:03:44,885
然后查看预测输出和目标并计算损失

74
00:03:44,885 --> 00:03:47,420
在模型的 forward 函数中

75
00:03:47,420 --> 00:03:52,460
我将 LSTM 输出的批次大小和序列长度变成了一个维度

76
00:03:52,460 --> 00:03:55,150
在这里也针对目标执行相同的处理流程

77
00:03:55,150 --> 00:03:57,575
然后进行反向传播

78
00:03:57,575 --> 00:04:00,690
朝着右侧方向移动一个步长并更新网络权重

79
00:04:00,690 --> 00:04:02,420
在优化步骤之前

80
00:04:02,420 --> 00:04:05,045
我添加了一行新的代码

81
00:04:05,045 --> 00:04:07,105
即调用 clip_grad_norm_

82
00:04:07,105 --> 00:04:10,970
这种 LSTM 模型在梯度方面有一个主要问题

83
00:04:10,970 --> 00:04:13,220
梯度可能会爆炸并变得非常非常大

84
00:04:13,220 --> 00:04:15,490
因此我们可以截断梯度

85
00:04:15,490 --> 00:04:17,570
设置一个截断阈值

86
00:04:17,570 --> 00:04:20,305
如果梯度大于该阈值

87
00:04:20,305 --> 00:04:22,530
则将梯度设为该截断阈值

88
00:04:22,530 --> 00:04:24,530
在这里 我们只需传入参数

89
00:04:24,530 --> 00:04:27,840
以及梯度截断阈值

90
00:04:27,840 --> 00:04:29,990
我们已经在 train 函数中

91
00:04:29,990 --> 00:04:32,485
传入这个值 值为 5

92
00:04:32,485 --> 00:04:34,205
执行反向传播步骤后

93
00:04:34,205 --> 00:04:35,510
截断梯度

94
00:04:35,510 --> 00:04:37,520
执行优化步骤

95
00:04:37,520 --> 00:04:40,445
最后对验证数据执行很相似的流程

96
00:04:40,445 --> 00:04:43,860
但是不执行反向传播步骤

97
00:04:43,860 --> 00:04:46,900
然后输出损失值

98
00:04:46,900 --> 00:04:48,955
定义好 train 函数后

99
00:04:48,955 --> 00:04:51,740
实例化并训练模型

100
00:04:51,740 --> 00:04:53,275
在练习 notebook 中

101
00:04:53,275 --> 00:04:55,930
你需要定义这些超参数

102
00:04:55,930 --> 00:05:00,660
我将隐藏维度设为 512

103
00:05:00,660 --> 00:05:02,040
并将层数设为 2

104
00:05:02,040 --> 00:05:04,520
然后实例化模型并输出该模型

105
00:05:04,520 --> 00:05:07,580
可以看出输入有 83 个唯一字符

106
00:05:07,580 --> 00:05:09,290
隐藏维度是 512

107
00:05:09,290 --> 00:05:11,420
有两个 LSTM 层级

108
00:05:11,420 --> 00:05:12,800
对于丢弃层

109
00:05:12,800 --> 00:05:17,855
默认丢弃概率是 0.5 对于最终全连接层

110
00:05:17,855 --> 00:05:19,055
参数包括输入特征数

111
00:05:19,055 --> 00:05:22,195
它和这个隐藏维度一样 然后是输出特征数

112
00:05:22,195 --> 00:05:23,610
等于字符数

113
00:05:23,610 --> 00:05:26,210
其他超参数包括

114
00:05:26,210 --> 00:05:29,565
批次大小、序列长度和训练周期数

115
00:05:29,565 --> 00:05:31,845
我将序列长度设为 100

116
00:05:31,845 --> 00:05:33,365
包含很多字符

117
00:05:33,365 --> 00:05:36,740
但是为模型提供了大量上下文信息

118
00:05:36,740 --> 00:05:39,020
注意 隐藏维度是

119
00:05:39,020 --> 00:05:41,840
模型能够检测的特征数量

120
00:05:41,840 --> 00:05:46,190
更大的值使网络能够学习更多文本特征

121
00:05:46,190 --> 00:05:50,830
下面还有更多定义超参数的信息

122
00:05:50,830 --> 00:05:55,050
通常 我会以这样的大型模型开始

123
00:05:55,050 --> 00:05:58,105
有多个 LSTM 层级和很大的隐藏维度

124
00:05:58,105 --> 00:06:01,115
然后看看模型的训练损失

125
00:06:01,115 --> 00:06:04,475
如果损失降低了 则继续

126
00:06:04,475 --> 00:06:06,285
如果不像预期得那样降低

127
00:06:06,285 --> 00:06:08,780
则更改某些超参数

128
00:06:08,780 --> 00:06:11,330
我们的文本数据很庞大

129
00:06:11,330 --> 00:06:14,930
我在 GPU 上训练整个模型 20 个周期

130
00:06:14,930 --> 00:06:19,300
可以看到训练和验证损失逐渐降低了

131
00:06:19,300 --> 00:06:23,430
在第 15 个周期左右 看到损失降低速度变慢了

132
00:06:23,430 --> 00:06:25,520
但是即使在第 20 个周期之后

133
00:06:25,520 --> 00:06:28,470
验证和训练损失还在降低

134
00:06:28,470 --> 00:06:31,810
还可以训练更长时间

135
00:06:31,810 --> 00:06:34,670
这部分是关于如何设置模型超参数

136
00:06:34,670 --> 00:06:38,135
以及获得最佳模型的信息 建议阅读一下

137
00:06:38,135 --> 00:06:40,760
然后 像我这样训练模型之后

138
00:06:40,760 --> 00:06:43,280
你可以保存模型并设定名称

139
00:06:43,280 --> 00:06:47,055
最后还有一步 使用模型做出预测并生成一些新的文本

140
00:06:47,055 --> 00:06:48,600
接下来我将讲解这方面的知识

