1
00:00:00,000 --> 00:00:02,790
So, recently, PyTorch has become pretty popular in

2
00:00:02,790 --> 00:00:07,050
the research community and I'm wondering if you think you know like why that is.

3
00:00:07,050 --> 00:00:13,860
True. I think it's again going back to how we built and traded on PyTorch.

4
00:00:13,860 --> 00:00:17,685
We gave it to a bunch of researchers and we took

5
00:00:17,685 --> 00:00:22,050
a rapid feedback from them and improve the product before it became mature.

6
00:00:22,050 --> 00:00:24,750
So, the core design of PyTorch is very,

7
00:00:24,750 --> 00:00:27,570
very researcher friendly by doing

8
00:00:27,570 --> 00:00:32,235
this reinforcement loop with researchers as we developed it.

9
00:00:32,235 --> 00:00:34,590
I think that is the main reason.

10
00:00:34,590 --> 00:00:38,925
It's very easy to do debugging.

11
00:00:38,925 --> 00:00:40,970
It's very Pythonic.

12
00:00:40,970 --> 00:00:46,985
If you know any of the popular Python machine learning or data science packages,

13
00:00:46,985 --> 00:00:48,710
it feels very natural that,

14
00:00:48,710 --> 00:00:51,110
the RBI looks very like numpy.

15
00:00:51,110 --> 00:00:56,635
So, I think that's the main thing that's been pulling researchers to PyTorch.

16
00:00:56,635 --> 00:01:02,855
Yeah. So, it sounds like PyTorch is designed with users and just their feedback in mind.

17
00:01:02,855 --> 00:01:07,310
I think some other libraries that makes me think of like sometimes they're designed with

18
00:01:07,310 --> 00:01:12,040
scalability and production needs first rather than users and ease of use.

19
00:01:12,040 --> 00:01:15,840
So, I'm wondering if you could talk a bit about how PyTorch,

20
00:01:15,840 --> 00:01:17,820
especially in its latest version,

21
00:01:17,820 --> 00:01:22,790
does also add features that make it easier to deploy models to production.

22
00:01:22,790 --> 00:01:30,620
Sure. So, I think the fundamental concept that if you want to build a usable library,

23
00:01:30,620 --> 00:01:34,535
it is intention that production is I think not correct.

24
00:01:34,535 --> 00:01:38,460
What happens is people from day one,

25
00:01:38,460 --> 00:01:40,610
if they put a focus on production,

26
00:01:40,610 --> 00:01:45,125
they don't need to make the library usable as well as,

27
00:01:45,125 --> 00:01:50,790
which means that it becomes like fairly inflexible or like unusable.

28
00:01:50,790 --> 00:01:53,670
So, with PyTorch 1.0,

29
00:01:53,670 --> 00:01:58,110
something that we did was we said you researchers,

30
00:01:58,110 --> 00:01:59,980
you want to do imperative code,

31
00:01:59,980 --> 00:02:01,415
all of that is great.

32
00:02:01,415 --> 00:02:03,050
It all works out very well.

33
00:02:03,050 --> 00:02:07,080
But if you want, unlike the code,

34
00:02:07,080 --> 00:02:14,135
PyTorch 0.4, it scaled up to hundreds of GPUs of pilot training.

35
00:02:14,135 --> 00:02:17,660
What we mean by production is you want

36
00:02:17,660 --> 00:02:20,810
to export your whole model and do like a C plus plus

37
00:02:20,810 --> 00:02:24,320
runtime or you want to run things like you'd

38
00:02:24,320 --> 00:02:28,100
take your network and quantize it and start running into the 32-bit,

39
00:02:28,100 --> 00:02:30,740
you want to run it at eight bits or four bytes.

40
00:02:30,740 --> 00:02:32,495
That kind of stuff,

41
00:02:32,495 --> 00:02:37,700
what we built PyTorch or when we could schedule

42
00:02:37,700 --> 00:02:42,980
for production is you do your research but when you want it to be production ready,

43
00:02:42,980 --> 00:02:46,010
you just add function annotations to

44
00:02:46,010 --> 00:02:51,005
your model which are like these one-liners that are top of a function.

45
00:02:51,005 --> 00:02:54,050
Then, PyTorch will parse your model,

46
00:02:54,050 --> 00:02:55,820
your Python program itself,

47
00:02:55,820 --> 00:03:02,050
and then make it into our own internal format that can be shipped to production.

48
00:03:02,050 --> 00:03:06,554
So, its kind of converting all of your Python code into,

49
00:03:06,554 --> 00:03:09,050
is it C plus plus code or just sort of an intermediate representation?

50
00:03:09,050 --> 00:03:14,730
It's an intermediate representation that can be run in C plus plus.

51
00:03:14,730 --> 00:03:16,019
We provide an interpreter,

52
00:03:16,019 --> 00:03:17,480
the C plus plus only.

53
00:03:17,480 --> 00:03:20,375
But anyone can take that IR,

54
00:03:20,375 --> 00:03:23,720
which is called intermediate representation and then they can run it

55
00:03:23,720 --> 00:03:27,520
in their own virtual machine that they've built for themselves.

56
00:03:27,520 --> 00:03:29,330
That's great. I mean, it kind of makes me think of,

57
00:03:29,330 --> 00:03:32,840
if someone writes a Word document or something and pages and you just export

58
00:03:32,840 --> 00:03:36,470
it to PDF and then if you have is like you can send it anywhere and anyone can read it.

59
00:03:36,470 --> 00:03:37,280
Exactly.

60
00:03:37,280 --> 00:03:41,720
So, when you are moving in between say like

61
00:03:41,720 --> 00:03:46,280
a model you've written in PyTorch and Python and an intermediate representation.

62
00:03:46,280 --> 00:03:48,320
See there is a bug in there,

63
00:03:48,320 --> 00:03:52,170
what will happen if you try to

64
00:03:52,170 --> 00:03:56,060
debug with intermediate representation or is that something you don't ever want to do?

65
00:03:56,060 --> 00:03:58,595
So, you don't ever have to do that.

66
00:03:58,595 --> 00:04:02,270
So, what happens is you're building your model,

67
00:04:02,270 --> 00:04:06,490
you add your function annotation as an,

68
00:04:06,490 --> 00:04:08,345
it's just optional, it's there,

69
00:04:08,345 --> 00:04:11,050
but you can disable it whenever you want.

70
00:04:11,050 --> 00:04:14,140
Either you can comment out the function annotation or you can have

71
00:04:14,140 --> 00:04:19,405
a global variable that says like switch off all compilation.

72
00:04:19,405 --> 00:04:25,945
So, it's like 90 percent of the time when you're doing experimentation and research,

73
00:04:25,945 --> 00:04:28,840
you're adjusting your irregular patronage mode.

74
00:04:28,840 --> 00:04:32,915
But then when you decide "This model is super solid,

75
00:04:32,915 --> 00:04:37,090
I've like very trustworthy of this thing.

76
00:04:37,090 --> 00:04:38,620
It's been around for a while.

77
00:04:38,620 --> 00:04:40,115
I want to ship it to production."

78
00:04:40,115 --> 00:04:42,730
You add function annotations and it becomes

79
00:04:42,730 --> 00:04:47,380
this magical black box that you don't usually need to touch.

80
00:04:47,380 --> 00:04:50,190
But if you, again, want to experiment with it,

81
00:04:50,190 --> 00:04:51,750
you just remove the annotations.

82
00:04:51,750 --> 00:04:56,700
Okay. So, experimentation, prototyping and the Python and PyTorch that we know and love.

83
00:04:56,700 --> 00:04:58,715
Then, once everything's look good to go,

84
00:04:58,715 --> 00:05:01,560
you can export it using annotations.

