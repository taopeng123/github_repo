1
00:00:00,186 --> 00:00:04,113
Mostrarei rapidamente como
definir e treinar a MLP

2
00:00:04,146 --> 00:00:05,614
de classificação de imagem.

3
00:00:05,647 --> 00:00:09,588
Primeiro eu carreguei e observei
os dados de imagem,

4
00:00:09,621 --> 00:00:12,511
depois defini
o modelo de classificação.

5
00:00:12,544 --> 00:00:15,303
Comecei com a camada
completamente conectada, fc1,

6
00:00:15,336 --> 00:00:18,271
que observa o vetor
com tamanho igual a 784,

7
00:00:18,304 --> 00:00:20,790
que representa
uma imagem achatada como input.

8
00:00:20,823 --> 00:00:23,336
Depois, segui a partir do recurso
que encontrei,

9
00:00:23,369 --> 00:00:27,255
que tinha duas camadas ocultas
com 512 inputs e outputs.

10
00:00:27,288 --> 00:00:30,136
Eu armazenei os valores aqui
como duas variáveis,

11
00:00:30,169 --> 00:00:31,855
hidden_1 e hidden_2.

12
00:00:31,888 --> 00:00:35,310
Este é um passo extra, mas facilita
na hora de alterar os valores

13
00:00:35,343 --> 00:00:37,495
para testar
ou coisa do gênero.

14
00:00:37,528 --> 00:00:39,925
Para completar
a primeira camada conectada,

15
00:00:39,958 --> 00:00:43,324
coloquei hidden_1 como
a quantidade de outputs desejada.

16
00:00:43,357 --> 00:00:46,529
Depois criei uma segunda
camada completamente conectada, fc2,

17
00:00:46,562 --> 00:00:51,183
que pega os outputs
e produz 512 outputs novamente.

18
00:00:51,216 --> 00:00:54,069
Também quero que os outputs
de uma camada

19
00:00:54,102 --> 00:00:56,320
sejam os inputs da próxima.

20
00:00:56,353 --> 00:00:59,524
Depois defini a última
camada completamente conectada, fc3,

21
00:00:59,557 --> 00:01:03,724
para que ela veja os 512 inputs
e produza 10 outputs.

22
00:01:03,757 --> 00:01:07,101
Os 10 outputs correspondem
à quantidade de classes,

23
00:01:07,134 --> 00:01:08,581
de 0 a 9.

24
00:01:08,614 --> 00:01:11,309
Essa camada produzirá
as pontuações de classe.

25
00:01:11,342 --> 00:01:15,052
Por fim, ainda na função init,
defini uma camada dropout,

26
00:01:15,085 --> 00:01:18,804
com a probabilidade dropout
de 0,2 ou de 20%.

27
00:01:18,837 --> 00:01:21,140
Agora que defini as camadas
necessárias

28
00:01:21,173 --> 00:01:23,241
para criar a MLP
de classificação,

29
00:01:23,274 --> 00:01:26,852
preciso definir o comportamento
feedforward da rede.

30
00:01:26,885 --> 00:01:29,325
Com a função forward,
quero responder

31
00:01:29,358 --> 00:01:32,355
como um vetor de entrada
procederá pelas camadas.

32
00:01:32,388 --> 00:01:36,549
O input X começa
como um tensor de imagem de 28x28.

33
00:01:36,582 --> 00:01:40,517
O primeiro passo é achatar
em um vetor de 784.

34
00:01:40,550 --> 00:01:45,093
Depois disso, passarei na primeira
camada completamente conectada, fc1,

35
00:01:45,126 --> 00:01:47,549
aplicando
a função de ativação.

36
00:01:47,582 --> 00:01:49,604
A seguir, farei
exatamente o mesmo

37
00:01:49,637 --> 00:01:52,365
com a segunda camada
completamente conectada, fc2.

38
00:01:52,398 --> 00:01:55,461
Entre as duas camadas,
adiciono uma camada dropout,

39
00:01:55,494 --> 00:01:57,837
que evita o sobreajuste.

40
00:01:57,870 --> 00:02:00,061
Após X passar
na segunda camada oculta,

41
00:02:00,094 --> 00:02:01,925
adicionamos
mais uma camada dropout

42
00:02:01,958 --> 00:02:04,356
à última camada
completamente conectada.

43
00:02:04,389 --> 00:02:07,029
Perceba que não apliquei
uma função de ativação

44
00:02:07,062 --> 00:02:08,284
à camada final,

45
00:02:08,317 --> 00:02:12,387
isso porque ela terá
uma função de ativação softmax,

46
00:02:12,420 --> 00:02:14,524
então eu deixarei como está,

47
00:02:14,557 --> 00:02:17,660
retornando o X transformado.

48
00:02:17,693 --> 00:02:20,180
Como fc3 produz 10 outputs,

49
00:02:20,213 --> 00:02:23,212
o X deve representar
as pontuações de 10 classes.

50
00:02:23,245 --> 00:02:26,654
Depois instancio
e imprimo a rede

51
00:02:26,687 --> 00:02:28,755
para que ela tenha
a camadas desejadas.

52
00:02:28,788 --> 00:02:31,709
Vemos as três camadas
lineares e a de dropout.

53
00:02:31,742 --> 00:02:35,315
O próximo passo é definir as funções
de perda e de otimização.

54
00:02:35,348 --> 00:02:38,795
Aqui defini o critério de perda
como CrossEntropyLoss.

55
00:02:38,828 --> 00:02:42,310
Esta é uma perda padrão
para a tarefa de classificação.

56
00:02:42,343 --> 00:02:45,412
Usarei o gradiente descendente
estocástico, SGD,

57
00:02:45,445 --> 00:02:47,580
da biblioteca
de otimização Torch.

58
00:02:47,613 --> 00:02:50,829
Isso usa os parâmetros do modelo
e uma taxa de aprendizado.

59
00:02:50,862 --> 00:02:53,282
Configurei a taxa como 0.01.

60
00:02:53,315 --> 00:02:56,707
Se a perda estiver diminuindo
devagar demais ou esporadicamente,

61
00:02:56,740 --> 00:02:58,179
mudamos este valor.

62
00:02:58,212 --> 00:03:02,115
Eu treinei este modelo
por 50 epochs.

63
00:03:02,148 --> 00:03:04,976
Isso levou um tempo,
pois só estou usando a CPU,

64
00:03:05,009 --> 00:03:08,311
mas mostrarei depois como usar
a GPU para treinar mais rápido.

65
00:03:08,344 --> 00:03:11,089
Ao fim de cada epoch,
imprimi a perda de treinamento

66
00:03:11,122 --> 00:03:13,811
para ver como ela diminuiu
com o passar do tempo.

67
00:03:13,844 --> 00:03:16,200
Houve uma rápida diminuição
no início,

68
00:03:16,233 --> 00:03:21,617
mas fica mais devagar,
especialmente perto da epoch 40.

69
00:03:21,650 --> 00:03:24,861
Isso continua diminuindo
até a epoch 50.

70
00:03:24,894 --> 00:03:28,828
Para ver como meu modelo
generaliza para os novos dados,

71
00:03:28,861 --> 00:03:32,276
eu testo com os dados de teste
que carregamos no início.

72
00:03:32,309 --> 00:03:35,205
Iterei os dados
do test_loader,

73
00:03:35,238 --> 00:03:38,412
apliquei o modelo
e gravei a perda de teste.

74
00:03:38,445 --> 00:03:42,164
Um modelo retorna
uma lista de pontuações de classe.

75
00:03:42,197 --> 00:03:46,692
Até eu prever a classe,
usarei o valor máximo das pontuações

76
00:03:46,725 --> 00:03:48,472
e retornarei uma previsão.

77
00:03:48,505 --> 00:03:51,884
Depois comparo a previsão
com o rótulo que queremos.

78
00:03:51,917 --> 00:03:55,339
Isso cria uma lista dizendo
se a previsão está correta ou não.

79
00:03:55,372 --> 00:04:01,148
Separei isto entre as 10 classes
e imprimi a precisão de cada uma.

80
00:04:01,181 --> 00:04:04,331
Tenho a perda geral do teste
e a precisão geral,

81
00:04:04,364 --> 00:04:06,179
que é de 97%.

82
00:04:06,212 --> 00:04:09,074
Isso é bom. Vemos que,
entre as classes,

83
00:04:09,107 --> 00:04:10,925
o valor é bem consistente.

84
00:04:10,958 --> 00:04:14,626
O modelo se saiu pior em imagens
com o número 7 ou 8,

85
00:04:14,659 --> 00:04:18,004
mas a distribuição demonstra
que o modelo foi bem treinado

86
00:04:18,037 --> 00:04:19,721
em cada tipo de dado.

87
00:04:19,754 --> 00:04:23,103
Também incluí uma célula na qual
podemos exibir imagens de teste

88
00:04:23,136 --> 00:04:25,674
e os rótulos previstos,
um do lado do outro.

89
00:04:25,707 --> 00:04:29,362
Assim fica fácil de ver
quando obtemos uma imagem errada.

90
00:04:29,395 --> 00:04:32,060
Observando
a precisão do teste,

91
00:04:32,093 --> 00:04:34,430
me pergunto se ele pode se sair
ainda melhor,

92
00:04:34,463 --> 00:04:37,262
se eu posso melhorar o modelo
adicionando outra camada

93
00:04:37,295 --> 00:04:39,209
que defina mais padrões
nos dados

94
00:04:39,242 --> 00:04:42,661
ou se eu escolhi o momento certo
de parar o treinamento?

95
00:04:42,694 --> 00:04:45,973
Na verdade, perceba que eu parei
o treinamento na epoch 50,

96
00:04:46,006 --> 00:04:49,357
a partir da minha expectativa
da diminuição da perda,

97
00:04:49,390 --> 00:04:51,837
mas é mais uma arte
do que uma ciência.

98
00:04:51,870 --> 00:04:54,441
A seguir, veremos
um método concreto

99
00:04:54,474 --> 00:04:56,271
para saber
quando parar de treinar,

100
00:04:56,304 --> 00:04:58,636
uma técnica chamada
de "validação de modelo".

