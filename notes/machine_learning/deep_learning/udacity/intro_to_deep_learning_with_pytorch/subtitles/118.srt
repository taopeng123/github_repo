1
00:00:00,000 --> 00:00:05,010
The job of a convolutional neural network is to discover patterns contained in an image.

2
00:00:05,010 --> 00:00:08,045
A sequence of layers is responsible for this discovery.

3
00:00:08,045 --> 00:00:11,610
The layers in a CNN convert an input image array into

4
00:00:11,610 --> 00:00:15,350
a representation that encodes only the content of the image.

5
00:00:15,350 --> 00:00:20,260
This is often called a feature level representation of an image or a feature vector.

6
00:00:20,260 --> 00:00:23,160
It may be helpful to think about it like this,

7
00:00:23,160 --> 00:00:26,400
take two input images that are both images of a car.

8
00:00:26,400 --> 00:00:27,570
Both are very different,

9
00:00:27,570 --> 00:00:29,130
and if I was to frame these pictures,

10
00:00:29,130 --> 00:00:31,975
the detail would be what makes them stylistically interesting.

11
00:00:31,975 --> 00:00:33,645
But for an image classifier,

12
00:00:33,645 --> 00:00:37,170
it only wants to know that these are both images of cars.

13
00:00:37,170 --> 00:00:39,780
When you look at how these images are transformed

14
00:00:39,780 --> 00:00:42,410
as they move through several layers of a CNN,

15
00:00:42,410 --> 00:00:45,780
the exact original pixel values matter less and less.

16
00:00:45,780 --> 00:00:50,510
The two transformed outputs should start to look much more similar to one another,

17
00:00:50,510 --> 00:00:52,640
moving closer towards the idea that both are

18
00:00:52,640 --> 00:00:56,225
a car rather than the details about what the cars look like.

19
00:00:56,225 --> 00:01:01,060
Later layers in a CNN have discarded information about style and texture,

20
00:01:01,060 --> 00:01:05,000
and instead are pushed towards answering questions about general shape,

21
00:01:05,000 --> 00:01:07,150
and about the presence of unique patterns,

22
00:01:07,150 --> 00:01:09,155
like, "Are there wheels in the image?

23
00:01:09,155 --> 00:01:10,395
Are there eyes in the image?

24
00:01:10,395 --> 00:01:12,400
What about three legs or tails?"

25
00:01:12,400 --> 00:01:14,420
Once we get to a representation where

26
00:01:14,420 --> 00:01:17,270
the content of an image has been distilled like this,

27
00:01:17,270 --> 00:01:20,390
we can flatten the array into a feature vector and feed it to

28
00:01:20,390 --> 00:01:25,455
one or more fully connected layers to determine what object is contained in the image.

29
00:01:25,455 --> 00:01:29,360
For instance, if wheels were found after the last max pooling layer,

30
00:01:29,360 --> 00:01:32,150
the feature vector will be able to reflect that.

31
00:01:32,150 --> 00:01:34,580
The fully connected layer will transform that information to

32
00:01:34,580 --> 00:01:38,290
predict that a car is present in the image with higher probability.

33
00:01:38,290 --> 00:01:40,870
If there were eyes, three legs, and a tail,

34
00:01:40,870 --> 00:01:43,430
then the output layer would take that information

35
00:01:43,430 --> 00:01:46,700
and deduce that a dog is likely present in the image.

36
00:01:46,700 --> 00:01:48,730
But of course, to emphasize,

37
00:01:48,730 --> 00:01:50,645
all this understanding in the model,

38
00:01:50,645 --> 00:01:52,790
is not pre-specified bias.

39
00:01:52,790 --> 00:01:56,945
It is learned by the model during training and through back-propagation that

40
00:01:56,945 --> 00:01:58,400
updates the weights that define

41
00:01:58,400 --> 00:02:01,320
the filters and the weights in the fully connected layers.

42
00:02:01,320 --> 00:02:04,010
This architecture that we're specifying here just

43
00:02:04,010 --> 00:02:06,800
gives the model a structure that will allow it to train better.

44
00:02:06,800 --> 00:02:10,750
So, it has the potential to classify objects with greater accuracy.

45
00:02:10,750 --> 00:02:15,660
Next, I'll show you how to start defining a CNN architecture for image classification,

46
00:02:15,660 --> 00:02:18,090
and you'll get to practice coding on your own.

