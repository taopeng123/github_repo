1
00:00:00,000 --> 00:00:02,190
我将快速介绍下

2
00:00:02,190 --> 00:00:05,545
如何定义和训练图像分类 MLP

3
00:00:05,545 --> 00:00:09,490
首先 我加载并查看了标准化图像输入

4
00:00:09,490 --> 00:00:12,750
然后开始定义分类模型

5
00:00:12,750 --> 00:00:15,930
首先是一个全连接层 fc1

6
00:00:15,930 --> 00:00:20,290
输入是长 784 的向量 表示扁平化的图像

7
00:00:20,290 --> 00:00:23,280
然后根据我搜到的资料继续创建该模型

8
00:00:23,280 --> 00:00:27,170
该模型有两个隐藏层 每层的输入和输出都是 512 个节点

9
00:00:27,170 --> 00:00:31,775
将这些值存储到 hidden_1 和 hidden_2 这两个变量中

10
00:00:31,775 --> 00:00:34,800
这是一个额外的步骤

11
00:00:34,800 --> 00:00:37,630
方便我后面轻松地更改这些值并进行测试

12
00:00:37,630 --> 00:00:39,979
要完成第一个全连接层

13
00:00:39,979 --> 00:00:43,245
我将输出数量设为 hidden_1

14
00:00:43,245 --> 00:00:46,425
然后创建第二个全连接层 fc2

15
00:00:46,425 --> 00:00:51,350
该层的输入是该输出数量 并再次生成 512 个输出值

16
00:00:51,350 --> 00:00:56,215
我还明确将一层的输出传入另一层

17
00:00:56,215 --> 00:00:59,480
然后定义最后一个全连接层 fc3

18
00:00:59,480 --> 00:01:03,670
该层获得 512 个输入值并生成 10 个输出值

19
00:01:03,670 --> 00:01:08,330
10 个输出对应的是从 0 到 9 的数字类别数量

20
00:01:08,330 --> 00:01:11,255
这层将生成类别分数

21
00:01:11,255 --> 00:01:13,400
最后 我在 init 函数里定义了丢弃层

22
00:01:13,400 --> 00:01:18,520
丢弃率是 0.2 (20%)

23
00:01:18,520 --> 00:01:23,330
定义好构成这个分类 MLP 的所有层级后

24
00:01:23,330 --> 00:01:26,695
还需要定义网络的前馈行为

25
00:01:26,695 --> 00:01:28,170
对于 forward 函数

26
00:01:28,170 --> 00:01:32,415
我希望设定输入向量经过这些层级的方式

27
00:01:32,415 --> 00:01:36,485
输入 x 一开始是一个 28x28 的图像张量

28
00:01:36,485 --> 00:01:40,335
我首先将该图像扁平化为长 784 的向量

29
00:01:40,335 --> 00:01:41,810
扁平化输入图像后

30
00:01:41,810 --> 00:01:44,280
将其传入第一个全连接层 fc1

31
00:01:44,280 --> 00:01:47,425
应用激活函数

32
00:01:47,425 --> 00:01:52,175
接下来对第二个全连接层 fc2 执行完全一样的操作

33
00:01:52,175 --> 00:01:53,855
但是在这两个层级之间

34
00:01:53,855 --> 00:01:57,725
我将添加丢弃层 以防止过拟合

35
00:01:57,725 --> 00:02:00,380
x 经过第二个隐藏层后

36
00:02:00,380 --> 00:02:04,370
再添加一个丢弃层 然后抵达最后的全连接层

37
00:02:04,370 --> 00:02:08,450
我没有向最终层级应用激活函数

38
00:02:08,450 --> 00:02:12,595
这是因为稍后我将应用 softmax 激活函数

39
00:02:12,595 --> 00:02:17,365
暂时保持不变并返回最终转换后的 x

40
00:02:17,365 --> 00:02:20,390
因为 fc3 生成了 10 个输出值

41
00:02:20,390 --> 00:02:23,245
所以这个 x 应该代表 10 个类别分数

42
00:02:23,245 --> 00:02:26,015
Ok然后实例化并输出网络

43
00:02:26,015 --> 00:02:28,850
检查是否包含我要的层级

44
00:02:28,850 --> 00:02:31,655
结果应该显示 3 个线性层级和丢弃层

45
00:02:31,655 --> 00:02:35,115
下一步是定义损失和优化函数

46
00:02:35,115 --> 00:02:38,780
我在这里将损失条件定义为交叉熵损失

47
00:02:38,780 --> 00:02:41,880
交叉熵是任何分类任务的标准损失函数

48
00:02:41,880 --> 00:02:44,675
然后我将使用 torch 优化库中的

49
00:02:44,675 --> 00:02:47,465
随机梯度下降法 (SGD)

50
00:02:47,465 --> 00:02:50,600
该函数的参数是模型参数和学习速率

51
00:02:50,600 --> 00:02:53,260
将学习速率设为 0.01

52
00:02:53,260 --> 00:02:56,745
如果你发现损失下降太慢或偶然下降

53
00:02:56,745 --> 00:02:58,165
可以更改此值

54
00:02:58,165 --> 00:03:02,050
然后训练此模型 50 个周期

55
00:03:02,050 --> 00:03:05,240
训练流程需要花费一段时间 因为我暂时只使用 CPU

56
00:03:05,240 --> 00:03:08,180
稍后我将演示如何使用 GPU 加快训练速度

57
00:03:08,180 --> 00:03:10,430
在每个周期结束时

58
00:03:10,430 --> 00:03:13,415
我都输出训练损失 观察它是如何逐渐降低的

59
00:03:13,415 --> 00:03:16,970
可以看出 损失一开始降低得很快

60
00:03:16,970 --> 00:03:21,240
然后减慢了 尤其是在 40 个周期左右

61
00:03:21,240 --> 00:03:24,520
但是在 50 个周期前依然会降低

62
00:03:24,520 --> 00:03:29,060
为了检测训练后的模型泛化到新数据的效果

63
00:03:29,060 --> 00:03:32,165
我用一开始加载的测试数据测试模型

64
00:03:32,165 --> 00:03:35,225
遍历测试加载器中的所有数据

65
00:03:35,225 --> 00:03:38,165
传入模型并记录测试损失

66
00:03:38,165 --> 00:03:42,140
模型返回的是类别分数列表

67
00:03:42,140 --> 00:03:43,835
为了分离出预测类别

68
00:03:43,835 --> 00:03:48,330
我将从这些分数中获取最大值并返回为预测值

69
00:03:48,330 --> 00:03:51,795
然后将此预测值与目标标签进行比较

70
00:03:51,795 --> 00:03:55,195
这样会生成一个列表 表示某个预测是否正确

71
00:03:55,195 --> 00:03:58,070
然后将它们分成 10 个类别

72
00:03:58,070 --> 00:04:00,740
并输出每个类别的准确率

73
00:04:00,740 --> 00:04:06,030
这是总体测试损失 这是总体准确率 准确率为 97%

74
00:04:06,030 --> 00:04:08,060
结果很不错

75
00:04:08,060 --> 00:04:10,695
可以看出在所有数字类别中 这个值很一致

76
00:04:10,695 --> 00:04:14,500
似乎对于数字 7 和 8 来说 模型的预测能力最差

77
00:04:14,500 --> 00:04:16,910
但是结果分布比较均匀

78
00:04:16,910 --> 00:04:19,755
表明模型均匀地使用每种类型的数据进行了训练

79
00:04:19,755 --> 00:04:21,130
我还添加了一个单元格

80
00:04:21,130 --> 00:04:25,534
你可以在其中显示测试图像 并排地显示预测标签和真实标签

81
00:04:25,534 --> 00:04:29,340
这样可以轻松地查看任何图像是否预测错了

82
00:04:29,340 --> 00:04:32,270
再看看总体测试准确率

83
00:04:32,270 --> 00:04:34,450
模型能否能表现地更好？

84
00:04:34,450 --> 00:04:36,500
例如能否通过添加另一个层级改善模型

85
00:04:36,500 --> 00:04:38,590
并发现数据中的更多规律

86
00:04:38,590 --> 00:04:42,740
我甚至在想 选择停止训练模型的时间点是否正确

87
00:04:42,740 --> 00:04:45,230
注意

88
00:04:45,230 --> 00:04:49,220
我只是凭感觉在 50 个周期时停止训练

89
00:04:49,220 --> 00:04:51,835
其实没有什么科学依据

90
00:04:51,835 --> 00:04:56,360
接下来我将介绍一种判断何时停止训练的具体方法

91
00:04:56,360 --> 00:04:58,730
这个技巧叫做模型验证

