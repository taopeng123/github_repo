1
00:00:00,000 --> 00:00:04,740
大家好！欢迎学习“深度学习工具 PyTorch”课程

2
00:00:04,740 --> 00:00:07,530
在这节课 我将演示

3
00:00:07,530 --> 00:00:11,400
如何使用 PyTorch 构建神经网络并训练网络

4
00:00:11,400 --> 00:00:14,220
在 notebook 里学习并练习完之后

5
00:00:14,220 --> 00:00:18,915
你将自己编写代码来构建网络

6
00:00:18,915 --> 00:00:21,795
这节课的目标是

7
00:00:21,795 --> 00:00:25,125
构建一个图像分类器

8
00:00:25,125 --> 00:00:27,060
但首先我们会学习基础知识

9
00:00:27,060 --> 00:00:31,605
那么 如何在 PyTorch 中构建一个简单的神经网络？

10
00:00:31,605 --> 00:00:34,905
回顾下神经网络的工作原理

11
00:00:34,905 --> 00:00:38,470
这里有一些输入值 例如 x1 x2

12
00:00:38,470 --> 00:00:43,460
我们用它们乘以权重 w 和偏差

13
00:00:43,460 --> 00:00:47,645
这个 b 表示偏差 我们乘以 1

14
00:00:47,645 --> 00:00:52,220
将这几个值相加得出 h 然后是激活函数

15
00:00:52,220 --> 00:00:54,875
即这里的 f(h)

16
00:00:54,875 --> 00:00:59,830
将这些输入值之和 h 传入激活函数 得出输出 y

17
00:00:59,830 --> 00:01:02,930
这就是神经网络的基本原理

18
00:01:02,930 --> 00:01:04,070
这些是输入

19
00:01:04,070 --> 00:01:06,125
乘以某些权重

20
00:01:06,125 --> 00:01:10,435
传入激活函数 得出输出

21
00:01:10,435 --> 00:01:13,880
你可以继续堆叠这个结构

22
00:01:13,880 --> 00:01:18,250
将这些单元（神经元）的输出传入采用另一组权重的另一个层级

23
00:01:18,250 --> 00:01:20,835
数学公式是这样的

24
00:01:20,835 --> 00:01:26,960
输出 y 等于权重 w 和输入值 x

25
00:01:26,960 --> 00:01:30,320
及偏差值 b 的线性组合

26
00:01:30,320 --> 00:01:34,070
然后放入激活函数 f 里并得出 y

27
00:01:34,070 --> 00:01:36,110
也可以写成这样的求和公式

28
00:01:36,110 --> 00:01:40,510
w^i 乘以 x^i 的和加上偏差项 b

29
00:01:40,510 --> 00:01:42,345
得出 y

30
00:01:42,345 --> 00:01:46,640
这个公式的好处是

31
00:01:46,640 --> 00:01:49,520
可以将输入特征（值）x 当做向量

32
00:01:49,520 --> 00:01:52,685
并将权重当做另一个向量

33
00:01:52,685 --> 00:01:58,800
因此这里的相乘求和与两个向量的点积/内积是相同的

34
00:01:58,800 --> 00:02:01,865
如果将输入和权重当做向量

35
00:02:01,865 --> 00:02:03,860
可以对这两个向量求点积

36
00:02:03,860 --> 00:02:06,785
然后得出值 h

37
00:02:06,785 --> 00:02:09,860
并将 h 传入激活函数里 得出输出 y

38
00:02:09,860 --> 00:02:16,430
现在我们将权重和输入值当做向量

39
00:02:16,430 --> 00:02:20,330
向量是一种张量

40
00:02:20,330 --> 00:02:24,350
张量是向量和矩阵的泛化形式

41
00:02:24,350 --> 00:02:27,950
这些是普通的数据结构

42
00:02:27,950 --> 00:02:32,285
一维张量是向量

43
00:02:32,285 --> 00:02:37,400
这是一个一维值数组

44
00:02:37,400 --> 00:02:42,665
这里是字符 ‘t’ ‘e’ ‘n’ ‘s’ ‘o’ ‘r’

45
00:02:42,665 --> 00:02:46,370
像这样的矩阵是二维张量

46
00:02:46,370 --> 00:02:48,830
这些值按从左到右和从上到下这两个方向排列

47
00:02:48,830 --> 00:02:51,620
它们分别是行和列

48
00:02:51,620 --> 00:02:54,500
你可以沿着一行对列执行操作

49
00:02:54,500 --> 00:02:58,490
或沿着一列对行执行操作

50
00:02:58,490 --> 00:03:01,745
这个是三维张量

51
00:03:01,745 --> 00:03:05,990
可以看做三维的 RGB 彩色图像

52
00:03:05,990 --> 00:03:07,370
对于每个像素

53
00:03:07,370 --> 00:03:10,490
所有的红绿蓝通道

54
00:03:10,490 --> 00:03:13,765
都有某个值

55
00:03:13,765 --> 00:03:15,630
因此在二维图像中

56
00:03:15,630 --> 00:03:17,070
每个像素都有三个值

57
00:03:17,070 --> 00:03:19,155
这就是三维张量

58
00:03:19,155 --> 00:03:21,800
正如我刚刚提到的 张量是一种泛化形式

59
00:03:21,800 --> 00:03:24,379
因此可以有四维

60
00:03:24,379 --> 00:03:27,710
五维 六维张量等等

61
00:03:27,710 --> 00:03:29,930
但是我们通常处理的是

62
00:03:29,930 --> 00:03:32,800
一维 二维和三维张量

63
00:03:32,800 --> 00:03:36,695
这些张量是

64
00:03:36,695 --> 00:03:40,715
pyTorch 和其他神经网络框架中的基本数据结构

65
00:03:40,715 --> 00:03:43,760
TensorFlow 就是根据张量命名的

66
00:03:43,760 --> 00:03:46,580
这些就是你要使用的基本数据结构

67
00:03:46,580 --> 00:03:49,520
你必须熟练掌握它们

68
00:03:49,520 --> 00:03:52,310
才能够使用

69
00:03:52,310 --> 00:03:55,865
深度学习框架

70
00:03:55,865 --> 00:03:59,690
我们开始吧我将演示如何创建张量

71
00:03:59,690 --> 00:04:03,605
并使用它们构建简单的神经网络

72
00:04:03,605 --> 00:04:07,565
首先 我们将导入 PyTorch 在这里输入 import torch

73
00:04:07,565 --> 00:04:09,770
我在这里创建了激活函数

74
00:04:09,770 --> 00:04:12,355
这是 S 型激活函数

75
00:04:12,355 --> 00:04:17,880
它是一个完美的 S 型图形 将输入值压缩到了 0 和 1 之间

76
00:04:17,880 --> 00:04:21,065
非常适合提供概率值

77
00:04:21,065 --> 00:04:25,195
概率值只能位于 0 到 1 之间

78
00:04:25,195 --> 00:04:27,770
因此 如果你希望

79
00:04:27,770 --> 00:04:30,560
神经网络的输出为概率

80
00:04:30,560 --> 00:04:33,060
则建议使用 S 型激活函数

81
00:04:33,060 --> 00:04:38,120
我将创建一些虚拟数据 生成一些权重和偏差

82
00:04:38,120 --> 00:04:41,240
你将使用这些虚拟值进行计算

83
00:04:41,240 --> 00:04:44,815
并获得简单神经网络的输出

84
00:04:44,815 --> 00:04:47,520
在这里创建 manual_seed()

85
00:04:47,520 --> 00:04:50,300
设置将要使用的随机数

86
00:04:50,300 --> 00:04:53,255
在这里创建特征

87
00:04:53,255 --> 00:04:57,605
特征是指网络的输入特征/输入数据

88
00:04:57,605 --> 00:05:00,150
这里是 torch.randn()

89
00:05:00,150 --> 00:05:04,910
randn 将创建由正态变量组成的张量

90
00:05:04,910 --> 00:05:08,180
即来自正态分布的随机正态变量

91
00:05:08,180 --> 00:05:11,250
指定元组大小

92
00:05:11,250 --> 00:05:15,605
这里我希望特征是一个矩阵

93
00:05:15,605 --> 00:05:20,675
即包含 1 行和 5 列的二维张量

94
00:05:20,675 --> 00:05:25,800
可以将它看做有 5 个元素的行向量

95
00:05:25,800 --> 00:05:28,610
对于矩阵 我们将创建另一个矩阵

96
00:05:28,610 --> 00:05:33,270
并使用随机正态变量 这次我将使用 randn_like

97
00:05:33,270 --> 00:05:35,990
它的原理是

98
00:05:35,990 --> 00:05:39,260
传入一个张量并查看该张量的形状

99
00:05:39,260 --> 00:05:41,330
然后创建形状相同的另一个张量

100
00:05:41,330 --> 00:05:42,770
这就是这个“like”的含义

101
00:05:42,770 --> 00:05:44,930
我将使用随机正态变量创建一个张量

102
00:05:44,930 --> 00:05:50,115
形状和 features 张量的一样这就是权重

103
00:05:50,115 --> 00:05:53,115
然后我将创建偏差项

104
00:05:53,115 --> 00:05:56,240
还是随机正态变量

105
00:05:56,240 --> 00:05:58,700
现在我只创建一个值

106
00:05:58,700 --> 00:06:00,715
这是 1 行和 1 列

107
00:06:00,715 --> 00:06:03,350
现在布置一道练习题

108
00:06:03,350 --> 00:06:06,050
你需要根据特征 权重

109
00:06:06,050 --> 00:06:08,450
和偏差张量

110
00:06:08,450 --> 00:06:11,030
计算这个简单神经网络的输出

111
00:06:11,030 --> 00:06:13,610
注意 你需要对特征和权重求内积

112
00:06:13,610 --> 00:06:17,390
即将特征和权重相乘并求和

113
00:06:17,390 --> 00:06:20,780
然后加上偏差项

114
00:06:20,780 --> 00:06:26,000
最后传入激活函数 得出网络的输出

115
00:06:26,000 --> 00:06:27,680
如果你想查看我是如何实现的

116
00:06:27,680 --> 00:06:30,380
请参阅我的 solution notebook

117
00:06:30,380 --> 00:06:34,130
或者观看下个视频 我会讲解这道练习的答案

