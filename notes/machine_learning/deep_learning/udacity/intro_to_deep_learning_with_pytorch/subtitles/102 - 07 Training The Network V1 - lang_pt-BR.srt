1
00:00:00,249 --> 00:00:02,749
Depois de carregar os dados
e definir o modelo,

2
00:00:02,782 --> 00:00:06,984
a próxima tarefa será definir
as funções de perda e de otimização.

3
00:00:07,017 --> 00:00:09,616
Para um problema de classificação
como este,

4
00:00:09,649 --> 00:00:12,183
recomendo começar
com a perda de entropia cruzada

5
00:00:12,216 --> 00:00:14,351
e com o método de gradiente
descendente,

6
00:00:14,384 --> 00:00:17,200
mas também é útil ler
a documentação

7
00:00:17,233 --> 00:00:20,455
dos tipos de função de perda
e dos otimizadores.

8
00:00:20,488 --> 00:00:23,144
Na verdade,
vejamos a documentação de perda.

9
00:00:23,177 --> 00:00:25,552
Vemos alguns tipos de perda

10
00:00:25,585 --> 00:00:28,097
e podemos ler sobre
a perda da entropia cruzada.

11
00:00:28,130 --> 00:00:32,129
A documentação diz que a função
CrossEntropy realiza

12
00:00:32,162 --> 00:00:34,864
uma função softmax
na camada de output

13
00:00:34,897 --> 00:00:37,640
e uma perda negativa de log.

14
00:00:37,673 --> 00:00:40,890
Isso significa que o modelo
produzirá pontuações de classe

15
00:00:40,923 --> 00:00:44,035
e que esta última função
transformará isso em probabilidades

16
00:00:44,068 --> 00:00:47,018
usando uma função softmax
e calculando a perda.

17
00:00:47,051 --> 00:00:50,074
Ela detalha como os cálculos
são realizados.

18
00:00:50,107 --> 00:00:53,819
Vemos que a perda é calculada
como um valor médio

19
00:00:53,852 --> 00:00:55,627
em um lote de imagens.

20
00:00:55,660 --> 00:00:59,298
Se um lote com 20 imagens
é visto pelo modelo no treinamento,

21
00:00:59,331 --> 00:01:03,290
a perda retornada
será a perda média das 20 imagens.

22
00:01:03,323 --> 00:01:06,539
Voltando ao notebook, as funções
de perda e de otimização

23
00:01:06,572 --> 00:01:10,171
definirão como a rede atualiza
os pesos durante o treinamento.

24
00:01:10,204 --> 00:01:12,922
A seguir, chegaremos
ao loop de treinamento.

25
00:01:12,955 --> 00:01:15,498
Vemos a quantidade
de epochs que serão treinadas,

26
00:01:15,531 --> 00:01:20,168
que é a quantidade de vezes que
o modelo itera o conjunto de dados.

27
00:01:20,201 --> 00:01:21,592
Uma epoch, por exemplo,

28
00:01:21,625 --> 00:01:24,108
significa que a imagem só será vista
uma vez.

29
00:01:24,141 --> 00:01:27,545
Sugiro que comece com pelo 20 epochs
para este conjunto de dados.

30
00:01:27,578 --> 00:01:31,808
É melhor começar pequeno
ao testar diferentes arquiteturas

31
00:01:31,841 --> 00:01:35,656
e aumentar a quantidade de epochs
ao treinar o modelo final.

32
00:01:35,689 --> 00:01:37,353
Repetimos cada epoch

33
00:01:37,386 --> 00:01:40,111
e rastreamos
a perda de treinamento.

34
00:01:40,144 --> 00:01:42,947
Dentro do loop epoch
fica o loop do lote.

35
00:01:42,980 --> 00:01:46,221
Aqui, o train_loader carregará
um lote de dados de treinamento,

36
00:01:46,254 --> 00:01:50,368
e podemos ver os rótulos corretos
em cada imagem do lote.

37
00:01:50,401 --> 00:01:53,745
No início do loop do lote,
limpamos os cálculos de gradiente

38
00:01:53,778 --> 00:01:57,568
acumulados pelo PyTorch
usando optimizer.zero_grad.

39
00:01:57,601 --> 00:02:01,335
Depois, chamamos o modelo
e realizamos um passo adiante.

40
00:02:01,368 --> 00:02:05,535
O modelo pega as imagens de input,
os dados do train_loader

41
00:02:05,568 --> 00:02:09,769
e retorna as pontuações de classe,
que chamaremos de "output".

42
00:02:09,802 --> 00:02:13,176
Usamos a função de perda
para comparar os outputs

43
00:02:13,209 --> 00:02:15,296
com os rótulos corretos,
o objetivo,

44
00:02:15,329 --> 00:02:17,888
que foram obtidos
do train_loader.

45
00:02:17,921 --> 00:02:21,074
Podemos parear um lote
de outputs e objetivos

46
00:02:21,107 --> 00:02:23,487
e calcular a perda
da entropia cruzada.

47
00:02:23,520 --> 00:02:25,721
Para completar
os passos de retropropagação,

48
00:02:25,754 --> 00:02:27,592
realizaremos um passo reverso

49
00:02:27,625 --> 00:02:29,424
para calcular o gradiente
da perda

50
00:02:29,457 --> 00:02:32,112
realizando um único passo
de otimização.

51
00:02:32,145 --> 00:02:35,471
Esse passo é responsável
por atualizar os valores dos pesos

52
00:02:35,504 --> 00:02:36,840
na rede.

53
00:02:36,873 --> 00:02:39,871
Por fim, calcularemos a perda
de treinamento em execução.

54
00:02:39,904 --> 00:02:43,727
Este loss.item é o valor perdido
da média do lote.

55
00:02:43,760 --> 00:02:47,445
Neste caso, queremos gravar
a perda acumulada do lote

56
00:02:47,478 --> 00:02:49,187
e não a média.

57
00:02:49,220 --> 00:02:53,115
Vou multiplicar pelo tamanho
do lote, data.size(0).

58
00:02:53,148 --> 00:02:56,682
Depois de terminar o loop
e passar por uma epoch,

59
00:02:56,715 --> 00:02:59,707
calculamos a média da perda
durante a epoch.

60
00:02:59,740 --> 00:03:02,323
Para isso, dividirei
a perda acumulada

61
00:03:02,356 --> 00:03:05,370
pela quantidade de imagens
no conjunto de treinamento.

62
00:03:05,403 --> 00:03:09,290
Isso imprimirá a perda média
do treinamento depois de cada epoch.

63
00:03:09,323 --> 00:03:12,730
Esta é só uma forma
de calcular a perda média.

64
00:03:12,763 --> 00:03:15,953
No código de exemplo
pode haver outro cálculo.

65
00:03:15,986 --> 00:03:19,285
Por exemplo, você pode calcular
a perda média em qualquer ponto

66
00:03:19,318 --> 00:03:20,603
do loop do lote,

67
00:03:20,636 --> 00:03:23,211
basta adicionar a perda
para cada imagem de input

68
00:03:23,244 --> 00:03:27,493
e dividir a perda acumulada
pela quantidade de imagens.

69
00:03:27,526 --> 00:03:29,667
Após executar o loop
por um tempo,

70
00:03:29,700 --> 00:03:31,020
depois de algumas epochs,

71
00:03:31,053 --> 00:03:34,721
poderemos testar o modelo
em dados de teste inéditos.

72
00:03:34,754 --> 00:03:37,702
Eu forneci alguns códigos
que iteram pelos dados de teste

73
00:03:37,735 --> 00:03:41,434
do test_loader e aplicam
o modelo de treinamento aos dados.

74
00:03:41,467 --> 00:03:44,366
Esse código permitirá ver
o desempenho do modelo

75
00:03:44,399 --> 00:03:46,284
em cada classe
do conjunto de dados.

76
00:03:46,317 --> 00:03:49,195
A seguir, poderemos ver
o código deste exercício

77
00:03:49,228 --> 00:03:52,932
e a solução para criar um MOP
para classificação de imagem.

78
00:03:52,965 --> 00:03:57,067
Observe a solução depois de tentar
construir a sua rede.

