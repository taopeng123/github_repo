1
00:00:00,000 --> 00:00:04,635
CIFAR-10 is a popular dataset of 60,000 tiny images,

2
00:00:04,635 --> 00:00:07,825
each depicting an object from one of 10 classes.

3
00:00:07,825 --> 00:00:10,275
You can see that each image is truly tiny.

4
00:00:10,275 --> 00:00:12,705
Only 32 pixels high and wide.

5
00:00:12,705 --> 00:00:15,690
These are color images so they're interpreted by the computer as

6
00:00:15,690 --> 00:00:18,905
arrays with a depth of three for RGB color channels.

7
00:00:18,905 --> 00:00:21,820
Because these are color images and there are a lot of them,

8
00:00:21,820 --> 00:00:25,470
the first thing I'm going to show you is an option to use a GPU for training.

9
00:00:25,470 --> 00:00:28,470
A GPU is essentially something that allows you to do

10
00:00:28,470 --> 00:00:33,150
data processing in parallel and so it may prove useful to speed up your training time.

11
00:00:33,150 --> 00:00:36,350
Here, you can see I'm loading in my usual libraries and then

12
00:00:36,350 --> 00:00:40,115
PyTorch gives us a way to check if a GPU device is available.

13
00:00:40,115 --> 00:00:43,280
Torch.cuda is available will return a Boolean

14
00:00:43,280 --> 00:00:46,985
variable true or false whether or not a GPU is available.

15
00:00:46,985 --> 00:00:50,630
We'll store this and then later if we do have a GPU available will be

16
00:00:50,630 --> 00:00:54,290
able to move our data and our model to that device for faster training.

17
00:00:54,290 --> 00:00:58,190
For now, I'm just going to visualize some data and present this problem and so I'm using

18
00:00:58,190 --> 00:01:02,700
my laptop and when I run this cell you can see that I'm training on CPU.

19
00:01:02,700 --> 00:01:06,140
Later, when I do try to develop a solution and train a model,

20
00:01:06,140 --> 00:01:10,895
I'll switch to GPU and in general this is a good thing to know how to use.

21
00:01:10,895 --> 00:01:13,670
Next, I'm going to load in my data as usual.

22
00:01:13,670 --> 00:01:18,390
CIFAR, much like is Amnest is available in the torchvision datasets library.

23
00:01:18,390 --> 00:01:22,625
I'm going to define my training and my test data by calling datasets.CIFAR10.

24
00:01:22,625 --> 00:01:27,040
I'll also transform this data into a tensor datatype and normalize

25
00:01:27,040 --> 00:01:31,565
the RGB values so that the pixel values are in a range from about zero to one.

26
00:01:31,565 --> 00:01:37,060
Finally, I can load in my transform data in batches using PyTorch's data loader class.

27
00:01:37,060 --> 00:01:39,340
These lines of code should look very similar to

28
00:01:39,340 --> 00:01:41,705
the Amnest code in which we loaded in data,

29
00:01:41,705 --> 00:01:43,655
transformed it into a tensor datatype,

30
00:01:43,655 --> 00:01:45,600
and separated the data into training,

31
00:01:45,600 --> 00:01:47,680
validation, and test sets.

32
00:01:47,680 --> 00:01:51,975
Also down here, I'm specifying the 10 image classes that I'm reading in.

33
00:01:51,975 --> 00:01:55,490
All CIFAR-10 images will fall into one of these categories.

34
00:01:55,490 --> 00:01:57,850
The data may take a moment to load in but once

35
00:01:57,850 --> 00:02:00,395
you load it in you can visualize a batch of that data.

36
00:02:00,395 --> 00:02:04,790
Here, I've defined a helper function which will basically unnormalize the images

37
00:02:04,790 --> 00:02:09,505
and convert them from a tensor image type to a non-py image type for visualization,

38
00:02:09,505 --> 00:02:12,110
then I'm just going to load in and display a batch of

39
00:02:12,110 --> 00:02:16,715
images and here we can verify that these images look pretty much how you would expect.

40
00:02:16,715 --> 00:02:18,170
We have images of cats,

41
00:02:18,170 --> 00:02:21,290
frogs, deer, and automobiles.

42
00:02:21,290 --> 00:02:24,985
We can even choose to view an image in more detail.

43
00:02:24,985 --> 00:02:27,170
Here, I'm displaying the red, green,

44
00:02:27,170 --> 00:02:32,030
and blue color channels as grayscale values for one single image and we should again

45
00:02:32,030 --> 00:02:34,160
see that the brightest pixel values are close to

46
00:02:34,160 --> 00:02:37,305
the value one and darker ones closer to zero.

47
00:02:37,305 --> 00:02:41,745
Next, you'll want to define and train a CNN to classify these images.

48
00:02:41,745 --> 00:02:44,250
You're also welcome to try out an MLP approach,

49
00:02:44,250 --> 00:02:46,435
see how both work, and compare the results.

50
00:02:46,435 --> 00:02:50,450
I'll be assuming that you want to define a CNN architecture so I provided

51
00:02:50,450 --> 00:02:54,800
links to the documentation for convolutional and maxpooling layers in PyTorch.

52
00:02:54,800 --> 00:02:56,630
Here's also a simple diagram showing how

53
00:02:56,630 --> 00:02:59,415
an input image might pass through a couple of these layers.

54
00:02:59,415 --> 00:03:00,850
Then if you scroll down,

55
00:03:00,850 --> 00:03:04,340
you can see that I've defined one example convolutional layer for you.

56
00:03:04,340 --> 00:03:06,995
I've defined it in the init function of our network.

57
00:03:06,995 --> 00:03:09,020
To define a convolutional layer,

58
00:03:09,020 --> 00:03:12,895
I use nn.Conv2d and I pass in some parameters.

59
00:03:12,895 --> 00:03:14,525
For our first convolutional layer,

60
00:03:14,525 --> 00:03:18,290
this will be the number of inputs seen as the depth of the input image.

61
00:03:18,290 --> 00:03:24,415
Recall that our inputs are 32 by 32 images with a depth of three for RGB color channels.

62
00:03:24,415 --> 00:03:27,500
So, I've defined the input and I've specified that this

63
00:03:27,500 --> 00:03:30,800
should output a convolutional layer with a depth of 16.

64
00:03:30,800 --> 00:03:35,930
That means this layer should take in our image and produce 16 filtered images as output.

65
00:03:35,930 --> 00:03:39,310
I've also specified that I'm using filters that are 3 by 3 in

66
00:03:39,310 --> 00:03:44,050
size and to keep my output layer the same x y size as my input image,

67
00:03:44,050 --> 00:03:46,650
I'll add one pixel of padding on the border.

68
00:03:46,650 --> 00:03:49,980
I've also defined one maxpooling layer named pool.

69
00:03:49,980 --> 00:03:53,990
This has a kernel size and stride size of two which means that any input it's

70
00:03:53,990 --> 00:03:58,510
applied to it will downsample it x y dimensions by a factor of two.

71
00:03:58,510 --> 00:03:59,640
Then in the forward function,

72
00:03:59,640 --> 00:04:02,000
we can see how all of these things fit together.

73
00:04:02,000 --> 00:04:03,885
For an input image x,

74
00:04:03,885 --> 00:04:05,080
I first pass it into

75
00:04:05,080 --> 00:04:09,300
our first convolutional layer and I apply a relu activation function.

76
00:04:09,300 --> 00:04:12,710
This output will be passed to a final pooling layer resulting in

77
00:04:12,710 --> 00:04:15,900
a downsampled transformed x which I'll return.

78
00:04:15,900 --> 00:04:16,930
To complete this model,

79
00:04:16,930 --> 00:04:21,020
it will be up to you to add multiple convolutional and pooling layers and finally

80
00:04:21,020 --> 00:04:23,390
flatten and apply a fully-connected layer for

81
00:04:23,390 --> 00:04:26,285
producing the desired number of class score outputs.

82
00:04:26,285 --> 00:04:28,265
After defining a complete CNN,

83
00:04:28,265 --> 00:04:31,840
you can instantiate it and even move it to GPU if it's available.

84
00:04:31,840 --> 00:04:35,090
Next, it'll be up to you to specify an appropriate loss and

85
00:04:35,090 --> 00:04:38,440
optimization function for this training task and finally,

86
00:04:38,440 --> 00:04:40,350
I've provided a training loop for you.

87
00:04:40,350 --> 00:04:44,135
You may want to increase the number of epochs you train your final model for.

88
00:04:44,135 --> 00:04:47,950
But this loop will keep track of the training and validation loss as you go.

89
00:04:47,950 --> 00:04:50,660
If you're validation loss decreases over an epoch,

90
00:04:50,660 --> 00:04:52,100
your model will be saved.

91
00:04:52,100 --> 00:04:54,650
Then you'll be able to test your train network and see

92
00:04:54,650 --> 00:04:57,470
how it performs on each type of test image.

93
00:04:57,470 --> 00:05:02,030
The biggest challenge will be defining a complete CNN and as always I encourage you

94
00:05:02,030 --> 00:05:03,650
to do your research before you define

95
00:05:03,650 --> 00:05:06,695
your model so that you can make an informed decision as you go.

96
00:05:06,695 --> 00:05:09,710
Try to solve this challenge on your own and if you want to check

97
00:05:09,710 --> 00:05:12,800
your work next I'll go over one possible solution.

