1
00:00:00,000 --> 00:00:04,605
ImageNet 是一个包含 1000 万以上手动标注图像的数据库

2
00:00:04,605 --> 00:00:08,180
这些图像来自 1,000 个不同的类别

3
00:00:08,180 --> 00:00:11,490
自 2010 年起 ImageNet 项目一直会举办

4
00:00:11,490 --> 00:00:15,630
ImageNet 大规模视觉识别竞赛

5
00:00:15,630 --> 00:00:18,630
来自世界各地的团队会在此年度竞赛中

6
00:00:18,630 --> 00:00:23,005
构建最佳对象识别和分类 CNN

7
00:00:23,005 --> 00:00:26,165
在 2012 年出现了第一个突破性的模型

8
00:00:26,165 --> 00:00:28,635
称之为 AlexNet

9
00:00:28,635 --> 00:00:32,715
由多伦多大学的团队开发而成

10
00:00:32,715 --> 00:00:36,610
AlexNet 团队使用 2012 年当时最佳的 GPU

11
00:00:36,610 --> 00:00:40,475
训练该网络大约一周时间

12
00:00:40,475 --> 00:00:44,995
AlexNet 开创性地使用了 ReLU 激活函数

13
00:00:44,995 --> 00:00:49,220
并使用丢弃技巧来避免过拟合

14
00:00:49,220 --> 00:00:55,655
在 2014 年 有两个团队几乎在 ImageNet 竞赛中打成平手

15
00:00:55,655 --> 00:00:59,710
其中一个网络叫做 VGGNet

16
00:00:59,710 --> 00:01:03,100
通常简称为 VGG

17
00:01:03,100 --> 00:01:07,905
它由牛津大学的视觉几何团队开发而成

18
00:01:07,905 --> 00:01:12,560
VGG 有 VGG 16 和 VGG 19 这两个版本

19
00:01:12,560 --> 00:01:18,935
分别共有 16 个和 19 个层级

20
00:01:18,935 --> 00:01:22,860
二者都结构简单出彩

21
00:01:22,860 --> 00:01:26,685
由一系列 3x3 卷积层组成

22
00:01:26,685 --> 00:01:29,460
中间夹杂着 2x2 池化层

23
00:01:29,460 --> 00:01:33,130
最后是 3 个全连接层

24
00:01:33,130 --> 00:01:39,650
VGG 率先独家使用很小的 3x3 卷积窗口

25
00:01:39,650 --> 00:01:45,295
而 AlexNet 的卷积窗口大得多 大小为 11x11

26
00:01:45,295 --> 00:01:51,955
在 2015 年 ImageNet 获胜者是微软研究院开发的网络 叫做 ResNet

27
00:01:51,955 --> 00:01:57,940
ResNet 和 VGG 有点像 不会一直重复相同的结构

28
00:01:57,940 --> 00:01:59,600
一层又一层

29
00:01:59,600 --> 00:02:05,215
和 VGG 一样 ResNet 也有很多不同的版本 相互之间的层级数量不同

30
00:02:05,215 --> 00:02:10,490
最大版本具有突破性的 152 层

31
00:02:10,490 --> 00:02:14,400
之前的研究员也尝试使 CNN 达到这个深度

32
00:02:14,400 --> 00:02:17,810
但是他们遇到了问题 当他们添加更多层级时

33
00:02:17,810 --> 00:02:20,100
性能增加到某个点后

34
00:02:20,100 --> 00:02:22,910
就开始快速下降

35
00:02:22,910 --> 00:02:27,350
部分原因是梯度消失问题造成的

36
00:02:27,350 --> 00:02:31,715
当我们通过反向传播训练网络时 就可能会遇到此问题

37
00:02:31,715 --> 00:02:37,475
主要原理是梯度信号必须散布到整个网络中

38
00:02:37,475 --> 00:02:39,625
网络越深

39
00:02:39,625 --> 00:02:44,550
信号在达到目的地之前就越有可能变弱

40
00:02:44,550 --> 00:02:50,665
ResNet 团队在很深的 CNN 中添加了跳过层级的连接

41
00:02:50,665 --> 00:02:54,390
所以梯度信号的传播路径变短了

42
00:02:54,390 --> 00:03:01,650
ResNet 在分类 ImageNet 数据库中的图像方面取得了惊人的效果

