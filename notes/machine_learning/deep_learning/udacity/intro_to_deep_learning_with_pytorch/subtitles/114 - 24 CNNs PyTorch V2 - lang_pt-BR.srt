1
00:00:00,001 --> 00:00:03,941
Bom, agora que você tentou definir
e treinar seu próprio classificador,

2
00:00:03,974 --> 00:00:06,449
vou mostrar a solução
que eu criei.

3
00:00:06,482 --> 00:00:08,909
Depois de carregar os meus dados
e processá-los,

4
00:00:08,942 --> 00:00:10,925
defini uma CNN completa.

5
00:00:11,792 --> 00:00:14,527
Mantive minha camada convolucional
inicial, conv1,

6
00:00:14,560 --> 00:00:15,963
que vê a imagem de input

7
00:00:15,996 --> 00:00:18,517
e gera uma pilha
de 16 mapas de características.

8
00:00:18,550 --> 00:00:21,051
E defini todas as camadas
convolucionais,

9
00:00:21,084 --> 00:00:22,409
adicionando mais 2 camadas

10
00:00:22,442 --> 00:00:24,632
com o dobro da profundidade
do output,

11
00:00:24,665 --> 00:00:27,485
até obtermos uma camada
com uma profundidade de 64.

12
00:00:27,518 --> 00:00:29,785
Começamos
com uma profundidade de 3,

13
00:00:29,818 --> 00:00:33,952
que muda para 16,
depois 32 e, por fim, 64.

14
00:00:33,985 --> 00:00:37,655
Todas essas camadas usam
um Kernel convolucional 3x3

15
00:00:37,688 --> 00:00:39,513
e têm padding igual a 1.

16
00:00:39,546 --> 00:00:42,250
Observe também que mantive
a camada max pooling,

17
00:00:42,283 --> 00:00:45,450
que reduzirá todos os tamanhos XY
em 2 unidades.

18
00:00:45,483 --> 00:00:49,390
Também incluí uma camada de dropout
com uma probabilidade de 0,25,

19
00:00:49,423 --> 00:00:51,182
para evitar sobreajuste.

20
00:00:51,215 --> 00:00:54,587
Por fim, também tenho
2 camadas completamente conectadas.

21
00:00:54,620 --> 00:00:57,453
Esta 1ª camada é responsável
por receber como input

22
00:00:57,486 --> 00:01:00,567
minha última pilha reduzida
de mapas de características.

23
00:01:00,600 --> 00:01:04,375
Eu sei que a minha imagem de input
original, de 32x32x3,

24
00:01:04,408 --> 00:01:08,562
é espremida na dimensão XY
e esticada na de profundidade

25
00:01:08,595 --> 00:01:11,772
ao se deslocar para as camadas
convolucionais e de pooling.

26
00:01:11,805 --> 00:01:14,591
Na função forward,
apliquei uma camada de pooling

27
00:01:14,624 --> 00:01:16,718
depois
de cada camada convolucional.

28
00:01:16,751 --> 00:01:19,961
Então esta imagem diminuirá
de tamanho, para 16x16,

29
00:01:19,994 --> 00:01:22,575
depois para 8x8
e, por fim, para 4x4,

30
00:01:22,608 --> 00:01:24,604
depois da última
camada de pooling.

31
00:01:24,984 --> 00:01:29,209
Na 3ª camada convolucional,
produziremos uma profundidade de 64.

32
00:01:29,242 --> 00:01:33,189
É assim que obtenho estes valores:
4x4 para o último tamanho XY

33
00:01:33,222 --> 00:01:35,677
e 64 para a profundidade.

34
00:01:35,710 --> 00:01:39,195
Esse é o número de inputs
que essa 1ª camada conectada verá.

35
00:01:39,228 --> 00:01:41,832
Depois ela produzirá
500 outputs.

36
00:01:41,865 --> 00:01:43,986
Estes 500 outputs servirão
de input

37
00:01:44,019 --> 00:01:46,141
para a última camada
de classificação,

38
00:01:46,174 --> 00:01:47,425
que usará isto como input

39
00:01:47,458 --> 00:01:50,676
e produzirá como output
10 pontuações de classe.

40
00:01:50,709 --> 00:01:54,049
Vamos ver como essas camadas
são usadas na função forward.

41
00:01:54,082 --> 00:01:58,187
Primeiro adicionei em sequência
camadas convolucionais e de pooling,

42
00:01:58,220 --> 00:02:01,031
passando a imagem de input
para a 1ª camada convolucional

43
00:02:01,064 --> 00:02:04,233
e aplicando a função de ativação
e a camada de pooling.

44
00:02:04,266 --> 00:02:07,878
Fiz a mesma coisa com a 2ª e a 3ª
camada convolucional.

45
00:02:07,911 --> 00:02:12,126
Por fim, achatei este X resultante,
transformando-o numa forma vetorial.

46
00:02:12,159 --> 00:02:16,014
Isso me permitiu passá-lo como input
a uma camada totalmente conectada.

47
00:02:16,047 --> 00:02:19,021
Entre esta nova camada achatada
e cada camada conectada

48
00:02:19,054 --> 00:02:21,865
adicionei uma camada de dropout,
para evitar sobreajuste.

49
00:02:21,898 --> 00:02:24,154
Mas depois passei
a imagem achatada do input X

50
00:02:24,187 --> 00:02:26,386
para a primeira camada
totalmente conectada.

51
00:02:26,419 --> 00:02:30,303
Como fiz com as camadas ocultas,
usei uma função de ativação ReLU.

52
00:02:30,336 --> 00:02:31,870
Por fim,
uma camada de dropout

53
00:02:31,903 --> 00:02:34,191
e a última camada
totalmente conectada.

54
00:02:34,224 --> 00:02:37,401
O X resultante deverá ser uma lista
de 10 pontuações de classe.

55
00:02:37,640 --> 00:02:41,053
Por fim, instanciei este modelo
e o movi para a GPU.

56
00:02:41,877 --> 00:02:45,292
Aqui você pode ver que eu imprimi
as camadas da função init,

57
00:02:45,325 --> 00:02:47,372
para ver se geram
os valores esperados.

58
00:02:47,405 --> 00:02:50,213
Isso mostra o número de inputs
e outputs de cada camada,

59
00:02:50,246 --> 00:02:52,459
o tamanho do Kernel,
o stride e o padding.

60
00:02:52,492 --> 00:02:53,647
Os valores conferem.

61
00:02:53,680 --> 00:02:56,787
Resumindo, a toda
camada convolucional que eu defino,

62
00:02:56,820 --> 00:03:00,200
aplico uma função ReLU
e uma camada max pooling.

63
00:03:00,233 --> 00:03:03,291
Depois de definir essas camadas,
eu achato essa representação

64
00:03:03,324 --> 00:03:05,530
e passo-a
para a camada totalmente conectada,

65
00:03:05,563 --> 00:03:07,531
adicionando dropout
e passando-a,

66
00:03:07,564 --> 00:03:10,288
para que produza
10 pontuações de classe.

67
00:03:10,321 --> 00:03:14,054
Bom, meu modelo está completo,
e agora partirei para o treinamento.

68
00:03:14,087 --> 00:03:16,247
Usei perda
de entropia cruzada,

69
00:03:16,280 --> 00:03:18,842
que é útil para testes
de classificação como este,

70
00:03:18,875 --> 00:03:21,082
e gradiente descendente
estocástico.

71
00:03:21,115 --> 00:03:25,535
Aqui comecei a treinar a rede,
e resolvi treiná-la por 30 epochs.

72
00:03:25,568 --> 00:03:28,882
Escolhi o valor ao ver as perdas
de treinamento e validação

73
00:03:28,915 --> 00:03:30,410
diminuírem com o tempo.

74
00:03:30,443 --> 00:03:32,843
Mas eu podia ter encerrado
o treinamento antes,

75
00:03:32,876 --> 00:03:34,227
por volta da 20ª epoch,

76
00:03:34,260 --> 00:03:37,224
quando a perda de validação
parou de diminuir.

77
00:03:37,257 --> 00:03:40,706
Salvei o modelo que apresentou
a melhor perda de validação,

78
00:03:40,739 --> 00:03:43,250
depois carreguei e testei
o modelo.

79
00:03:43,283 --> 00:03:47,866
Constatei com o teste
que a precisão média foi de 70%,

80
00:03:47,899 --> 00:03:50,878
o que não é nada mau.
É bem melhor do que um palpite.

81
00:03:50,911 --> 00:03:52,873
Se você tiver se empenhado
nesta tarefa,

82
00:03:52,906 --> 00:03:55,392
quero parabenizá-lo
por ter chegado até aqui.

83
00:03:55,425 --> 00:03:58,676
Você aprendeu muito sobre programar
sua própria rede neural.

84
00:03:58,709 --> 00:04:01,806
É claro que algumas classes
têm mais êxito do que outras,

85
00:04:01,839 --> 00:04:05,110
e é sempre interessante
tentar entender os motivos disso.

86
00:04:05,143 --> 00:04:09,871
O meu modelo acerta mais imagens
de veículos do que de animais.

87
00:04:09,904 --> 00:04:12,774
Isso é porque os animais
variam muito de cor e tamanho,

88
00:04:12,807 --> 00:04:15,027
então vou poder melhorar
o modelo

89
00:04:15,060 --> 00:04:18,287
se eu incluir mais imagens
nesse conjunto de dados específico.

90
00:04:18,320 --> 00:04:20,776
Pode ser útil adicionar
outra camada convolucional

91
00:04:20,809 --> 00:04:24,375
e ver se consigo extrair padrões
mais complexos dessas imagens.

92
00:04:24,408 --> 00:04:28,214
Aqui posso visualizar quais imagens
o modelo acertou e errou.

93
00:04:28,247 --> 00:04:31,788
Há muito espaço para testar
e otimizar ainda mais a CNN,

94
00:04:31,821 --> 00:04:35,000
e incentivo que você faça isso.
É um grande aprendizado.

95
00:04:35,033 --> 00:04:38,817
Devo dizer que, em 2015,
houve uma competição on-line

96
00:04:38,850 --> 00:04:40,575
em que cientistas de dados
tentaram

97
00:04:40,608 --> 00:04:42,759
classificar imagens
deste banco de dados.

98
00:04:42,792 --> 00:04:44,996
A arquitetura vencedora
era uma CNN

99
00:04:45,029 --> 00:04:48,367
e alcançou uma precisão de teste
de quase 95%.

100
00:04:48,400 --> 00:04:51,721
A rede demorou cerca de 90 horas
para treinar numa GPU,

101
00:04:51,754 --> 00:04:53,959
o que eu não recomendo
nesta aula,

102
00:04:53,992 --> 00:04:58,014
mas isso mostra que obter precisão
não é uma tarefa trivial.

