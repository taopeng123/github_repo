1
00:00:00,000 --> 00:00:04,120
In this notebook, I'm going to go over an implementation of style transfer,

2
00:00:04,120 --> 00:00:06,590
following the details outlined in this paper.

3
00:00:06,590 --> 00:00:10,025
Image style transfer using convolutional neural networks.

4
00:00:10,025 --> 00:00:14,520
We're going to use a pre-trained VGG 19 net as a feature extractor.

5
00:00:14,520 --> 00:00:17,550
We can put individual images through this network,

6
00:00:17,550 --> 00:00:19,770
then at specific layers get the output,

7
00:00:19,770 --> 00:00:23,535
and calculate the content and style representations for an image.

8
00:00:23,535 --> 00:00:27,870
Basically, style transfer aims to create a new target image that tries to match

9
00:00:27,870 --> 00:00:32,315
the content of a given content image and the style of a given style image.

10
00:00:32,315 --> 00:00:36,490
Here's our example of a cat and a Hokusai wave image as an example.

11
00:00:36,490 --> 00:00:38,200
But with the code in this notebook,

12
00:00:38,200 --> 00:00:39,630
which is in our public GitHub,

13
00:00:39,630 --> 00:00:44,165
you'll be able to upload images of your own and really customize your own target image.

14
00:00:44,165 --> 00:00:45,830
Okay. So, first things first,

15
00:00:45,830 --> 00:00:49,100
I'm loading in our usual libraries including a new one,

16
00:00:49,100 --> 00:00:51,005
the PIL image library.

17
00:00:51,005 --> 00:00:54,310
This will help me load in any kind of image I want to.

18
00:00:54,310 --> 00:00:55,590
Next, I want to load in

19
00:00:55,590 --> 00:00:59,610
the pre-trained VGG 19 network that this implementation relies on.

20
00:00:59,610 --> 00:01:01,335
Using pi torches models,

21
00:01:01,335 --> 00:01:04,865
I can load this network in by name and ask for it to be pretrained.

22
00:01:04,865 --> 00:01:08,990
I actually just want to load in all the convolutional and pooling layers,

23
00:01:08,990 --> 00:01:10,970
which in this case are named features,

24
00:01:10,970 --> 00:01:13,075
and this is unique to the VGG network.

25
00:01:13,075 --> 00:01:16,255
You may remember doing something similar in the transfer learning lesson.

26
00:01:16,255 --> 00:01:21,410
We load in a model and we freeze any weights or parameters that we don't want to change.

27
00:01:21,410 --> 00:01:23,460
So, I'm saving this pre-trained model,

28
00:01:23,460 --> 00:01:25,440
then for every weight in this network,

29
00:01:25,440 --> 00:01:27,785
I'm setting requires grad to false.

30
00:01:27,785 --> 00:01:30,245
This means that none of these weights will change.

31
00:01:30,245 --> 00:01:34,130
So now, VGG becomes a kind of fixed feature extractor,

32
00:01:34,130 --> 00:01:37,900
which is just what we want for getting content and style features later.

33
00:01:37,900 --> 00:01:41,345
Next, I'm going to check if a GPU device is available,

34
00:01:41,345 --> 00:01:44,260
and if it is, I'm moving my model to it.

35
00:01:44,260 --> 00:01:46,660
I do recommend running this example on a GPU

36
00:01:46,660 --> 00:01:49,630
just to speed up the target image creation process.

37
00:01:49,630 --> 00:01:53,580
Then, this is going to print out the VGG model and all its layers.

38
00:01:53,580 --> 00:01:56,375
We can see the sequence of layers is all numbered.

39
00:01:56,375 --> 00:01:58,315
Here's the first convolutional layer,

40
00:01:58,315 --> 00:01:59,460
and the first stack,

41
00:01:59,460 --> 00:02:01,835
conv11, and its number zero.

42
00:02:01,835 --> 00:02:03,795
You have the second in that first stack,

43
00:02:03,795 --> 00:02:05,925
conv12, and it's labeled two.

44
00:02:05,925 --> 00:02:10,075
Then, we have a max pooling layer and conv21 in our second stack.

45
00:02:10,075 --> 00:02:13,870
We can keep going until the very last max pooling layer.

46
00:02:13,870 --> 00:02:18,110
Next, I'm going to continue loading and the resources I need to implement style transfer.

47
00:02:18,110 --> 00:02:20,600
So, I have my trained VGG model,

48
00:02:20,600 --> 00:02:23,695
and now I need to load in my content and style images.

49
00:02:23,695 --> 00:02:24,980
Here I have a function,

50
00:02:24,980 --> 00:02:28,765
which is going to transform any image into a normalized tensor.

51
00:02:28,765 --> 00:02:31,295
This will deal with jpegs or PNGs,

52
00:02:31,295 --> 00:02:35,060
and it will make sure that the size is reasonable for our purposes.

53
00:02:35,060 --> 00:02:40,175
Then, I'm going to actually load in style and content images from my images directory.

54
00:02:40,175 --> 00:02:44,765
I'm also reshaping my style image into the same shape as the content image.

55
00:02:44,765 --> 00:02:48,910
This reshaping step is just going to make the math nicely lined up later on.

56
00:02:48,910 --> 00:02:51,575
Then here, I also have a function to help me convert

57
00:02:51,575 --> 00:02:55,700
a normalized tensor image back into a numpy image for display,

58
00:02:55,700 --> 00:02:57,830
and I can show you the images that I chose.

59
00:02:57,830 --> 00:03:03,110
I chose an octopus for my content image and a David Hockney painting for my style image.

60
00:03:03,110 --> 00:03:05,180
I really like to do people or animals for

61
00:03:05,180 --> 00:03:08,650
content images and bright artistic paintings for style images.

62
00:03:08,650 --> 00:03:11,160
But it's really going to be up to you in this case.

63
00:03:11,160 --> 00:03:14,910
Okay. So now, we have all the elements we need for style transfer.

64
00:03:14,910 --> 00:03:17,620
Next, I'm going to give you your first task.

65
00:03:17,620 --> 00:03:19,775
We know that we have to eventually pass

66
00:03:19,775 --> 00:03:23,070
our content and style images through our VGG network,

67
00:03:23,070 --> 00:03:26,620
and extract content and style features from particular layers.

68
00:03:26,620 --> 00:03:30,590
So, your job is going to be to complete this get features function.

69
00:03:30,590 --> 00:03:34,220
This function takes in an image and returns the outputs

70
00:03:34,220 --> 00:03:38,060
from layers that correspond to our content and style representations.

71
00:03:38,060 --> 00:03:40,940
This is going to be a list of features that are taken at

72
00:03:40,940 --> 00:03:43,855
particular layers in our VGG 19 model.

73
00:03:43,855 --> 00:03:45,905
This function is almost complete.

74
00:03:45,905 --> 00:03:50,115
It just needs a descriptive dictionary that maps our VGG 19 layers,

75
00:03:50,115 --> 00:03:52,695
that are currently numbered 0 through 36,

76
00:03:52,695 --> 00:03:54,485
into names like conv1_1,

77
00:03:54,485 --> 00:03:56,290
conv2_1, and so on.

78
00:03:56,290 --> 00:03:59,440
I've given you the first layer that we're interested in to start.

79
00:03:59,440 --> 00:04:01,835
If you need a reminder for which layers make up

80
00:04:01,835 --> 00:04:04,485
the content and style representations of an image,

81
00:04:04,485 --> 00:04:06,440
take a look at the original paper,

82
00:04:06,440 --> 00:04:08,475
and identify which layers we'll need,

83
00:04:08,475 --> 00:04:10,710
then list them all here.

84
00:04:10,710 --> 00:04:13,120
If you get stuck or don't know where to start,

85
00:04:13,120 --> 00:04:15,470
I'll show you my solution in the next video.

