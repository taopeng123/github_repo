1
00:00:00,000 --> 00:00:04,200
Well, sometimes your model might use forms of

2
00:00:04,200 --> 00:00:08,295
control flow that don't actually work with this tracing method.

3
00:00:08,295 --> 00:00:10,830
So, for example, you might have

4
00:00:10,830 --> 00:00:15,420
some if statements in your forward method that depend on your input.

5
00:00:15,420 --> 00:00:20,370
So, things like this, they're fairly common in natural language processing problems.

6
00:00:20,370 --> 00:00:23,670
So, there is a second way to convert

7
00:00:23,670 --> 00:00:27,420
your models to Tor script and this is through annotation.

8
00:00:27,420 --> 00:00:30,435
So, if you have a model like this.

9
00:00:30,435 --> 00:00:34,140
So, typically you would subclass it from torch.nn.module,

10
00:00:34,140 --> 00:00:36,990
create your parameters or whatever else you need,

11
00:00:36,990 --> 00:00:38,655
and then have some forward pass.

12
00:00:38,655 --> 00:00:43,400
Here, the forward pass has this If statement that depends on the input itself.

13
00:00:43,400 --> 00:00:47,045
So, here the tracing method that we used before isn't going to work.

14
00:00:47,045 --> 00:00:49,070
Remember with that, what we did is we basically

15
00:00:49,070 --> 00:00:51,290
passed an example input through our network,

16
00:00:51,290 --> 00:00:54,500
and then in that way like traced out all the operations and built this graph,

17
00:00:54,500 --> 00:00:57,210
but with control flow like this then the graph that you're going

18
00:00:57,210 --> 00:01:00,100
to build actually depends on the input that you put in.

19
00:01:00,100 --> 00:01:05,750
So, instead what we're gonna do here is subclass from torch.jit.ScriptModule.

20
00:01:05,750 --> 00:01:11,960
So remember, when we used tracing that that actually returned a script module for us,

21
00:01:11,960 --> 00:01:14,830
but here we are creating our own script module.

22
00:01:14,830 --> 00:01:16,575
Now, with our forward method,

23
00:01:16,575 --> 00:01:20,135
we know with this control flow we can use a decorator,

24
00:01:20,135 --> 00:01:23,090
so torch.jit.ScriptMethod, and then it

25
00:01:23,090 --> 00:01:26,800
will appropriately convert this to a script module for us.

26
00:01:26,800 --> 00:01:32,660
So, the cool thing about this is that you previously defined your module like this,

27
00:01:32,660 --> 00:01:34,940
and you've got everything to work, you've trained it,

28
00:01:34,940 --> 00:01:38,825
and now you want to convert it for production.

29
00:01:38,825 --> 00:01:43,875
All you really need to do is subclass it from script module instead of module here,

30
00:01:43,875 --> 00:01:46,515
and then add this decorator.

31
00:01:46,515 --> 00:01:51,260
So, it's basically just two changes to the code that you already have,

32
00:01:51,260 --> 00:01:55,160
and you're ready to ship it to production after training.

33
00:01:55,160 --> 00:01:57,210
So now, with either method,

34
00:01:57,210 --> 00:02:00,110
tracing or annotation to get your script module,

35
00:02:00,110 --> 00:02:06,005
you can serialize it to a file which can then later be loaded into C++.

36
00:02:06,005 --> 00:02:10,870
So, to do this, you simply take your script module and use the save method,

37
00:02:10,870 --> 00:02:14,490
passing it in the file name or path where you want it to be saved,

38
00:02:14,490 --> 00:02:18,425
and then it will produce this file in your directory.

39
00:02:18,425 --> 00:02:22,295
With this file, you can load it into a C++ program,

40
00:02:22,295 --> 00:02:26,070
and use your model just as you would in Python.

