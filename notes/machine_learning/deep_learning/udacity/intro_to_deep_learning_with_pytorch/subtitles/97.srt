1
00:00:00,000 --> 00:00:04,200
Any gray scale image is interpreted by a computer as an array.

2
00:00:04,200 --> 00:00:07,380
A grid of values for each grid cell is called a pixel,

3
00:00:07,380 --> 00:00:09,865
and each pixel has a numerical value.

4
00:00:09,865 --> 00:00:14,010
Each image in the MNIST database is 28 pixels high and wide.

5
00:00:14,010 --> 00:00:18,070
And so, it's understood by a computer as a 28 by 28 array.

6
00:00:18,070 --> 00:00:20,070
In a typical gray scale image,

7
00:00:20,070 --> 00:00:23,124
white pixels are encoded as the value 255,

8
00:00:23,124 --> 00:00:25,625
and black pixels are encoded as zero.

9
00:00:25,625 --> 00:00:27,600
Gray pixels fall somewhere in between,

10
00:00:27,600 --> 00:00:30,150
with light-gray being closer to 255.

11
00:00:30,150 --> 00:00:32,060
We'll soon see that color images have

12
00:00:32,060 --> 00:00:35,495
similar numerical representations for each pixel color.

13
00:00:35,495 --> 00:00:39,505
These MNIST images have actually gone through a quick pre-processing step.

14
00:00:39,505 --> 00:00:44,275
They've been re-scaled so that each image has pixel values in a range from zero to one,

15
00:00:44,275 --> 00:00:46,740
as opposed to from 0-255.

16
00:00:46,740 --> 00:00:50,420
To go from a range of 0-255 to zero to one,

17
00:00:50,420 --> 00:00:54,000
you just have to divide every pixel value by 255.

18
00:00:54,000 --> 00:00:56,254
This step is called normalization,

19
00:00:56,254 --> 00:00:59,280
and it's common practice in many deep learning techniques.

20
00:00:59,280 --> 00:01:02,375
Normalization will help our algorithm to train better.

21
00:01:02,375 --> 00:01:05,345
The reason we typically want normalized pixel values

22
00:01:05,345 --> 00:01:08,630
is because neural networks rely on gradient calculations.

23
00:01:08,630 --> 00:01:11,450
These networks are trying to learn how important or how

24
00:01:11,450 --> 00:01:15,120
weighty a certain pixel should be in determining the class of an image.

25
00:01:15,120 --> 00:01:19,610
Normalizing the pixel values helps these gradient calculations stay consistent,

26
00:01:19,610 --> 00:01:23,835
and not get so large that they slow down or prevent a network from training.

27
00:01:23,835 --> 00:01:26,329
So, now we have a normalized data,

28
00:01:26,329 --> 00:01:29,345
how might we approach the task of classifying these images?

29
00:01:29,345 --> 00:01:32,430
Well, you already learned one method for classification,

30
00:01:32,430 --> 00:01:34,790
using a multi-layer perceptron.

31
00:01:34,790 --> 00:01:38,450
How might we input this image data into an MLP?

32
00:01:38,450 --> 00:01:41,520
Recall that MLPs only take vectors as input.

33
00:01:41,520 --> 00:01:44,245
So, in order to use an MLP with images,

34
00:01:44,245 --> 00:01:47,575
we have to first convert any image array into a vector.

35
00:01:47,575 --> 00:01:51,394
This process is so common that it has a name, flattening.

36
00:01:51,394 --> 00:01:55,380
I'll illustrate this flattening conversion process on a small example here.

37
00:01:55,380 --> 00:01:57,570
In the case of a four-by-four image,

38
00:01:57,570 --> 00:02:00,380
we have a matrix with 16 pixel values.

39
00:02:00,380 --> 00:02:03,375
Instead of representing this as a four-by-four matrix,

40
00:02:03,375 --> 00:02:06,250
we can construct a vector with 16 entries,

41
00:02:06,250 --> 00:02:08,225
where the first first four entries of our vector

42
00:02:08,225 --> 00:02:10,765
correspond to the first wheel of our old array.

43
00:02:10,765 --> 00:02:14,495
The second four entries correspond to the second wheel and so on.

44
00:02:14,495 --> 00:02:17,300
After converting our images into vectors,

45
00:02:17,300 --> 00:02:20,650
they can then be fed into the input layer of an MLP.

46
00:02:20,650 --> 00:02:23,045
We'll see how this works and see how to produce

47
00:02:23,045 --> 00:02:26,600
a class prediction for any given image in the next few videos.

