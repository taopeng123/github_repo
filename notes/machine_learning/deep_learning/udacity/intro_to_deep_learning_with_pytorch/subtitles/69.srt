1
00:00:00,000 --> 00:00:04,830
So, you were talking about PyTorch being informed by what users are wanting,

2
00:00:04,830 --> 00:00:09,030
and especially with being able to put models to production.

3
00:00:09,030 --> 00:00:12,840
I was wondering if there are any other features that you hear

4
00:00:12,840 --> 00:00:16,770
people clamoring for what kind of demands do you hear now,

5
00:00:16,770 --> 00:00:19,515
and maybe where do you think PyTorch might move in the future?

6
00:00:19,515 --> 00:00:24,915
Yes. So, one thing people do ask for on the research side is,

7
00:00:24,915 --> 00:00:27,835
when they're exploring new ideas,

8
00:00:27,835 --> 00:00:33,290
they don't want to be seeing like a Tenex drop in performance.

9
00:00:33,290 --> 00:00:34,865
So as an example,

10
00:00:34,865 --> 00:00:38,075
in PyTorch to provide an [inaudible] LSTM,

11
00:00:38,075 --> 00:00:41,310
which gives you a standard LSTM,

12
00:00:41,310 --> 00:00:46,265
you can configure the number of layers and what it does.

13
00:00:46,265 --> 00:00:52,430
It goes really fast because it uses GPU library called cuDNN,

14
00:00:52,430 --> 00:00:53,975
which was written by NVIDIA,

15
00:00:53,975 --> 00:01:03,540
and so it's about 10 times faster than if you just handwrite an LSTM with four loops.

16
00:01:03,680 --> 00:01:09,860
The problem that the researchers have been telling us about is that,

17
00:01:09,860 --> 00:01:13,430
if they want to try some new paper idea,

18
00:01:13,430 --> 00:01:16,955
this interface, the LSTM interface is very limiting,

19
00:01:16,955 --> 00:01:20,120
because let's say you wanted to do something like recurrent dropout,

20
00:01:20,120 --> 00:01:22,280
and [inaudible] LSTM doesn't support that,

21
00:01:22,280 --> 00:01:25,355
it only supports one formulation in particular.

22
00:01:25,355 --> 00:01:33,465
So, if they write it as a four loops and within LSTM cell,

23
00:01:33,465 --> 00:01:36,510
they see a 10 times slow down.

24
00:01:36,510 --> 00:01:36,960
I see.

25
00:01:36,960 --> 00:01:40,750
So, their request recently has been, "Hey,

26
00:01:40,750 --> 00:01:45,045
can we do our recurrent nets may be creative,

27
00:01:45,045 --> 00:01:49,905
at the same time can get something close to cuDNN performance?"

28
00:01:49,905 --> 00:01:52,860
That's an interesting request.

29
00:01:52,860 --> 00:01:57,680
Again, that comes in through the GIT investment that we did.

30
00:01:57,680 --> 00:02:02,840
We're trying to see if we can get users the speeds of

31
00:02:02,840 --> 00:02:10,935
cuDNN by stitching high-performers GPU kernels on the fly in the backend,

32
00:02:10,935 --> 00:02:15,255
based on what the users model is,

33
00:02:15,255 --> 00:02:17,425
that it looks promising.

34
00:02:17,425 --> 00:02:21,720
Those are requests that researchers have been asking for.

35
00:02:23,740 --> 00:02:31,170
One of the things that we heard from startups,

36
00:02:31,170 --> 00:02:35,515
and also people doing online courses,

37
00:02:35,515 --> 00:02:43,275
they want more interactive tutorials like based on iPython Notebooks.

38
00:02:43,275 --> 00:02:46,490
Also probably in embedding some digits.

39
00:02:46,490 --> 00:02:50,705
They want first-class integration with Colab,

40
00:02:50,705 --> 00:02:55,000
because you get free GPU [inaudible] .

41
00:02:55,000 --> 00:02:56,350
That's right.

42
00:02:56,350 --> 00:02:59,450
They've been asking for support for Google TPUs.

43
00:02:59,450 --> 00:03:03,330
These are all the request for getting and for handling all of them.

44
00:03:03,330 --> 00:03:06,050
Yes. It looks like the main cloud providers that I can

45
00:03:06,050 --> 00:03:09,005
think of are happy to support the latest versions.

46
00:03:09,005 --> 00:03:09,380
Yes.

47
00:03:09,380 --> 00:03:11,090
PyTorch for that reason.

48
00:03:11,090 --> 00:03:15,350
Yes. Amazon Azure, they made PyTorch a first-class citizen.

49
00:03:15,350 --> 00:03:19,875
Google announced support not only for PyTorch being a first-class citizen,

50
00:03:19,875 --> 00:03:25,430
GCP, but also they announced TPU support that we've been working with closely with them.

51
00:03:25,430 --> 00:03:26,155
Yes.

52
00:03:26,155 --> 00:03:31,115
Tensor Board is going to have PyTorch integration directly as well.

53
00:03:31,115 --> 00:03:31,800
That's great.

