
The book "A Byte of Python" has been all recroded in this note.

==
findgeneral                        Python general
findcomment                        Comment in Python
finddatatypes                      Data types
findescape                         Escape Sequences
findoperators                      Operators
findmath                           Math functions
findand                            and
findor                             or
findnot                            not
findprint                          print
findreadfrominput                  Read from input in terminal
findreadfromfile                   Read from file 
findwritetofile                    Write to file
findreadfromwebpage                Read from webpage
findwhile                          while
findif                             if
findcast                           cast
findround                          Round to nearest integer
findprecision                      Display a float with two decimal places:
findbreak                          break
findcontinue                       continue
findfor                            for
findrange                          range
findfunction                       function
findparameter                      Function parameters
findreturn                         The return Statement
findpass                           Pass statement
finddocstring                      DocStrings
findlocal                          Local variables
findglobal                         Global statement
findnonlocal                       Nonlocal statement
finddefaultargument                Default Argument Values
findkeywordargument                Keyword Arguments
findvararg                         VarArgs parameters
findkeywordonly                    Keyword- only Parameters
findmodule                         Modules
findtuple                          tuple
findlist                           list
finddictionary                     dictionary
findset                            set
findsequence                       sequences 
findnull                           null
findnone                           None
findstring                         string
findsubstring                      Return a substring, Determine whether a string contains a substring
findsplit                          Split a string
findprefix                         Whether a string start with a prefix
findstrip                          Strip a string (remove charaters at beginning and end)
findtrim                           Strip a string (remove charaters at beginning and end)
findjoinlisttostring               Join list to string
findargs                           Parse command line arguments  
findargv                           Parse command line arguments 
findclass                          class
findinheritance                    inheritance
finddestructor                     destructor
findgetter                         Getters and setters
findsetter                         Getters and setters
findexception                      Exceptions
findsleep                          sleep
findtime                           Output current local time
findnumpy                          NumPy
findrandomnumber                   Random number
findpandas                         Pandas
findreadcsv                        Read csv file to a dataframe
finddataframe                      DataFrame
findcreatedataframe                Create DataFrame
findrank                           Rank
findcorrelation                    Correlation
findaddcolumn                      Add a column
findplot                           Plot in Python, using matplotlib
finddates                          Dates in pandas
findjoin                           Join
findmerge                          Join, merge, concat
findconcat                         Join, merge, concat
finddropnan                        Drop the rows with NaN
findrenamecolumn                   Rename colum
findhead                           head
findtail                           tail
findslice                          Slice dataframe             
findselect                         Select rows and columns
findiloc                           iloc, loc, ix
findloc                            iloc, loc, ix
findix                             iloc, loc, ix
findmax                            Max
findstatistics                     Statistics functions
findlinearregression               Linear Regression
findpolyfit                        Polyfit
findsort                           Sort
findgroupby                        group by
findlen                            Number of rows in dataframe df
findsize                           Number of rows in dataframe df
findisnull                         isnull or missing values
findmissingvalues                  isnull or missing values
findnormalize                      Normalize
findsumcolumns                     Sum of all columns 
findmeancolumns                    Mean of all columns 


(endfind)

==
# Read the book "A Byte of Python" in full again in May 2018, and recorded all my notes in this file.

Features of Python (from Tao):

1. There is no ; at the end of each statement.
2. We can not randomly add spaces in front of a statement.
3. In "i = 5", there can be spaces between =
4. No need to declare data type for a variable like: int i = 5.

==
(findgeneral)                        
Python general

Portable:

Due to its open-source nature, Python has been ported to (i.e. changed to make it work on) many platforms. All your Python programs can work on any of these platforms without requiring any changes at all if you are careful enough to avoid any system-dependent features.

--
Interpreted:

A program written in a compiled language like C or C++ is converted from the source language i.e. C or C++ into a language that is spoken by your computer (binary code i.e. 0s and 1s) using a compiler with various flags and options. When you run the program, the linker/loader software copies the program from hard disk to memory and starts running it.

Python, on the other hand, does not need compilation to binary. You just run the program directly from the source code. Internally, Python converts the source code into an intermediate form called bytecodes and then translates this into the native language of your computer and then runs it. All this, actually, makes using Python much easier since you don't have to worry about compiling the program, making sure that the proper libraries are linked and loaded, etc, etc. This also makes your Python programs much more portable, since you can just copy your Python program onto another computer and it just works!

--
Python is strongly object-oriented in the sense that everything is an object including numbers, strings and functions.

--
To test if you have Python already installed on your Linux box:

$ python -V

If you have Python 2.x already installed, then try python3 -V

--
There are two ways of using Python to run your program - using the interactive interpreter
prompt or using a source file.

Using The Interpreter Prompt:

$ python
>>> print('Hello World')

$ python3
>>> print('Hello World')

To exit the prompt, press ctrl-d 

--
Like C++, unlike Java:
A file name can be different from the class name. A file can even have no class in it.

--
Using A Source File:

I follow the convention of having all Python programs saved with the extension .py

-- File helloworld.py starts --

#!/usr/bin/python
#Filename: helloworld.py
print('Hello World')

-- File helloworld.py ends --

Run the above program:

$ python helloworld.py

See below for the benefit of specifying the interpreter at the beginning of the file

--
Executable Python Programs:

First, we have to give the program executable permission using the chmod command then run the source program.

$ chmod a+x helloworld.py
$ ./helloworld.py

The chmod command is used here to change the mode of the file by giving execute permission to all users of the system.

--
Tao: the benefit of specifying the interpreter at the beginning of the file:

You can rename the file to just helloworld and run it as ./helloworld and it will still work since the system knows that it has to run the program using the interpreter whose location is specified in the first line in the source file.

What if you don't know where Python is located? Then, you can use the special env program on Linux/Unix systems. Just change the first line of the program to the following:

#!/usr/bin/env python

The env program will in turn look for the Python interpreter which will run the program.

--
Python does not use comments except for the special case of the first line here (#!/usr/bin/python). It is called the shebang line - whenever the first two characters of the source file are #! followed by the location of a program, this tells your Linux/Unix system that this program should be run with this interpreter when you execute the program.

W.r.t. Python, a program or a script or software all mean the same thing.

--
If you want to specify more than one logical line on a single physical line, then you have to
explicitly specify this using a semicolon (;) which indicates the end of a logical
line/statement. For example:

i = 5; print(i);

An example of writing a logical line spanning many physical lines follows. This is referred to
as explicit line joining.
s = 'This is a string. \
This continues the string.'
print(s)

This gives the output:
This is a string. This continues the string.
Similarly,
print\
(i)
is the same as
print(i)

--
Indentation

Statements which go together must have the same indentation. Each such set of statements is called a block

I strongly recommend that you use a single tab or four spaces for each indentation level.

Python will always use indentation for blocks and will never use braces.

In the above file (helloworld.py), ensure there are no spaces or tabs before the first character in each line

--
What if we wanted to be able to run the program from anywhere? 

You can do this by storing the program in one of the directories listed in the PATH environment variable. Whenever you run any program, the system looks for that program in each of the directories listed in the PATH environment variable and then runs that program. We can make this program available everywhere by simply copying this source file to one of the directories listed in PATH.

$ echo $PATH
/usr/local/bin:/usr/bin:/bin:/usr/X11R6/bin:/home/swaroop/bin

$ cp helloworld.py /home/swaroop/bin/helloworld

$ helloworld
Hello World

We see that /home/swaroop/bin is one of the directories in the PATH variable

Alternatively, you can add a directory of your choice to the PATH variable - this can be done by running PATH=$PATH:/home/swaroop/mydir

This method is very useful if you want to write useful scripts that you want to run the program anytime, anywhere. It is like creating your own commands just like cd or any other commands that you use in the Linux terminal or DOS prompt.

--
Python is case-sensitive

--
(findcomment)
Comment in Python:

Anything to the right of the # symbol is a comment

--
If you need quick information about any function or statement in Python, then you can use the built-in help functionality. This is very useful especially when using the interpreter prompt. For example, run help(print) - this displays the help for the print function which is used to print things to the screen. Use help() to learn
more about using help itself! In case you need to get help for operators like return, then you need to put those inside quotes such as help('return') so that Python doesn't get confused on what we're trying to do.

Press q to exit the help.

==
(finddatatypes)
Data types:

# Show data type:
i = 123
type(i)
# Displays: <type 'int'>

# Convert string to int:
x = '123456'
i = int(x)

# Convert int to string:
str(10) # Returns: '10'

Numbers:

Numbers in Python are of three types - integers, floating point (or floats for short) and complex numbers.

Examples:

Integer: 2
Float: 3.23, 52.3E-4.
Complex number: (-5+4j), (2.3 - 4.6j)

The default integer type can be any large value.

Boolean:

The True and False are called Boolean types and you can consider them to be equivalent to the value 1 and 0 respectively.

if True:
    print('Yes, it is true')

--
Print the type of a variable:

>>> i = 123
>>> type(i)
<type 'int'>
>>> type(i) is int
True

==
(findnull)
(findnone)
None

与C不同的是，在python中是没有NULL的，取而代之的是None，它的含义是为空，但要注意和空列表与空字符串的区别，None的类型是Nonetype

>>>a=None
>>>type(a)
<class 'Nonetype'>

另外，None是没有像len,size等属性的，要判断一个变量是否为None，直接使用
if a == None. 

Same as C++:
"if a" is equivalent to "if a != None"
"if not a" is equivalent to "if a == None"

再者，注意None与布尔类型的区别，布尔类型只包括两个：True和False（注意它的大小写）
但python是把0，空字符串‘ ’和None都看作False，把其他数值和非空字符串都看作True

==
(findstring)
String

name = 'john'

len(str) # Length of str

--
(findsubstring)

** Return substring:

To return a substring from a string, search for "find sequence",
this is also what people did online.

** Whether contains substring:

Determine whether a string contains a substring:
substr in str # Returns True if str contains substr, otherwise false.

** Position of substring:

str1 = "this is string example....wow!!!";
str2 = "exam";

print str1.find(str2) # Returns: 15 <- the index of 'e' in str1

** 

--
(findsplit)
Split a string

split() method returns a list of strings after breaking the given string by the specified separator.

# Splits at space
text = 'geeks for geeks'
text.split() # Returns: ['geeks', 'for', 'geeks']
 
# Splits at ',' 
word = 'geeks, for, geeks'
word.split(', ') # Returns: ['geeks', 'for', 'geeks']

--
(findstrip)
(findtrim)
Strip a string (remove charaters at beginning and end)

str.strip() removes all whitespace at the start and end, including spaces, tabs, newlines and carriage returns. Leaving it in doesn't do any harm, and allows your program to deal with unexpected extra whitespace inserted into the file.

# str.strip([chars]): 相當於Java中的trim(), returns a copy of the string in which all chars have been stripped(即removed) from the beginning and the end of the string (default whitespace characters).

str = "0000000this is string example....wow!!!0000000";
str.strip('0') # Returns: "this is string example....wow!!!"

--
(findprefix)
Whether a string start with a prefix

The method startswith() checks whether string starts with str

str = "this is string example"
str.startswith('this') # Returns True

--
(findjoinlisttostring)
Join list to string

delimiter = '_*_'
mylist = ['Brazil', 'Russia', 'India', 'China']
delimiter.join(mylist) # Returns 'Brazil_*_Russia_*_India_*_China'

--
(findargs)   
(findargv)    
Parse command line arguments   

** Simple way **

import sys

for i in sys.argv:
    print(i)

$ python using_sys.py we are arguments

using_sys.py
we
are
arguments

** Complicated way **

File prog.py:

import optparse
parser = optparse.OptionParser()
parser.add_option('-q', '--query', action="store", dest="query") # Tao: dest="query" means the input argument is stored in options.query.
options, args = parser.parse_args()
print 'Query string=', options.query

Using the file prog.py:

python prog.py -q helo
# Output: Query string= helo

python prog.py --query helo 
# Output: Query string= helo

--
Single Quotes:
You can specify strings using single quotes such as 'Quote me on this'.

Double Quotes:
Strings in double quotes work exactly the same way as strings in single quotes. An example
is "What's your name?"

Triple Quotes:
You can specify multi-line strings using triple quotes - (""" or '''). You can use single quotes
and double quotes freely within the triple quotes. An example is:
'''This is a multi-line string. This is the first line.
This is the second line.
"What's your name?," I asked.
He said "Bond, James Bond."
'''

--
Reverse a string: nameStr[::-1]

--
# The format function does not only applies to print, but applies to all strings:

name = "Tao"
s = "My name is {}".format(name) 

--
(findescape)
Escape Sequences:

You specify the single quote as \'
Now, you can specify the string as 'What\'s your name?'

What if you wanted to specify a two-line string? One way is to use a triple-quoted string as shown previously or you can use an escape sequence for the newline character - \n to indicate the start of a new line.

One thing to note is that in a string, a single backslash at the end of the line indicates that the string is continued in the next line, but no newline is added. For example:
"This is the first sentence.\
This is the second sentence."
is equivalent to "This is the first sentence. This is the second sentence.".

--
Raw Strings
If you need to specify some strings where no special processing such as escape sequences are handled, then what you need is to specify a raw string by prefixing r or R to the string. An example is r"Newlines are indicated by \n".

Always use raw strings when dealing with regular expressions. Otherwise, a lot of backwhacking may be required. For example, backreferences can be referred to as '\\1' or r'\1'.

--
Strings Are Immutable
This means that once you have created a string, you cannot change it.

--
String Literal Concatenation
If you place two string literals side by side, they are automatically concatenated by Python.
For example, 'What\'s ' 'your name?' is automatically converted in to "What's your name?".

--
There is no separate char data type in Python. There is no real need for it and I am sure you won't miss it.

--
The format Method

Sometimes we may want to construct strings from other information. This is where the format() method is useful. The format method can be called to substitute those specifications with corresponding arguments to the format method.

age = 25
name = 'Swaroop'
print('{0} is {1} years old'.format(name, age)) # Output: Swaroop is 25 years old
print('Why is {0} playing with that python?'.format(name)) # Output: Why is Swaroop playing with that python?

Notice that we could achieved the same using string concatenation: name + ' is ' + str(age) + ' years old' but notice how much uglier and error-prone this is.

More examples of format method:

>>> '{0:.3}'.format(1/3) # decimal (.) precision of 3 for float
'0.333'

>>> '{0:_^11}'.format('hello') # fill with underscores (_) with the text centered (^) to 11 width
'___hello___'

>>> '{name} wrote {book}'.format(name='Swaroop', book='A Byte of Python') # keyword-based
'Swaroop wrote A Byte of Python'

==
(findoperators)
Operators

Evaluation order:
Remember (same as Java and C++):
->||

There are no ++ and -- operators in Python.
x++ can be written as x += 1 and x-- can be written as x -= 1 <- tao: so there are += and -= operators in Python.

Shortcut:
a *= 3
is equivalent as
a = a * 3

Power:
3 ** 4 gives 3 * 3 * 3 * 3

Divide:
4 / 3 gives 1.3333333333333333, not 1!

Floor Division:
4 // 3 gives 1

Modulus:
5 % 2 gives 1

(findand)
(findor)
(findnot)
Bitwise AND: &
Bit-wise OR: |

Boolean AND: and
Boolean OR:  or 
Boolean NOT: not

Less Than: <
Less Than or Equal To: <=

Equal To: ==
x = 'str'; 
y = 'str'; 
x == y returns True.

Not Equal To: !=

Right Shift: >>
11 >> 1 gives 5. 11 is represented in bits by 1011 which when right shifted by 1 bit gives 101 which is the decimal 5.

Left Shift: <<

==
(findmath)
Math functions

import math 
math.exp(-45.17) # The method exp() returns returns exponential of x: e^x.
math.sqrt(100)

==
(findprint)
print

A better way to print without using format (from online and tao's experiment):

a = 1
b = 2
print('a =', a) # Output: a = 1
print('a = ', a, ', b = ', b, sep="") # Output: a = 1, b = 2

--
age = 25
age *= 2
name = 'John'
print(age)
print('{0} is speaking'.format(name))
print('{0} is {1} years old'.format(name, age))
print('{name} is {age} years old'.format(name = 'Kevin', age = 40))
print('Age is', age) # Output: Age is 25, note a space is added between "Age is" and "25".

By deafult, the print() function prints the text as well as an automatic newline to the screen. Tao: to override it, use this:
print(line, end = 'a')
this makes the newline character replaced by 'a'.

--
From online:

print in Python 3 vs Python 2:

Old: print "The answer is", 2*2
New: print("The answer is", 2*2)

Old: print x,           # Trailing comma suppresses newline
New: print(x, end=" ")  # Appends a space instead of a newline

Old: print              # Prints a newline
New: print()            # You must call the function!

==
(findreadfrominput)
Read from input in terminal

# something = input('Enter text: ') //Prints "Enter text: " to the screen and waits for input from the user.
# Enter text: sir // sir是用户從鍵盤輸入的, 然後something就等於sir了

==
(findreadfromfile)
Read from file 

file = open('poem.txt') # if no mode is specified, 'r'ead mode is assumed by default

while True:
    line = file.readline()
    if len(line) == 0: # Zero length indicates EOF
        break
    print(line, end = '') # Suppress the newline at end of each output line, see more below.
file.close() # close the file

By deafult, the print() function prints the text as well as an automatic newline to the screen. We are suppressing the newline by specifying end='' because the line that is read from the file already ends with a newline character.

==
(findwritetofile)
Write to file

Write to file:

f = open('poem.txt', 'w') # w: write mode. r: read mode. a: append mode.
f = open('poem.txt', 'w+') # w+: the + sign that means it will create a file if it does not exist
f.write('helo') # write text to file
f.close() # close the file

Determine whether a file exists:

import os
os.path.exists('/this/is/a/dir') # Returns true for directories, not just files.

==
(findreadfromwebpage)
Read from webpage:

link = "https://stackoverflow.com/questions/15138614/how-can-i-read-the-contents-of-an-url-with-python"
f = urllib.urlopen(link)
myfile = f.read()
print myfile

==
(findwhile)
(findif)
(findcast)
(findbreak)
(findcontinue)
(findtrue)

while, if, cast, break, continue, True

number = 1
running = True

while running:
    #guess = int(input("Input a number: ")) //由此可知, int(str)可以將 string類型的str 轉化為int
    guess = 1

    if guess == number:
        print("That's right.")
        running = False
    elif guess > number:
        print('Too big.')
        break
    else:
        print('Too small.')
        continue
else:
    print('The while loop is over.') // A while statement can have an optional else clause. The else block is executed when the while loop condition becomes False

There is no switch statement in Python.

The continue statement is used to tell Python to skip the rest of the statements in the current loop block and to continue to the next iteration of the loop.

The break statement is used to break out of a loop statement i.e. stop the execution of a looping statement, even if the loop condition has not become False or the sequence of items has been completely iterated over.

An important note is that if you break out of a for or while loop, any corresponding loop else block is not executed.

--
(findround)
Round to nearest integer:

int(round(x))

--
(findprecision)
Display a float with two decimal places:

>>> '%.2f' % 1.234
'1.23'

>>> '%.2f' % 5.0
'5.00'

==
(findfor)
(findrange)
for, range

for i in range(1, 5): # range(1, 5)是一個sequence: [1, 2, 3, 4]. 它包括1, 但不包括5! range(1,5,2) = [1,3].
    print(i)

Remember that the for..in loop works for any sequence. Here, we have a list of numbers generated by the built-in range function, but in general we can use any kind of sequence of any kind of objects!

--
fruits = ['banana', 'apple',  'mango']

for fruit in fruits:        
   print fruit

--
Question:

Is there a way to step between 0 and 1 by 0.1?

I thought I could do it like the following, but it failed:

for i in range(0, 1, 0.1):
    print i
Instead, it says that the step argument cannot be zero, which I did not expect.

Answer:

Rather than using a decimal step directly, it's much safer to express this in terms of how many points you want. Otherwise, floating-point rounding error is likely to give you a wrong result.

You can use the linspace function from the NumPy library (which isn't part of the standard library but is relatively easy to obtain). linspace takes a number of points to return, and also lets you specify whether or not to include the right endpoint:

>>> np.linspace(0,1,11)
array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])
>>> np.linspace(0,1,10,endpoint=False)
array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])
If you really want to use a floating-point step value, you can, with numpy.arange.

>>> import numpy as np
>>> np.arange(0.0, 1.0, 0.1)
array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])
Floating-point rounding error will cause problems, though. Here's a simple case where rounding error causes arange to produce a length-4 array when it should only produce 3 numbers:

>>> numpy.arange(1, 1.3, 0.1)
array([1. , 1.1, 1.2, 1.3])

==
(findfunction)
function

def sayHello():
    print('Hello World!')

sayHello() # Call the function

def fahrenheit(value):
    return (value * 9 / 5) + 32

Tao: from above and below, Python also uses naming conventions like sayHello (Java style), rather than say_hello (C++ style).

--
(findparameter)
Function parameters:

Note the terminology used - the names given in the function definition are called parameters whereas the values you supply in the function call are called arguments.

def printMax(a, b):
    if a > b:
        print(a, 'is maximum')
    elif a == b:
        print(a, 'is equal to', b)
    else:
        print(b, 'is maximum')

printMax(3, 4)

x = 5
y = 7
printMax(x, y)

--
(findreturn)
The return Statement

def maximum(x, y):
    if x > y:
        return x
    else:
        return y

maximum(2, 3) //Returns 3

Note that a return statement without a value is equivalent to return None. None is a special type in Python that represents nothingness. For example, it is used to indicate that a variable has no value if it has a value of None.

Every function implicitly contains a return None statement at the end unless you have written your own return statement. 

--
(findpass)
Pass statement

def someFunction():
    pass

The pass statement is used in Python to indicate an empty block of statements.

--
(finddocstring)
DocStrings

Python has a nifty feature called documentation strings, usually referred to by its shorter name docstrings. DocStrings are an important tool that you should make use of since it helps to document the program better and makes it easier to understand.

A string on the first logical line of a function is the docstring for that function. Note that DocStrings also apply to modules and classes.

The convention followed for a docstring is a multi-line string where the first line starts with a capital letter and ends with a dot. Then the second line is blank followed by any detailed explanation starting from the third line. You are strongly advised to follow this convention for all your docstrings for all your non-trivial functions.

We can access the docstring of the printMax function using the __doc__ (notice the double underscores) attribute (name belonging to) of the function.

If you have used help() in Python, then you have already seen the usage of docstrings! What it does is just fetch the __doc__ attribute of that function and displays it in a neat manner for you. You can try it out on the function above - just include help(printMax) in your program. Remember to press the q key to exit help.

def printMax(x, y):
    '''Prints the maximum of two numbers.

    The two values must be integers.'''
    x = int(x) # convert to integers, if possible
    y = int(y)

    if x > y:
        print(x, 'is maximum')
    else:
        print(y, 'is maximum')

printMax(3, 5) # Output: 5 is maximum

print(printMax.__doc__)
# Output:
Prints the maximum of two numbers.

    The two values must be integers.

We can use docstrings for classes as well as methods. We can access the class docstring at runtime using Robot.__doc__ and the method docstring as Robot.sayHi.__doc__

--
(findlocal)
Local variables

When you declare variables inside a function definition, they are not related in any way to other variables with the same names used outside the function i.e. variable names are local to the function. This is called the scope of the variable. All variables have the scope of the block they are declared in starting from the point of definition of the name.

x = 50

def func(x):
    print('x is', x) # Output: x is 50
    x = 2
    print('Changed local x to', x) # Output: Changed local x to 2

func(x)
print('x is still', x) # Output: x is still 50

--
(findglobal)
Global statement

If you want to assign a value to "a name defined at the top level of the program" (i.e. not inside any kind of scope such as functions or classes), then you have to tell Python that the name is not local, but it is global. We do this using the global statement. It is impossible to assign a value to a variable defined outside a function without the global statement.

x = 50

def func():
    global x
    print('x is', x) # Output: x is 50
    x = 2
    print('Changed global x to', x) # Output: Changed global x to 2

func()
print('Value of x is', x) # Output: Value of x is 2

--
(findnonlocal)
Nonlocal statement

We have seen how to access variables in the local and global scope above. There is another kind of scope called "nonlocal" scope which is in-between these two types of scopes. Nonlocal scopes are observed when you define functions inside functions. Since everything in Python is just executable code, you can define functions anywhere.

def func_outer():
    x = 2
    print('x is', x) # Output: x is 2

    def func_inner():
        nonlocal x
        x = 5

    func_inner()

    print('Changed local x to', x) # Output: Changed local x to 5

func_outer()

--
(finddefaultargument)
Default Argument Values

For some functions, you may want to make some of its parameters as optional and use default values if the user does not want to provide values for such parameters. This is done with the help of default argument values.

Only those parameters which are at the end of the parameter list can be given default argument values. This is because the values are assigned to the parameters by position.

def say(message, times = 1):
    print(message * times)

say('Hello') # Output: Hello
say('World', 5) # Output: WorldWorldWorldWorldWorld

--
(findkeywordargument)
Keyword Arguments

If you have some functions with many parameters and you want to specify only some of them, then you can give values for such parameters by naming them - this is called keyword arguments - we use the name (keyword) instead of the position (which we have been using all along) to specify the arguments to the function.

We can give values to only those parameters which we want, provided that the other parameters have default argument values.

def func(a, b=5, c=10):
    print('a is', a, 'and b is', b, 'and c is', c)

func(3, 7) # Output: a is 3 and b is 7 and c is 10
func(25, c=24) # Output: a is 25 and b is 5 and c is 24
func(c=50, a=100) # Output: a is 100 and b is 5 and c is 50

--
(findvararg)
VarArgs parameters

Sometimes you might want to define a function that can take any number of parameters, this can be achieved by using the stars:

def total(initial=5, *numbers, **keywords):
    count = initial
    for number in numbers:
        count += number
    for key in keywords:
        count += keywords[key]
    return count

total(10, 1, 2, 3, vegetables=50, fruits=100)
      --  -------  -------------------------
  initial numbers              keywords
          (numbers is a list)  (keywords is a dictionary)


When we declare a starred parameter such as *param, then all the positional arguments from that point till the end are collected as a list called 'param'.

Similarly, when we declare a double-starred parameter such as **param, then all the keyword arguments from that point till the end are collected as a dictionary called 'param'.

--
(findkeywordonly)
Keyword- only Parameters

If we want to specify certain keyword parameters to be available as keyword-only and not as positional arguments, they can be declared after a starred parameter:

def total(initial=5, *numbers, vegetables):
    count = initial
    for number in numbers:
        count += number
    count += vegetables
    return count

total(10, 1, 2, 3, vegetables=50)
total(10, 1, 2, 3) # Raises error because we have not supplied a default argument value for 'vegetables'

Declaring parameters after a starred parameter results in keyword-only arguments. If these arguments are not supplied a default value (Tao: in the function definition), then calls to the function will raise an error if the keyword argument is not supplied, as seen above.

If you want to have keyword-only arguments but have no need for a starred parameter, then simply use an empty star without using any name such as def total(initial=5, *, vegetables).

==
(findmodule)
Modules

Tao: modules in Python is like packages in Java and Scala.

What if you wanted to reuse a number of functions in other programs that you write? The answer is modules.

There are various methods of writing modules, but the simplest way is to create a file with a .py extension that contains functions and variables.

Another method is to write the modules in the native language in which the Python interpreter itself was written. For example, you can write modules in the C programming language and when compiled, they can be used from your Python code when using the standard Python interpreter.

A module can be imported by another program to make use of its functionality. This is how we can use the Python standard library as well. First, we will see how to use the standard library modules.

Example:

#!/usr/bin/python
# Filename: using_sys.py

import sys

print('The command line arguments are:')
for i in sys.argv:
    print(i)

print('\n\nThe PYTHONPATH is', sys.path, '\n')

$ python using_sys.py we are arguments

The command line arguments are:
using_sys.py
we
are
arguments
The PYTHONPATH is ['', 'C:\\Windows\\system32\\python30.zip',
'C:\\Python30\\DLLs', 'C:\\Python30\\lib',
'C:\\Python30\\lib\\plat-win', 'C:\\Python30',
'C:\\Python30\\lib\\site-packages']

When Python executes the import sys statement, it looks for the sys module. In this case, it is one of the built-in modules, and hence Python knows where to find it.

If it was not a compiled module i.e. a module written in Python, then the Python interpreter will search for it in the directories listed in its sys.path variable. If the module is found, then the statements in the body of that module is run and then the module is made available for you to use. Note that the initialization is done only the first time that we import a module.

The sys.argv variable is a list of strings. Python stores the command line arguments in the sys.argv variable for us to use.

Remember, the name of the script running is always the first argument in the sys.argv list. Notice that Python starts counting from 0 and not 1.

The sys.path contains the list of directory names where modules are imported from. Observe that the first string in sys.path is empty - this empty string indicates that the current directory is also part of the sys.path which is same as the PYTHONPATH environment variable. This means that you can directly import modules located in the current directory. Otherwise, you will have to place your module in one of the directories listed in sys.path. 

--
from . . . import . . .

Tao: in the above, even you imported sys, you still need to type sys.argv rather than only argv each time.

If you want to directly import the argv variable into your program (to avoid typing the
sys. everytime for it), then you can use the 
from sys import argv 
statement. 

If you want to import all the names used in the sys module, then you can use the 
from sys import *
statement. This works for any module. In general, you should avoid using this statement and use the import statement instead since your program will avoid name clashes and will be more readable.

--
Making Your Own Modules

Creating your own modules is easy, you've been doing it all along! This is because every
Python program is also a module. You just have to make sure it has a .py extension.

Example:

#!/usr/bin/python
# Filename: mymodule.py

def sayhi():
    print('Hi, this is mymodule speaking.')

__version__ = '0.1'

# End of mymodule.py

The above was a sample module. As you can see, there is nothing particularly special about
compared to our usual Python program.

Remember that the module should be placed in the same directory as the program that we
import it in, or the module should be in one of the directories listed in sys.path.

#!/usr/bin/python
# Filename: mymodule_demo.py

import mymodule
mymodule.sayhi()

print ('Version', mymodule.__version__)

$ python mymodule_demo.py
Hi, this is mymodule speaking.
Version 0.1

Here is a version utilising the from..import syntax:
#!/usr/bin/python
# Filename: mymodule_demo2.py

from mymodule import sayhi, __version__

sayhi()
print('Version', __version__)

You could also use:
from mymodule import *
This will import all public names such as sayhi but would not import __version__
because it starts with double underscores.

--
How to import module from different folder (from online):

By default, you can't. When importing a file, Python only searches the current directory, the directory that the entry-point script is running from, and sys.path which includes locations such as the package installation directory (it's actually a little more complex than this, but this covers most cases).

However, you can add to the Python path at runtime:

# some_file.py
import sys
sys.path.append('/path/to/application/app/folder')

import file

==
Byte- compiled .pyc files

Importing a module is a relatively costly affair, so Python does some tricks to make it faster. One way is to create byte-compiled files with the extension .pyc which is an intermediate form that Python transforms the program into. This .pyc file is useful when you import the module the next time from a different program - it will be much faster since a portion of the processing required in importing a module is already done. Also, these byte-compiled files are platform-independent.

--
_ _ name_ _

Every module has a name. This is handy in the particular situation of figuring out if the module is being run standalone or being imported. As mentioned previously, when a module is imported for the first time, the code in that module is executed. We can use this concept to alter the behavior of the module if the program was used by itself and not when it was imported from another module. This can be achieved using the __name__ attribute of the module.

Example:
#!/usr/bin/python
# Filename: using_name.py
if __name__ == '__main__':
    print('This program is being run by itself')
else:
    print('I am being imported from another module')

$ python using_name.py
This program is being run by itself

$ python
>>> import using_name
I am being imported from another module

--
dir

When you supply a module name to the dir() function, it returns the list of the names
defined in that module. When no argument is applied to it, it returns the list of names
defined in the current module.

==
Packages

What if you wanted to organize modules? That's where packages come into the
picture.

Packages are just folders of modules with a special __init__.py file that indicates to
Python that this folder is special because it contains Python modules.

==
Data Structures

There are four built-in data structures in Python - list, tuple, dictionary and set.

tuple用(), list用[], dictionary用{}, 它們依次是 小中大 括號

Python uses 0-based indexing
R uses 1-based indexing

==
(findtuple)
tuple

Tao: tuple is like array in C++

tuples are immutable.

The pair of parentheses in tuples is optional.

zoo = ('monkey', 'tiger', 'cat')
a = len(zoo)
b = zoo[0]
print(zoo)

newZoo = ('pig', 'dog', zoo) # newZoo = ('monkey', 'camel', ('python', 'elephant', 'penguin'))
newZoo[2] # Returns ('python', 'elephant', 'penguin')
newZoo[2][2] # Returns 'penguin'
len(newZoo)
len(newZoo[2])

emptyTuple = ()
singleton = (2, ) # A tuple containing the item 2 (only one item). Must define like this. (2) means a pair of parentheses surrounding the object in an expression (tao: like an arithmetic expression (2 + 1)).

# passing tuples around:
def func():
    return (3, 'helo')

num, s = func()

Can define a tuple within a tuple, or a tuple within a list, or a list within a tuple.

==
(findlist)
list

Tao: list is like vector in C++

Lists are mutatble. 
You can add, remove or search for items in the list. we say that a list is a mutable data type

The list of items should be enclosed in square brackets.

odd = [1, 3, 5]
odd.append(7)
print(odd) # Output: [1, 3, 5, 7]

shoplist = ['apple', 'mango', 'orange']
a = shoplist[0]
b = len(shoplist)

shoplist.append('banana')
shoplist.sort()
print(shoplist)

for item in shoplist:
    print(item, end=' ') #加end=' '是因為print()函數會自動在 print出的東西的 末尾加一個newline character, end=' '的作用就是將這個newline character換成空格.

del shoplist[0] #將shoplist的第0個元素 從shoplist中 刪掉

# using lists as stacks (from online):
stack = [3, 4, 6]
stack.append(6) #相當於push <- It adds 6 to the original list "stack", and it returns nothing.
stack.pop()

stackNew = stack + [40] <- This returns a new list

# using lists as queues (from online):
from collections import deque
queue = deque(["Eric", "John", "Michael"])
queue.append("Terry") #相當於offer
queue.popleft() #相當於poll

list1 = [3, 4, 6]
a = sum(list1)
b = max(list1)
c = min(list1)

# empty list
my_list = []

==
(finddictionary)
dictionary

Tao: dictionary is like map in C++

ages = {'John' : 30, 'Mary' : 40}
a = ages['John']
b = len(ages)
del ages['John']
ages['Mary'] = 20 # update
ages['Kate'] = 40 # add an item
new_dict = {} # Create an empty dictionary

# Traverse a dictionary:
for name, age in ages.items(): #不是 for name : age ...
    print('{0} is {1} years old'.format(name, age))

# Existence of key in dictionary:
if 'Mary' in ages: # if ages contains key 'Mary'
    print('Has Mary.')

Remember that key-value pairs in a dictionary are not ordered in any manner. If you want a particular order, then you will have to sort them yourself before using it.

==
list and dictionary as function parameter

def total(count, *numbers, **keywords):
    for i in numbers:
        count += i
    for key in keywords:
        count += keywords[key]
    return count

print(total(0, 1, 2, 3, John=4, Jack=5))

==
(findset)
set

bric = set(['brazil', 'russia', 'india']) # A set is initialized from a list
'india' in bric # 相當於Java中的bri.contains('india')
bric.add('china')
bric.remove('china')
bric.issuperset(bri) # bri is also a set
bri & bric # OR bri.intersection(bric)
bricNew = bric.copy()

Sets are unordered.

==
(findsequence)
sequences 

Lists, tuples and strings are examples of sequences. The major features of sequences is that they have membership tests (i.e. the in and not in expressions) and indexing operations. 

Sequences also have a slicing operation which allows us to retrieve a slice of the sequence i.e. a part of the sequence.

name = 'jan'
name[-1] # Returns 'n'
name[4] # 報錯: IndexError: string index out of range
name[1:3]  #包括name[1], 但不包括name[3]
name[2:]
name[:] # a copy of the whole sequence
name[::2] # 2 is the step
name[:-1] # Returns a slice of the sequence which excludes the last item of the sequence but contains everything else.
name[::-1] # Reverse the sequence


==
(findclass)
class

Tao: about self:
1. In a class, all member methods should have a self parameter: def funcName(self, x, y). When calling this method, no need to insantiate this self parameter: funcName(2, 3).
2. In a class, when using its own member variables or methods, should add self: self.variableName, self.func(). This is true even when a member function in a class calls itself recursively, it still needs to add self.

Tao: in a class, no need to define its member variables. Any variables can jump out suddenly like the self.name below.

Tao: there is no way to overload __init__ method in Python (confirmed from online). We need to use tricks to overload it or avoid having the desire to overload it.

# Example class 1:

class Person:
    # 這是constructor. self相當於Java中的this:
    def __init__(self, name): 
        self.name = name 
    
    def sayHi(self):
        print('Hi', self.name) 
    
    #def sayHello(): //Avadoles!!! 報錯, 因為所有class method必加self參數. 實踐表明, static methd不用加self參數
    #    print('Hello')

p = Person('John')
p.sayHi()

# Example class 2:

class Animal():
    pass # An empty block

anim = Animal()

Self: although, you can give any name for this parameter, it is strongly recommended that you
use the name self.

All class memembers (including the data memebers) are public. If you use data members with names using the double underscore prefix such as __privatevar, Python uses name-mangling to effectively make it a private variable.

fields vs variables, methods vs functions:

Variables that belong to an object or class are referred to as fields. Functions that belong to a class: such functions are called methods of the class. This terminology is important because it helps us to differentiate between functions and variables which are independent and those which belong to a class or object.

Tao: Functions can be out of class in Python.

--
Class And Object Variables

There are two types of fields - class variables and object variables:

Class variables are shared - they can be accessed by all instances of that class. There is only one copy of the class variable and when any one object makes a change to a class variable, that change will be seen by all the other instances. Tao: this is like static variable in Java.

Object variables are owned by each individual object/instance of the class. In this case, each object has its own copy of the field i.e. they are not shared and are not related in any way to the field by the same name in a different instance.

Example:

class Robot:
    # A class variable, counting the number of robots
    # Tao: therefore, do not explicitly define variables in a class unless you want to make it a class variable
    population = 0

    def __init__(self, name):
        self.name = name # Tao: self.name is an object variable
        print('Initializing {0}'.format(self.name))

        # When this person is created, the robot adds to the population
        Robot.population += 1

    def __del__(self):
        print('{0} is being destroyed!'.format(self.name))

        Robot.population -= 1

        if Robot.population == 0:
            print('{0} was the last one.'.format(self.name))
        else:
            print('There are still {0:d} robots working.'.format(Robot.population))

    def howMany():
        print('We have {0:d} robots.'.format(Robot.population))

    howMany = staticmethod(howMany)

droid1 = Robot('R2-D2') #Output: Initializing R2-D2)
Robot.howMany() #Output: We have 1 robots.

droid2 = Robot('C-3PO') #Output: Initializing C-3PO)
Robot.howMany() #Output: We have 2 robots.

del droid1 #Output: R2-D2 is being destroyed! (newline) There are still 1 robots working.
del droid2 #Output: C-3PO is being destroyed! (newline) C-3PO was the last one.
Robot.howMany() #Output: We have 0 robots.

Here, population belongs to the Robot class and hence is a class variable. The name variable belongs to the object (it is assigned using self) and hence is an object variable.

Thus, we refer to the population class variable as Robot.population and not as self.population. We refer to the object variable name using self.name notation in the methods of that object.

The howMany is actually a method that belongs to the class and not to the object. This means we can define it as either a classmethod or a staticmethod depending on whether we need to know which class we are part of. Since we don't need such information, we will go for staticmethod.

We could have also achieved the same using decorators. Decorators can be imagined to be a shortcut to calling an explicit statement:

@staticmethod
def howMany():
    print('We have {0:d} robots.'.format(Robot.population))

(finddestructor)
The __del__ method (see example above) is run when the object is no longer in use and there is no guarantee when that method will be run. If you want to explicitly see it in action, we have to use the del statement which is what we have done here.

==
(findinheritance)
Inheritance

       SchoolMember 
            |
     ------------------        
    |                  |
 Teacher             Student

class SchoolMember:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    def tell(self):
        print('Name:"{0}" Age:"{1}"'.format(self.name, self.age), end=" ")

class Teacher(SchoolMember):
    def __init__(self, name, age, salary):
        SchoolMember.__init__(self, name, age)
        self.salary = salary

    def tell(self):
        SchoolMember.tell(self)
        print('Salary: "{0:d}"'.format(self.salary))

class Student(SchoolMember):
    def __init__(self, name, age, marks):
        SchoolMember.__init__(self, name, age)
        self.marks = marks

    def tell(self):
        SchoolMember.tell(self)
        print('Marks: "{0:d}"'.format(self.marks))

t = Teacher('Mrs. Shrividya', 40, 30000)
s = Student('Swaroop', 25, 75)

members = [t, s]

for member in members:
    member.tell() # works for both Teachers and Students

# Output:
Name:"Mrs. Shrividya" Age:"40" Salary: "30000"
Name:"Swaroop" Age:"25" Marks: "75"

Inherit from multiply classes: class Teacher(SchoolMember, Buyer, UncleFucker)

This is very important to remember - Python does not automatically call the constructor of the base class, you have to explicitly call it yourself.

Best illurstration of polymorphism:
You can refer to a Teacher or Student object as a SchoolMember object which could be useful in some situations such as counting of the number of school members. This is called polymorphism where a sub-type can be substituted in any situation where a parent type is expected i.e. the object can be treated as an instance of the parent class.

==
(findgetter)
(findsetter)
Getters and setters:

What's the pythonic way to use getters and setters?

The "Pythonic" way is not to use "getters" and "setters", but to use plain attributes, like the question demonstrates, and del for dereferencing (but the names are changed to protect the innocent... builtins).

The sample code is:

class C(object):
    def __init__(self):
        self._x = None

    @property
    def x(self):
        """I'm the 'x' property."""
        print("getter of x called")
        return self._x

    @x.setter
    def x(self, value):
        print("setter of x called")
        self._x = value

    @x.deleter
    def x(self):
        print("deleter of x called")
        del self._x


c = C()
c.x = 'foo'  # setter called
foo = c.x    # getter called
del c.x      # deleter called

==
References

When you create an object and assign it to a variable, the variable only refers to the object and does not represent the object itself. Tao: same as Java.

When you create an object and assign it to a variable, the variable only refers to the object and does not represent the object itself! That is, the variable name points to that part of your computer's memory where the object is stored. This is called as binding of the name to the object.

Remember that an assignment statement for lists does not create a copy. You have to use slicing operation to make a copy of the sequence.

The time.strftime() function takes a specification such as the one we have used in the
above program. The %Y specification will be replaced by the year without the century. The
%m specification will be replaced by the month as a decimal number between 01 and 12 and
so on.

==
(findexception)
Exceptions

We put all the statements that might raise exceptions/errors inside the try block and then put handlers for the appropriate errors/exceptions in the except clause/block. The except clause can handle a single specified error or exception, or a parenthesized list of errors/exceptions. If no names of errors or exceptions are supplied, it will handle all errors and exceptions.

Note that there has to be at least one except clause associated with every try clause. Otherwise, what's the point of having a try block?

If any error or exception is not handled, then the default Python handler is called which just
stops the execution of the program and prints an error message.

You can also have an else clause associated with a try..except block. The else clause is executed if no exception occurs.

try:
    text = input('Enter something --> ')
except EOFError:
    print('Why did you do an EOF on me?')
except KeyboardInterrupt:
    print('You cancelled the operation.')
else:
    print('You entered {0}'.format(text))

--
Raising Exceptions

You can raise exceptions using the raise statement by providing the name of the error/exception and the exception object that is to be thrown.

The error or exception that you can arise should be class which directly or indirectly must be a derived class of the Exception class.


# A user-defined exception class.'''
class ShortInputException(Exception):
    def __init__(self, length, atleast):
        Exception.__init__(self)
        self.length = length
        self.atleast = atleast

    try:
        text = input('Enter something --> ')
        if len(text) < 3:
            raise ShortInputException(len(text), 3)
        # Other work can continue as usual here

    except EOFError:
        print('Why did you do an EOF on me?')

    except ShortInputException as ex:
        print('ShortInputException: The input was {0} long, expected at least {1}'.format(ex.length, ex.atleast))

    else:
        print('No exception was raised.')

--
Finally

Suppose you are reading a file in your program. How do you ensure that the file object is closed properly whether or not an exception was raised? This can be done using the finally block.

In the following, observe that the KeyboardInterrupt exception is thrown and the program quits. However, before the program exits, the finally clause is executed and the file object is always closed.

import time

try:
    f = open('poem.txt')
    while True: # our usual file-reading idiom
        line = f.readline()
        if len(line) == 0:
            break
        print(line, end='')
        time.sleep(2) # To make sure it runs for a while

except KeyboardInterrupt:
    print('!! You cancelled the reading from the file.')

finally:
    f.close()
    print('(Cleaning up: Closed the file)')

--
The with statement

Acquiring a resource in the try block and subsequently releasing the resource in the finally block is a common pattern. Hence, there is also a with statement that enables this to be done in a clean manner:

with open("poem.txt") as f:
    for line in f:
        print(line, end='')

The output should be same as the previous example (the example of finally block). The difference here is that we are using the open function with the with statement - we leave the closing of the file to be done automatically by with open.

==
Standard Library

sys module

The sys module contains system-specific functionality. We have already seen that the sys.argv list contains the command-line arguments.

Suppose we want to check the version of the Python command being used. The first entry is the major version.

>>> import sys
>>> sys.version_info
(3, 0, 0, 'beta', 2)
>>> sys.version_info[0] >= 3
True

Ensure the program runs only under Python 3.0. We use another module from the standard library called warnings that is used to display warnings to the end-user:

import sys, warnings

if sys.version_info[0] < 3:
    warnings.warn("Need Python 3.0 for this program to run",
        RuntimeWarning)
else:
    print('Proceed as normal')

Output:

$ python2.5 versioncheck.py
versioncheck.py:6: RuntimeWarning: Need Python 3.0 for this program to run RuntimeWarning)

$ python3 versioncheck.py
Proceed as normal

--
logging module
(Tao: not important, can skip)

What if you wanted to have some debugging messages or important messages to be stored somewhere so that you can check whether your program has been running as you would expect it? How do you "store somewhere" these messages? This can be achieved using the logging module.

import os, platform, logging

if platform.platform().startswith('Windows'):
    logging_file = os.path.join(os.getenv('HOMEDRIVE'), os.getenv('HOMEPATH'), 'test.log')
else:
    logging_file = os.path.join(os.getenv('HOME'), 'test.log')

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s : %(levelname)s : %(message)s',
    filename = logging_file,
    filemode = 'w',
)

logging.debug("Start of the program")
logging.info("Doing something")
logging.warning("Dying now")

Output:
$python use_logging.py
Logging to C:\Users\swaroop\test.log

If we check the contents of test.log, it will look something like this:
2008-09-03 13:18:16,233 : DEBUG : Start of the program
2008-09-03 13:18:16,233 : INFO : Doing something
2008-09-03 13:18:16,233 : WARNING : Dying now

We use three modules from the standard library - the os module for interacting with the operating system, the platform module for information about the platform i.e. the operating system and the logging module to log information.

We use the os.path.join() function to put these three parts of the location together. The reason to use a special function rather than just adding the strings together is because this function will ensure the full location matches the format expected by the operating system.

Once the program has run, we can check this file and we will know what happened in the program, even though no information was displayed to the user running the program.

--
urllib and json modules
(Tao: not important, can skip)

How much fun would it be if we could write our own program that will get search results from the web? Let us explore that now.

This can be achieved using a few modules. First is the urllib module that we can use to fetch any webpage from the internet. We will make use of Yahoo! Search to get the search results and luckily they can give us the results in a format called JSON which is easy for us to parse because of the built-in json module in the standard library.

import sys

if sys.version_info[0] != 3:
    sys.exit('This program needs Python 3.0')

import json
import urllib, urllib.parse, urllib.request, urllib.response

# Get your own APP ID at http://developer.yahoo.com/wsregapp/

YAHOO_APP_ID =
'jl22psvV34HELWhdfUJbfDQzlJ2B57KFS_qs4I8D0Wz5U5_yCI1Awv8.lBSfPhwr'

SEARCH_BASE =
'http://search.yahooapis.com/WebSearchService/V1/webSearch'

class YahooSearchError(Exception):
    pass

# Taken from http://developer.yahoo.com/python/python-json.html
def search(query, results=20, start=1, **kwargs):
    kwargs.update({
        'appid': YAHOO_APP_ID,
        'query': query,
        'results': results,
        'start': start,
        'output': 'json'
})

url = SEARCH_BASE + '?' + urllib.parse.urlencode(kwargs)
result = json.load(urllib.request.urlopen(url))

if 'Error' in result:
    raise YahooSearchError(result['Error'])
return result['ResultSet']

query = input('What do you want to search for? ')

for result in search(query)['Result']:
    print("{0} : {1}".format(result['Title'], result['Url']))


==
More

Passing tuples around

Ever wished you could return two different values from a function? You can. All you have to do is use a tuple.

>>> def get_error_details():
... return (2, 'second error details')
...

>>> errnum, errstr = get_error_details()
>>> errnum
2

>>> errstr
'second error details'

Notice that the usage of a, b = <some expression> interprets the result of the expression as a tuple with two values.

If you want to interpret the results as (a, <everything else>), then you just need to star it just like you would in function parameters:

>>> a, *b = [1, 2, 3, 4]
>>> a
1
>>> b
[2, 3, 4]

This also means the fastest way to swap two variables in Python is:
>>> a = 5; b = 8
>>> a, b = b, a
>>> a, b
(8, 5)

--
Special Methods

There are certain methods such as the __init__ and __del__ methods which have special significance in classes.

Special methods are used to mimic certain behaviors of built-in types. For example, if you want to use the x[key] indexing operation for your class (just like you use it for lists and tuples), then all you have to do is implement the __getitem__() method and your job is done. If you think about it, this is what Python does for the list class itself! Some useful special methods are listed in the following table:

__init__(self, ...): This method is called just before the newly created object is returned for usage.

__del__(self): Called just before the object is destroyed

__str__(self): Called when we use the print function or when str() is used.

__lt__(self, other): Called when the less than operator (<) is used. Similarly, there are special
methods for all the operators (+, >, etc.)

__getitem__(self, key): Called when x[key] indexing operation is used.

__len__(self): Called when the built-in len() function is used for the sequence object.

--
Single Statement Blocks

In an if or loop, if the body has only one line, then can put this line in the same line as if or for:

>>> flag = True
>>> if flag: print 'Yes'

I strongly recommend avoiding this short-cut method, except for error checking.

--
Lambda Forms

A lambda statement is used to create new function objects and then return them at runtime.

Tao: in the below:
1. make_repeater returns a function object.
2. This function object is created by the lambda statement. The s in the lambda s is the parameter of this function object. s * n is the function body.
3. twice is such a function object, so it can be called as other functions: twice(5).

def make_repeater(n):
    return lambda s: s * n

twice = make_repeater(2)

print(twice('word')) # Output: wordword
print(twice(5)) # Output: 10

--
List Comprehension

List comprehensions are used to derive a new list from an existing list. Suppose you have a list of numbers and you want to get a corresponding list with all the numbers multiplied by 2 only when the number itself is greater than 2. List comprehensions are ideal for such situations.

listone = [2, 3, 4]
listtwo = [2*i for i in listone if i > 2]
print(listtwo) # Output: [6, 8]

--
exec and eval

The exec function is used to execute Python statements which are stored in a string or file, as opposed to written in the program itself. For example, we can generate a string containing Python code at runtime and then execute these statements using the exec statement:

>>> exec('print("Hello World")')
Hello World

Similarly, the eval function is used to evaluate valid Python expressions which are stored in a string. A simple example is shown below.

>>> eval('2*3')
6

--
The assert statement

The assert statement is used to assert that something is true. For example, if you are very sure that you will have at least one element in a list you are using and want to check this, and raise an error if it is not true, then assert statement is ideal in this situation. When the assert statement fails, an AssertionError is raised.

>>> mylist = ['item']
>>> assert len(mylist) >= 1
>>> mylist.pop()
'item'
>>> mylist
[]
>>> assert len(mylist) >= 1
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
AssertionError

The assert statement should be used judiciously. Most of the time, it is better to catch exceptions, either handle the problem or display an error message to the user and then quit.

--
The repr function

The repr function is used to obtain a canonical string representation of the object. The    interesting part is that you will have eval(repr(object)) == object most of the time.

>>> i = []
>>> i.append('item')
>>> repr(i)
"['item']"
>>> eval(repr(i))
['item']
>>> eval(repr(i)) == i
True

Basically, the repr function is used to obtain a printable representation of the object. You can control what your classes return for the repr function by defining the __repr__ method in your class.

--
(findsleep)
sleep

The method sleep() suspends execution for the given number of seconds. The argument may be a floating point number to indicate a more precise sleep time.

import time
time.sleep(5) # Sleep for 5 seconds.

--
(findtime)
Output current local time

import datetime
time_str = (datetime.datetime.now() - datetime.timedelta(hours = 5)).strftime("%H:%M, %Y-%m-%d") # Minus 5 hours, may not be necessary.
print('Chicago time: {0}\n'.format(time_str)) # Output: Chicago time: 16:33, 2018-08-01

--
t1 = time.time()
print "ml4t"
t2 = time.time()
print "The time taken by print statement is ", t2 - t1, "seconds"


==
others:

# Python程序的文件名不用跟class名一樣, 甚至程序裡可以不含class.

# When you create an objet and assign it to a variable, the variable only refers to the object and does not represent the object itself.

# Python is strongly object-oriented in the sense that everything is an object including numbers, strings and functions.

# Python中的函數是可以在class之外的

# swap two variables:
# a = 5; b = 8
# a, b = b, a

# Read a list of numbers (in string form) from input and convert them into a list of int (from HackerRank):
# arr = [int(arr_temp) for arr_temp in input().strip().split(' ')]  # 此句中strip()還可以刪掉輸入末尾的newline, 當然同時也刪空格(from Haddop課).
# now arr is a list of int

# abs(-45), abs(100.12)

# 實踐表明, Python中連注釋都要正式indent, 否則報錯

==
The current date and time which we find out using the time.strftime() function. (import time).

Notice the use of os.sep variable (import os) - this gives the directory separator according to your
operating system i.e. it will be '/' in Linux, Unix, it will be '\\' in Windows and ':' in
Mac OS. Using os.sep instead of these characters directly will make our program portable
and work across these systems.

==
The zip command that we are using has some options and parameters passed. The -q
option is used to indicate that the zip command should work quietly. The -r option
specifies that the zip command should work recursively for directories i.e. it should include
all the subdirectories and files. The two options are combined and specified in a shortcut as
-qr. The options are followed by the name of the zip archive to create followed by the list of
files and directories to backup. We convert the source list into a string using the join
method of strings which we have already seen how to use.

Then, we finally run the command using the os.system function which runs the command
as if it was run from the system i.e. in the shell - it returns 0 if the command was
successfully, else it returns an error number.

==
target = today + os.sep + now + '_' + \ comment.replace(' ', '_') + '.zip'

===
# Create the subdirectory if it isn't already there
if not os.path.exists(today): #t oday is a string defined earlier.
    os.mkdir(today) # make directory

=====================================================================

=====
(findnumpy)
NumPy

From https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/

Practical Tutorial on Data Manipulation with Numpy and Pandas in Python

TUTORIAL
Introduction

The pandas library has emerged into a power house of data manipulation tasks in python since it was developed in 2008. With its intuitive syntax and flexible data structure, it's easy to learn and enables faster data computation. The development of numpy and pandas libraries has extended python's multi-purpose nature to solve machine learning problems as well. The acceptance of python language in machine learning has been phenomenal since then.

This is just one more reason underlining the need for you to learn these libraries now. Published in early 2017, this blog claimed that python jobs outnumbered R jobs.

In this tutorial, we'll learn about using numpy and pandas libraries for data manipulation from scratch. Instead of going into theory, we'll take a practical approach.

First, we'll understand the syntax and commonly used functions of the respective libraries. Later, we'll work on a real-life data set.

Note: This tutorial is best suited for people who know the basics of python. No further knowledge is expected. Make sure you have python installed on your laptop.

Table of Contents

6 Important things you should know about Numpy and Pandas
Starting with Numpy
Starting with Pandas
Exploring an ML Data Set
Building a Random Forest Model
6 Important things you should know about Numpy and Pandas

The data manipulation capabilities of pandas are built on top of the numpy library. In a way, numpy is a dependency of the pandas library.
Pandas is best at handling tabular data sets comprising different variable types (integer, float, double, etc.). In addition, the pandas library can also be used to perform even the most naive of tasks such as loading data or doing feature engineering on time series data.
Numpy is most suitable for performing basic numerical computations such as mean, median, range, etc. Alongside, it also supports the creation of multi-dimensional arrays.
Numpy library can also be used to integrate C/C++ and Fortran code.
Remember, python is a zero indexing language unlike R where indexing starts at one.
The best part of learning pandas and numpy is the strong active community support you'll get from around the world.
Just to give you a flavor of the numpy library, we'll quickly go through its syntax structures and some important commands such as slicing, indexing, concatenation, etc. All these commands will come in handy when using pandas as well. Let's get started!

Starting with Numpy

#load the library and check its version, just to make sure we aren't using an older version
import numpy as np
np.__version__
'1.12.1'

#create a list comprising numbers from 0 to 9
L = list(range(10))

#converting integers to string - this style of handling lists is known as list comprehension.
#List comprehension offers a versatile way to handle list manipulations tasks easily. We'll learn about them in future tutorials. Here's an example.  

[str(c) for c in L]
['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']

[type(item) for item in L]
[int, int, int, int, int, int, int, int, int, int]

Creating Arrays

Numpy arrays are homogeneous in nature, i.e., they comprise one data type (integer, float, double, etc.) unlike lists.

#creating arrays
np.zeros(10, dtype='int')
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

#creating a 3 row x 5 column matrix
np.ones((3,5), dtype=float)
array([[ 1.,  1.,  1.,  1.,  1.],
      [ 1.,  1.,  1.,  1.,  1.],
      [ 1.,  1.,  1.,  1.,  1.]])

#creating a matrix with a predefined value
np.full((3,5),1.23)
array([[ 1.23,  1.23,  1.23,  1.23,  1.23],
      [ 1.23,  1.23,  1.23,  1.23,  1.23],
      [ 1.23,  1.23,  1.23,  1.23,  1.23]])

#create an array with a set sequence
np.arange(0, 20, 2)
array([0, 2, 4, 6, 8,10,12,14,16,18])

#create an array of even space between the given range of values
np.linspace(0, 1, 5)
array([ 0., 0.25, 0.5 , 0.75, 1.])

#create a 3x3 array with mean 0 and standard deviation 1 in a given dimension
np.random.normal(0, 1, (3,3))
array([[ 0.72432142, -0.90024075,  0.27363808],
      [ 0.88426129,  1.45096856, -1.03547109],
      [-0.42930994, -1.02284441, -1.59753603]])

#create an identity matrix
np.eye(3)
array([[ 1.,  0.,  0.],
      [ 0.,  1.,  0.],
      [ 0.,  0.,  1.]])

#set a random seed
np.random.seed(0)

x1 = np.random.randint(10, size=6) #one dimension
x2 = np.random.randint(10, size=(3,4)) #two dimension
x3 = np.random.randint(10, size=(3,4,5)) #three dimension

print("x3 ndim:", x3.ndim)
print("x3 shape:", x3.shape)
print("x3 size: ", x3.size)
('x3 ndim:', 3)
('x3 shape:', (3, 4, 5))
('x3 size: ', 60)

Array Indexing

The important thing to remember is that indexing in python starts at zero.

x1 = np.array([4, 3, 4, 4, 8, 4])
x1
array([4, 3, 4, 4, 8, 4])

#assess value to index zero
x1[0]
4

#assess fifth value
x1[4]
8

#get the last value
x1[-1]
4

#get the second last value
x1[-2]
8

#in a multidimensional array, we need to specify row and column index
x2
array([[3, 7, 5, 5],
      [0, 1, 5, 9],
      [3, 0, 5, 0]])

#1st row and 2nd column value
x2[2,3]
0

#3rd row and last value from the 3rd column
x2[2,-1]
0

#replace value at 0,0 index
x2[0,0] = 12
x2
array([[12,  7,  5,  5],
      [ 0,  1,  5,  9],
      [ 3,  0,  5,  0]])

Array Slicing

Now, we'll learn to access multiple or a range of elements from an array.

x = np.arange(10)
x
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

#from start to 4th position
x[:5]
array([0, 1, 2, 3, 4])

#from 4th position to end
x[4:]
array([4, 5, 6, 7, 8, 9])

#from 4th to 6th position
x[4:7]
array([4, 5, 6])

#return elements at even place
x[ : : 2]
array([0, 2, 4, 6, 8])

#return elements from first position step by two
x[1::2]
array([1, 3, 5, 7, 9])

#reverse the array
x[::-1]
array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])

Array Concatenation

Many a time, we are required to combine different arrays. So, instead of typing each of their elements manually, you can use array concatenation to handle such tasks easily.

#You can concatenate two or more arrays at once.
x = np.array([1, 2, 3])
y = np.array([3, 2, 1])
z = [21,21,21]
np.concatenate([x, y,z])
array([ 1,  2,  3,  3,  2,  1, 21, 21, 21])

#You can also use this function to create 2-dimensional arrays.
grid = np.array([[1,2,3],[4,5,6]])
np.concatenate([grid,grid])
array([[1, 2, 3],
      [4, 5, 6],
      [1, 2, 3],
      [4, 5, 6]])

#Using its axis parameter, you can define row-wise or column-wise matrix
np.concatenate([grid,grid],axis=1)
array([[1, 2, 3, 1, 2, 3],
      [4, 5, 6, 4, 5, 6]])

Until now, we used the concatenation function of arrays of equal dimension. But, what if you are required to combine a 2D array with 1D array? In such situations, np.concatenate might not be the best option to use. Instead, you can use np.vstack or np.hstack to do the task. Let's see how!
x = np.array([3,4,5])
grid = np.array([[1,2,3],[17,18,19]])
np.vstack([x,grid])
array([[ 3,  4,  5],
      [ 1,  2,  3],
      [17, 18, 19]])


#Similarly, you can add an array using np.hstack
z = np.array([[9],[9]])
np.hstack([grid,z])
array([[ 1,  2,  3,  9],
      [17, 18, 19,  9]])

Also, we can split the arrays based on pre-defined positions. Let's see how!
x = np.arange(10)
x
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

x1,x2,x3 = np.split(x,[3,6])
print x1,x2,x3
[0 1 2] [3 4 5] [6 7 8 9]

grid = np.arange(16).reshape((4,4))
grid
upper,lower = np.vsplit(grid,[2])
print (upper, lower)
(array([[0, 1, 2, 3],
       [4, 5, 6, 7]]), array([[ 8,  9, 10, 11],
       [12, 13, 14, 15]]))

In addition to the functions we learned above, there are several other mathematical functions available in the numpy library such as sum, divide, multiple, abs, power, mod, sin, cos, tan, log, var, min, mean, max, etc. which you can be used to perform basic arithmetic calculations. Feel free to refer to numpy documentation for more information on such functions.

--
From ml4t:

--
Any python can run numpy, no need to use some annaconda environment (confirmed from tao's practice).

--
To use NumPy:
import numpy as np

The NumPy numerical library: NumPy is a Python library that acts as a wrapper around underlying C and Fortran code. Because of that, it's very, very fast. NumPy focuses on matrices which are called ndarrays. NumPy is one of the important reasons people use Python for financial research.

Now, how does NumPy relate to Pandas? Well, I said just a moment ago that NumPy is a wrapper for numerical libraries, well it turns out that Pandas is a kind of wrapper for NumPy. So remember our traditional data frame here, with our columns being symbols and our rows being dates. This data frame is just a wrapper around this ndarray, access the columns with symbols and the rows by dates. But you can, in fact, just treat this inside part (tao: the part of the dataframe without the header line and the index column) as an ndarray directly. If you use this syntax (nd1 = df1.values) in Python, that pulls these values out and lets you access it directly and then ndarray. You don't really need to do that though, you can, if you like, ** treat a data frame just like a NumPy ndarray **. And so we're going to assume in the rest of this lesson that we're just working with an ndarray

==
NumPy access ndarray cells:

nd[0, 0] # The element at row 0, column 0
nd[3, 2] # The element at row 3, column 2
nd[0:3, 1:3] # The block from row 0 to row 2, column 1 to column 2. Notices that 0:3 means 0,1,2.
nd[:, 3] # All the rows, column 3.
nd[-1, 1:3] # -1 means last row. Similary, -2 means second to last row.
nd[0, 1:3] # For the 0 row, get values from column 1 to column 2

nd[0, 0:3:2] # Slice n:m:t sepcifies a range that starts at n, and stops before m, in steps of size t.

nd1[0:2, 0:2] = nd2[-2:, 2:4] # Replace some of the values in nd1, with these values from nd2. "-2:" means from "the second to last row" to "the last row". 

--
Assign values:

nd[0, 0] = 1 # Assign value
nd[0, :] = 2 # Assign a single value to an entire row
nd[:, 3] = [1, 2, 3, 4, 5] # Assign a list to a column in an array.

==
Create NumPy arrays from scratch:

np.array() can take as input a list, a template, or other sequence.

import numpy as np

a = np.array([2, 3, 4]) # List to 1D array

b = np.array([(2, 3, 4), (5, 6, 7)]) # List of tuples to 2D array. Each tuple serves as one row. We could also have passed a list of lists.

print b

Output:
[[2 3 4]
  5 6 7]]

b.shape # Returns [2, 3]  
b.shape[0] # Number of rows
b.shape[1] # Number of columns
b.size # Number of elements in the array

print b.dtype # Data type of each element

--
Create empty ndarray:

np.empty(5)
np.empty((5, 4))

The empty function takes the shape of the array as input. The shape can be defined as a single integer, as we did over here, for creating a one dimensional array, or a sequence of integers denoting the size in each dimension. For a two dimensional array, a sequence of two integers is needed. That is the number of rows and the number of columns.

print np.empty((5, 4))

Now let's check the output. Hm, strange. The empty array is not actually empty. What happens is that when we call numpy.empty to create an array, the elements of the array read in whatever values were present in the corresponding memory location.

--
Create ndarray with ones or zeroes:

np.ones((5, 4)) # Create an array full of ones.
np.zeroes((5, 4)) # Create an array full of zeroes.

We notice that the default data type of all the values in the array is float. Fortunately, you can change this when creating the array:

np.ones((5, 4), dtype = np.int_) # Here we defined the values to be integers

--
Create ndarray with random values:

Generate an array full of random numbers, uniformly sampled from [0.0, 1.0). Pass in a size tuple:

np.random.random((5, 4)) # 5 rows, 4 columns

A slightly variation of this function is rand. We directly pass the
values of the rows and columns through the function and did not define a tuple:

np.random.rand(5, 4) # 5 rows, 4 columns

--
Create ndarray with normal (Gaussian) distribution.

Standard normal (mean = 0, s.d. = 1):

np.random.normal(size = (2, 3)) # 2 rows, 3 columns

Mean = 50, s.d. = 10:

np.random.normal(50, 10, size = (2, 3))

--
Create ndarray with random integers:

np.random.randint(10) # A single integer in [0, 10)
np.random.randint(0, 10) # Same as above, specifying [low, high) explicit
np.random.randint(0, 10, size = 5) # 5 random integers as a 1D array 
np.random.randint(0, 10, size = (2, 3)) # 2*3 array of random integers 

--
np.random.seed(693)

a = np.random.randint(0, 10, size = (5, 4))

Note how we used seed, the random number generator with the constant, to get the same sequence of numbers every time.

--
We can also sum in a specific direction of the array.  What I mean by direction is along rows or columns. NumPy gives this direction a special name.  It is called axis.  Axis = 0 signifies rows, and axis =  1 indicates columns. 

a:

[[2 0 5 1
  1 3 4 4
  9 2 9 1
  9 3 7 5 
  4 7 0 3]]

# Iterate over rows, to compute sum of each column:
a.sum(axis = 0) # Returns sum of each column: [25 15 25 14]

# Iterate over columns, to compute sum of each row:
a.sum(axis = 1) # Returns sum of each row: [8 12 21 24 14]

# Returns min across rows, to compute min of each column:
a.min(axis = 0) # Returns min of each column: [1 0 0 1]

# Returns max across columns, to compute max of each row:
a.max(axis = 1) # Returns max of each row: [5 4 9 9 7]

a.mean() # Returns the mean all elements: 3.95. Of course we can get mean along each axis as we did for max and min.  

--
Find the position of some element in an ndarray:

a.argmx() # Returns the index of the maximum value in given 1D array

For multidimensional arrays, finding and representing indices is a little tricky. 

--
We want to get all the values from the array, which is less than mean of the entire array.  

mean = a.mean()
a[a < mean] # Returns the wanted values above
a[a < mean] = mean # all the values previously less than mean have been replaced by the mean

--
Arithmetic operations on arrays are always applied element wise (tao: ie, element by elment).

2 * a # Every element multiplied by 2.
a + b # Add every element from a and b.
a * b # Normal matrix multiplication (as in Linear Algebra).

What about matrix multiplication?  How do you achieve that?  Like, for everything, Num Pi has a function.  It has function called dot, which performs matrix multiplication.  

--
(findrandomnumber)                   
Random number

import numpy as np  
np.random.random() # Returns a random number, not sure about the range.


=============
(findpandas)
Pandas

From 
https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/

Let's move on to pandas now. Make sure you following each line below because it'll help you in doing data manipulation using pandas.

Let's start with Pandas

#load library - pd is just an alias. I used pd because it's short and literally abbreviates pandas.
#You can use any name as an alias. 
import pandas as pd
#create a data frame - dictionary is used here where keys get converted to column names and values to row values.
data = pd.DataFrame({'Country': ['Russia','Colombia','Chile','Equador','Nigeria'],
                    'Rank':[121,40,100,130,11]})
data
Country	Rank
0	Russia	121
1	Colombia	40
2	Chile	100
3	Equador	130
4	Nigeria	11
#We can do a quick analysis of any data set using:
data.describe()
Rank
count	5.000000
mean	80.400000
std	52.300096
min	11.000000
25%	40.000000
50%	100.000000
75%	121.000000
max	130.000000
Remember, describe() method computes summary statistics of integer / double variables. To get the complete information about the data set, we can use info() function.

#Among other things, it shows the data set has 5 rows and 2 columns with their respective names.
data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5 entries, 0 to 4
Data columns (total 2 columns):
Country    5 non-null object
Rank       5 non-null int64
dtypes: int64(1), object(1)
memory usage: 152.0+ bytes


#Let's create another data frame.
data = pd.DataFrame({'group':['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],'ounces':[4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
data
group	ounces
0	a	4.0
1	a	3.0
2	a	12.0
3	b	6.0
4	b	7.5
5	b	8.0
6	c	3.0
7	c	5.0
8	c	6.0
#Let's sort the data frame by ounces - inplace = True will make changes to the data
data.sort_values(by=['ounces'],ascending=True,inplace=False)
group	ounces
1	a	3.0
6	c	3.0
0	a	4.0
7	c	5.0
3	b	6.0
8	c	6.0
4	b	7.5
5	b	8.0
2	a	12.0
We can sort the data by not just one column but multiple columns as well.

data.sort_values(by=['group','ounces'],ascending=[True,False],inplace=False)
group	ounces
2	a	12.0
0	a	4.0
1	a	3.0
5	b	8.0
4	b	7.5
3	b	6.0
8	c	6.0
7	c	5.0
6	c	3.0
Often, we get data sets with duplicate rows, which is nothing but noise. Therefore, before training the model, we need to make sure we get rid of such inconsistencies in the data set. Let's see how we can remove duplicate rows.

#create another data with duplicated rows
data = pd.DataFrame({'k1':['one']*3 + ['two']*4, 'k2':[3,2,1,3,3,4,4]})
data
k1	k2
0	one	3
1	one	2
2	one	1
3	two	3
4	two	3
5	two	4
6	two	4
#sort values 
data.sort_values(by='k2')
k1	k2
2	one	1
1	one	2
0	one	3
3	two	3
4	two	3
5	two	4
6	two	4
#remove duplicates - ta da! 
data.drop_duplicates()
k1	k2
0	one	3
1	one	2
2	one	1
3	two	3
5	two	4
Here, we removed duplicates based on matching row values across all columns. Alternatively, we can also remove duplicates based on a particular column. Let's remove duplicate values from the k1 column.

data.drop_duplicates(subset='k1')
k1	k2
0	one	3
3	two	3
Now, we will learn to categorize rows based on a predefined criteria. It happens a lot while data processing where you need to categorize a variable. For example, say we have got a column with country names and we want to create a new variable 'continent' based on these country names. In such situations, we will require the steps below:

data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami','corned beef', 'Bacon', 'pastrami', 'honey ham','nova lox'],
                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
data
food	ounces
0	bacon	4.0
1	pulled pork	3.0
2	bacon	12.0
3	Pastrami	6.0
4	corned beef	7.5
5	Bacon	8.0
6	pastrami	3.0
7	honey ham	5.0
8	nova lox	6.0
Now, we want to create a new variable which indicates the type of animal which acts as the source of the food. To do that, first we'll create a dictionary to map the food to the animals. Then, we'll use map function to map the dictionary's values to the keys. Let's see how is it done.

meat_to_animal = {
'bacon': 'pig',
'pulled pork': 'pig',
'pastrami': 'cow',
'corned beef': 'cow',
'honey ham': 'pig',
'nova lox': 'salmon'
}

def meat_2_animal(series):
    if series['food'] == 'bacon':
        return 'pig'
    elif series['food'] == 'pulled pork':
        return 'pig'
    elif series['food'] == 'pastrami':
        return 'cow'
    elif series['food'] == 'corned beef':
        return 'cow'
    elif series['food'] == 'honey ham':
        return 'pig'
    else:
        return 'salmon'


#create a new variable
data['animal'] = data['food'].map(str.lower).map(meat_to_animal)
data
food	ounces	animal
0	bacon	4.0	pig
1	pulled pork	3.0	pig
2	bacon	12.0	pig
3	Pastrami	6.0	cow
4	corned beef	7.5	cow
5	Bacon	8.0	pig
6	pastrami	3.0	cow
7	honey ham	5.0	pig
8	nova lox	6.0	salmon
#another way of doing it is: convert the food values to the lower case and apply the function
lower = lambda x: x.lower()
data['food'] = data['food'].apply(lower)
data['animal2'] = data.apply(meat_2_animal, axis='columns')
data
food	ounces	animal	animal2
0	bacon	4.0	pig	pig
1	pulled pork	3.0	pig	pig
2	bacon	12.0	pig	pig
3	pastrami	6.0	cow	cow
4	corned beef	7.5	cow	cow
5	bacon	8.0	pig	pig
6	pastrami	3.0	cow	cow
7	honey ham	5.0	pig	pig
8	nova lox	6.0	salmon	salmon
Another way to create a new variable is by using the assign function. With this tutorial, as you keep discovering the new functions, you'll realize how powerful pandas is.

data.assign(new_variable = data['ounces']*10)
food	ounces	animal	animal2	new_variable
0	bacon	4.0	pig	pig	40.0
1	pulled pork	3.0	pig	pig	30.0
2	bacon	12.0	pig	pig	120.0
3	pastrami	6.0	cow	cow	60.0
4	corned beef	7.5	cow	cow	75.0
5	bacon	8.0	pig	pig	80.0
6	pastrami	3.0	cow	cow	30.0
7	honey ham	5.0	pig	pig	50.0
8	nova lox	6.0	salmon	salmon	60.0
Let's remove the column animal2 from our data frame.

data.drop('animal2',axis='columns',inplace=True)
data
food	ounces	animal
0	bacon	4.0	pig
1	pulled pork	3.0	pig
2	bacon	12.0	pig
3	Pastrami	6.0	cow
4	corned beef	7.5	cow
5	Bacon	8.0	pig
6	pastrami	3.0	cow
7	honey ham	5.0	pig
8	nova lox	6.0	salmon
We frequently find missing values in our data set. A quick method for imputing missing values is by filling the missing value with any random number. Not just missing values, you may find lots of outliers in your data set, which might require replacing. Let's see how can we replace values.

#Series function from pandas are used to create arrays
data = pd.Series([1., -999., 2., -999., -1000., 3.])
data
0       1.0
1    -999.0
2       2.0
3    -999.0
4   -1000.0
5       3.0
dtype: float64


#replace -999 with NaN values
data.replace(-999, np.nan,inplace=True)
data
0       1.0
1       NaN
2       2.0
3       NaN
4   -1000.0
5       3.0
dtype: float64


#We can also replace multiple values at once.
data = pd.Series([1., -999., 2., -999., -1000., 3.])
data.replace([-999,-1000],np.nan,inplace=True)
data
0    1.0
1    NaN
2    2.0
3    NaN
4    NaN
5    3.0
dtype: float64
Now, let's learn how to rename column names and axis (row names).

data = pd.DataFrame(np.arange(12).reshape((3, 4)),index=['Ohio', 'Colorado', 'New York'],columns=['one', 'two', 'three', 'four'])
data
one	two	three	four
Ohio	0	1	2	3
Colorado	4	5	6	7
New York	8	9	10	11
#Using rename function
data.rename(index = {'Ohio':'SanF'}, columns={'one':'one_p','two':'two_p'},inplace=True)
data
one_p	two_p	three	four
SanF	0	1	2	3
Colorado	4	5	6	7
New York	8	9	10	11
#You can also use string functions
data.rename(index = str.upper, columns=str.title,inplace=True)
data
One_p	Two_p	Three	Four
SANF	0	1	2	3
COLORADO	4	5	6	7
NEW YORK	8	9	10	11
Next, we'll learn to categorize (bin) continuous variables.

ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]
We'll divide the ages into bins such as 18-25, 26-35,36-60 and 60 and above.

#Understand the output - '(' means the value is included in the bin, '[' means the value is excluded
bins = [18, 25, 35, 60, 100]
cats = pd.cut(ages, bins)
cats
[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]
Length: 12
Categories (4, object): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]


#To include the right bin value, we can do:
pd.cut(ages,bins,right=False)
[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [25, 35), [60, 100), [35, 60), [35, 60), [25, 35)]
Length: 12
Categories (4, object): [[18, 25) < [25, 35) < [35, 60) < [60, 100)]


#pandas library intrinsically assigns an encoding to categorical variables.
cats.labels
array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)


#Let's check how many observations fall under each bin
pd.value_counts(cats)
(18, 25]     5
(35, 60]     3
(25, 35]     3
(60, 100]    1
dtype: int64
Also, we can pass a unique name to each label.

bin_names = ['Youth', 'YoungAdult', 'MiddleAge', 'Senior']
new_cats = pd.cut(ages, bins,labels=bin_names)

pd.value_counts(new_cats)
Youth	5
MiddleAge	3
YoungAdult	3
Senior	1
dtype: int64	
#we can also calculate their cumulative sum
pd.value_counts(new_cats).cumsum()
Youth	5
MiddleAge	3
YoungAdult	3
Senior	1
dtype: int64	
Let's proceed and learn about grouping data and creating pivots in pandas. It's an immensely important data analysis method which you'd probably have to use on every data set you work with.

df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],
                   'key2' : ['one', 'two', 'one', 'two', 'one'],
                   'data1' : np.random.randn(5),
                   'data2' : np.random.randn(5)})
df
data1	data2	key1	key2
0	0.973599	0.001761	a
1	0.207283	-0.990160	a
2	1.099642	1.872394	b
3	0.939897	-0.241074	b
4	0.606389	0.053345	a
#calculate the mean of data1 column by key1
grouped = df['data1'].groupby(df['key1'])
grouped.mean()
key1
a    0.595757
b    1.019769
Name: data1, dtype: float64
Now, let's see how to slice the data frame.
dates = pd.date_range('20130101',periods=6)
df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))
df
A	B	C	D
2013-01-01	1.030816	-1.276989	0.837720	-1.490111
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058
2013-01-03	1.524227	1.863575	1.291378	1.300696
2013-01-04	0.918203	-0.158800	-0.964063	-1.990779
2013-01-05	0.089731	0.114854	-0.585815	0.298772
2013-01-06	0.222260	0.435183	-0.045748	0.049898
#get first n rows from the data frame
df[:3]
A	B	C	D
2013-01-01	1.030816	-1.276989	0.837720	-1.490111
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058
2013-01-03	1.524227	1.863575	1.291378	1.300696
#slice based on date range
df['20130101':'20130104']
A	B	C	D
2013-01-01	1.030816	-1.276989	0.837720	-1.490111
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058
2013-01-03	1.524227	1.863575	1.291378	1.300696
2013-01-04	0.918203	-0.158800	-0.964063	-1.990779
#slicing based on column names
df.loc[:,['A','B']]
A	B
2013-01-01	1.030816	-1.276989
2013-01-02	-1.070215	-0.209129
2013-01-03	1.524227	1.863575
2013-01-04	0.918203	-0.158800
2013-01-05	0.089731	0.114854
2013-01-06	0.222260	0.435183
#slicing based on both row index labels and column names
df.loc['20130102':'20130103',['A','B']]
A	B
2013-01-02	-1.070215	-0.209129
2013-01-03	1.524227	1.863575
#slicing based on index of columns
df.iloc[3] #returns 4th row (index is 3rd)
A    0.918203
B   -0.158800
C   -0.964063
D   -1.990779
Name: 2013-01-04 00:00:00, dtype: float64


#returns a specific range of rows
df.iloc[2:4, 0:2]
A	B
2013-01-03	1.524227	1.863575
2013-01-04	0.918203	-0.158800
#returns specific rows and columns using lists containing columns or row indexes
df.iloc[[1,5],[0,2]] 
A	C
2013-01-02	-1.070215	0.604572
2013-01-06	0.222260	-0.045748
Similarly, we can do Boolean indexing based on column values as well. This helps in filtering a data set based on a pre-defined condition.

df[df.A > 1]
A	B	C	D
2013-01-01	1.030816	-1.276989	0.837720	-1.490111
2013-01-03	1.524227	1.863575	1.291378	1.300696
#we can copy the data set
df2 = df.copy()
df2['E']=['one', 'one','two','three','four','three']
df2
A	B	C	D	E
2013-01-01	1.030816	-1.276989	0.837720	-1.490111	one
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058	one
2013-01-03	1.524227	1.863575	1.291378	1.300696	two
2013-01-04	0.918203	-0.158800	-0.964063	-1.990779	three
2013-01-05	0.089731	0.114854	-0.585815	0.298772	four
2013-01-06	0.222260	0.435183	-0.045748	0.049898	three
#select rows based on column values
df2[df2['E'].isin(['two','four'])]
A	B	C	D	E
2013-01-03	1.524227	1.863575	1.291378	1.300696	two
2013-01-05	0.089731	0.114854	-0.585815	0.298772	four
#select all rows except those with two and four
df2[~df2['E'].isin(['two','four'])]
A	B	C	D	E
2013-01-01	1.030816	-1.276989	0.837720	-1.490111	one
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058	one
2013-01-04	0.918203	-0.158800	-0.964063	-1.990779	three
2013-01-06	0.222260	0.435183	-0.045748	0.049898	three
We can also use a query method to select columns based on a criterion. Let's see how!

#list all columns where A is greater than C
df.query('A > C')
A	B	C	D
2013-01-01	1.030816	-1.276989	0.837720	-1.490111
2013-01-03	1.524227	1.863575	1.291378	1.300696
2013-01-04	0.918203	-0.158800	-0.964063	-1.990779
2013-01-05	0.089731	0.114854	-0.585815	0.298772
2013-01-06	0.222260	0.435183	-0.045748	0.049898
#using OR condition
df.query('A < B | C > A')
A	B	C	D
2013-01-02	-1.070215	-0.209129	0.604572	-1.743058
2013-01-03	1.524227	1.863575	1.291378	1.300696
2013-01-05	0.089731	0.114854	-0.585815	0.298772
2013-01-06	0.222260	0.435183	-0.045748	0.049898
Pivot tables are extremely useful in analyzing data using a customized tabular format. I think, among other things, Excel is popular because of the pivot table option. It offers a super-quick way to analyze data.

#create a data frame
data = pd.DataFrame({'group': ['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],
                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
data
group	ounces
0	a	4.0
1	a	3.0
2	a	12.0
3	b	6.0
4	b	7.5
5	b	8.0
6	c	3.0
7	c	5.0
8	c	6.0
#calculate means of each group
data.pivot_table(values='ounces',index='group',aggfunc=np.mean)
group
a    6.333333
b    7.166667
c    4.666667
Name: ounces, dtype: float64


#calculate count by each group
data.pivot_table(values='ounces',index='group',aggfunc='count')
group
a    3
b    3
c    3
Name: ounces, dtype: int64
Up till now, we've become familiar with the basics of pandas library using toy examples. Now, we'll take up a real-life data set and use our newly gained knowledge to explore it.

Exploring ML Data Set

We'll work with the popular adult data set.The data set has been taken from UCI Machine Learning Repository. You can download the data from here. In this data set, the dependent variable is "target." It is a binary classification problem. We need to predict if the salary of a given person is less than or more than 50K.

#load the data
train  = pd.read_csv("~/Adult/train.csv")
test = pd.read_csv("~/Adult/test.csv")
#check data set
train.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 32561 entries, 0 to 32560
Data columns (total 15 columns):
age               32561 non-null int64
workclass         30725 non-null object
fnlwgt            32561 non-null int64
education         32561 non-null object
education.num     32561 non-null int64
marital.status    32561 non-null object
occupation        30718 non-null object
relationship      32561 non-null object
race              32561 non-null object
sex               32561 non-null object
capital.gain      32561 non-null int64
capital.loss      32561 non-null int64
hours.per.week    32561 non-null int64
native.country    31978 non-null object
target            32561 non-null object
dtypes: int64(6), object(9)
memory usage: 3.7+ MB
We see that, the train data has 32561 rows and 15 columns. Out of these 15 columns, 6 have integers classes and the rest have object (or character) classes. Similarly, we can check for test data. An alternative way of quickly checking rows and columns is

print ("The train data has",train.shape)
print ("The test data has",test.shape)
('The train data has', (32561, 15))
('The test data has', (16281, 15))


#Let have a glimpse of the data set
train.head()
age	workclass	fnlwgt	education	education.num	marital.status	occupation	relationship	race	sex	capital.gain	capital.loss	hours.per.week	native.country	target
0	39	State-gov	77516	Bachelors	13	Never-married	Adm-clerical	Not-in-family	White	Male	2174	0	40	United-States	<=50K
1	50	Self-emp-not-inc	83311	Bachelors	13	Married-civ-spouse	Exec-managerial	Husband	White	Male	0	0	13	United-States	<=50K
2	38	Private	215646	HS-grad	9	Divorced	Handlers-cleaners	Not-in-family	White	Male	0	0	40	United-States	<=50K
3	53	Private	234721	11th	7	Married-civ-spouse	Handlers-cleaners	Husband	Black	Male	0	0	40	United-States	<=50K
4	28	Private	338409	Bachelors	13	Married-civ-spouse	Prof-specialty	Wife	Black	Female	0	0	40	Cuba	<=50K
Now, let's check the missing values (if present) in this data.

nans = train.shape[0] - train.dropna().shape[0]
print ("%d rows have missing values in the train data" %nans)

nand = test.shape[0] - test.dropna().shape[0]
print ("%d rows have missing values in the test data" %nand)

2399 rows have missing values in the train data
1221 rows have missing values in the test data
We should be more curious to know which columns have missing values.

#only 3 columns have missing values
train.isnull().sum()
age	0
workclass	1836
fnlwgt	0
education	0
education.num	0
marital.status	0
occupation	1843
relationship	0
race	0
sex	0
capital.gain	0
capital.loss	0
hours.per.week	0
native.country	583
target	0
dtype: int64	
Let's count the number of unique values from character variables.

cat = train.select_dtypes(include=['O'])
cat.apply(pd.Series.nunique)
workclass	8
education	16
marital.status	7
occupation	14
relationship	6
race	5
sex	2
native.country	41
target	2
dtype: int64	
Since missing values are found in all 3 character variables, let's impute these missing values with their respective modes.

#Education
train.workclass.value_counts(sort=True)
train.workclass.fillna('Private',inplace=True)


#Occupation
train.occupation.value_counts(sort=True)
train.occupation.fillna('Prof-specialty',inplace=True)


#Native Country
train['native.country'].value_counts(sort=True)
train['native.country'].fillna('United-States',inplace=True)
Let's check again if there are any missing values left.

train.isnull().sum()
age	0
workclass	0
fnlwgt	0
education	0
education.num	0
marital.status	0
occupation	0
relationship	0
race	0
sex	0
capital.gain	0
capital.loss	0
hours.per.week	0
native.country	0
target	0
dtype: int64	
Now, we'll check the target variable to investigate if this data is imbalanced or not.

#check proportion of target variable
train.target.value_counts()/train.shape[0]
<=50K    0.75919
>50K     0.24081
Name: target, dtype: float64
We see that 75% of the data set belongs to <=50K class. This means that even if we take a rough guess of target prediction as <=50K, we'll get 75% accuracy. Isn't that amazing? Let's create a cross tab of the target variable with education. With this, we'll try to understand the influence of education on the target variable.

pd.crosstab(train.education, train.target,margins=True)/train.shape[0]
target	<=50K	>50K	All
education			
10th	0.026750	0.001904	0.028654
11th	0.034243	0.001843	0.036086
12th	0.012285	0.001013	0.013298
1st-4th	0.004975	0.000184	0.005160
5th-6th	0.009736	0.000491	0.010227
7th-8th	0.018611	0.001228	0.019840
9th	0.014957	0.000829	0.015786
Assoc-acdm	0.024631	0.008139	0.032769
Assoc-voc	0.031357	0.011087	0.042443
Bachelors	0.096250	0.068210	0.164461
Doctorate	0.003286	0.009398	0.012684
HS-grad	0.271060	0.051442	0.322502
Masters	0.023464	0.029452	0.052916
Preschool	0.001566	0.000000	0.001566
Prof-school	0.004699	0.012991	0.017690
Some-college	0.181321	0.042597	0.223918
All	0.759190	0.240810	1.000000
We see that out of 75% people with <=50K salary, 27% people are high school graduates, which is correct as people with lower levels of education are expected to earn less. On the other hand, out of 25% people with >=50K salary, 6% are bachelors and 5% are high-school grads. Now, this pattern seems to be a matter of concern. That's why we'll have to consider more variables before coming to a conclusion.

If you've come this far, you might be curious to get a taste of building your first machine learning model. In the coming week we'll share an exclusive tutorial on machine learning in python. However, let's get a taste of it here.

We'll use the famous and formidable scikit learn library. Scikit learn accepts data in numeric format. Now, we'll have to convert the character variable into numeric. We'll use the labelencoder function.

In label encoding, each unique value of a variable gets assigned a number, i.e., let's say a variable color has four values ['red','green','blue','pink'].

Label encoding this variable will return output as: red = 2 green = 0 blue = 1 pink = 3

#load sklearn and encode all object type variables
from sklearn import preprocessing

for x in train.columns:
    if train[x].dtype == 'object':
        lbl = preprocessing.LabelEncoder()
        lbl.fit(list(train[x].values))
        train[x] = lbl.transform(list(train[x].values))
Let's check the changes applied to the data set.

train.head()
age	workclass	fnlwgt	education	education.num	marital.status	occupation	relationship	race	sex	capital.gain	capital.loss	hours.per.week	native.country	target
0	39	6	77516	9	13	4	0	1	4	1	2174	0	40	38	0
1	50	5	83311	9	13	2	3	0	4	1	0	0	13	38	0
2	38	3	215646	11	9	0	5	1	4	1	0	0	40	38	0
3	53	3	234721	1	7	2	5	0	2	1	0	0	40	38	0
4	28	3	338409	9	13	2	9	5	2	0	0	0	40	4	0
As we can see, all the variables have been converted to numeric, including the target variable.

#<50K = 0 and >50K = 1
train.target.value_counts()
0    24720
1     7841
Name: target, dtype: int64
Building a Random Forest Model

Let's create a random forest model and check the model's accuracy.

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.cross_validation import cross_val_score
from sklearn.metrics import accuracy_score

y = train['target']
del train['target']

X = train
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)

#train the RF classifier
clf = RandomForestClassifier(n_estimators = 500, max_depth = 6)
clf.fit(X_train,y_train)

    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                max_depth=6, max_features='auto', max_leaf_nodes=None,
                min_impurity_split=1e-07, min_samples_leaf=1,
                min_samples_split=2, min_weight_fraction_leaf=0.0,
                n_estimators=500, n_jobs=1, oob_score=False, random_state=None,
                verbose=0, warm_start=False)

clf.predict(X_test)
Now, let's make prediction on the test set and check the model's accuracy.

#make prediction and check model's accuracy
prediction = clf.predict(X_test)
acc =  accuracy_score(np.array(y_test),prediction)
print ('The accuracy of Random Forest is {}'.format(acc))
The accuracy of Random Forest is 0.85198075545.
Hurrah! Our learning algorithm gave 85% accuracy. Well, we can do tons of things on this data and improve the accuracy. We'll learn about it in future articles. What's next?

In this tutorial, we divided the train data into two halves and made prediction on the test data. As your exercise, you should use this model and make prediction on the test data we loaded initially. You can perform same set of steps we did on the train data to complete this exercise. In case you face any difficulty, feel free to share it in Comments below.

Summary

This tutorial is meant to help python developers or anyone who's starting with python to get a taste of data manipulation and a little bit of machine learning using python. I'm sure, by now you would be convinced that python is actually very powerful in handling and processing data sets. But, what we learned here is just the tip of the iceberg. Don't get complacent with this knowledge.

To dive deeper in pandas, check its documentation and start exploring. If you get stuck anywhere, you can drop your questions or suggestions in Comments below. Hope you found this tutorial useful.

--
From ml4t:

Pandas: This library was created by Wes McKinney at a hedge fund call AQR. It's used at many hedge funds and by many people in the finance industry. One of the key components of Pandas is something called the dataframe.

==
import pandas as pd
import numpy as np

==
Use pandas in my Thinkpad computer:

export PATH=~/anaconda2/bin:$PATH
source activate homework1
python file_name.py

==
(findreadcsv)
Read csv file to a dataframe:

df = pd.read_csv("data/AAPL.csv")

Practice shows it will read the data as appropriate data types automatically.

--
Only read in selected columns (col1, col2):

dfSPY = pd.read_csv("data.csv", usecols = ['col1', 'col2'])

--
Read the string 'nan' as not-a-number:

dfSPY = pd.read_csv("data.csv", na_values = ['nan'])

Let's understand that csv 'nan' as string, so we need to tell the read_csv that 'nan' should be interpreted as not a number. Tao: otherwise it will read 'nan' as a string, instead of not-a-number.

--
Make a column to be the index:

dfSPY = pd.read_csv("data.csv", index_col = "date", parse_dates = True)

We make the date column in the csv file as index. We do this by using the index_col parameter. We also want the dates present in the DataFrame to be converted into date time index objects. This can be done by setting the value for the parse_dates parameter to True.

==
(finddropnan)
Drop the rows with NaN:

df2 = df1.dropna()
df2 = df1.dropna(subset = ["col1"]) # Drop only the rows which have col1 equals NaN.

==
(finddataframe)
(findcreatedataframe)
# Create DataFrame:

# Tao: practice shows that d below is just a normal dictionary. The key is string type, and value is a list.

d = {'col1': [1, 2], 'col2': [3, 4]}

df = pd.DataFrame(data=d)

df

   col1  col2
0     1     3
1     2     4

You will also observe there is a column that is not named and has values 0, 1, 2, 3. And this is not from the .csv. These are called index for the data frame, which help you to access rows.

--
Add a new column from computation:

df['col_c'] = 2 * df['col_a'] + df['col_a'] * df['col_b']

==
(findhead)
(findtail)
head & tail

df.head() # Top 5 rows 
df.tail() # Last 5 rows 

df.head(5)
df.tail(3)

--
(findaddcolumn)
Add a column

In the same way as adding to dictionary:

# Tao: the new df contains all the old columns and the new column
df['new_column'] = 2 * df['col_a'] + df['col_b']

--
(findrank)
Rank

df:

           coverage	 name	reports	 year
Cochice	    25	     Jason	4	     2012
Pima	    94	     Molly	24	     2012
Santa Cruz	57	     Tina	31	     2013
Maricopa	62	     Jake	2	     2014
Yuma	    70	     Amy	3	     2014

# Create a new column that is the rank of the value of coverage in ascending order
# Tao: the new df contains all the old columns and the new column

df['coverageRanked'] = df['coverage'].rank(ascending = True)

df:

           coverage	 name	reports	 year  coverageRanked
Cochice	    25	     Jason	4	     2012  1
Pima	    94	     Molly	24	     2012  5
Santa Cruz	57	     Tina	31	     2013  2
Maricopa	62	     Jake	2	     2014  3
Yuma	    70	     Amy	3	     2014  4

--
(findcorrelation)
Correlation

df['A'].corr(df['B'])

--
(findiloc)
(findloc)
(findix)
iloc, loc, ix:

Abstract from https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/

There’s three main options to achieve the selection and indexing activities in Pandas, which can be confusing. The three selection cases and methods covered in this post are:

1. Selecting data by row numbers (.iloc)
2. Selecting data by label or by a conditional statment (.loc)
3. Selecting in a hybrid approach (.ix) (now Deprecated in Pandas 0.20.1). The ix[] indexer is a hybrid of .loc and .iloc.

.iloc selections: position based selection:

data.iloc[<row selection], <column selectoin>]
 
row selectoin and column selection: 
iteger list of rows:[0,1,2]  
integer list of columns: [0,1,2]
slice of rows: [4:7]
slice of columns:[4:7]
single values: 1
single column selections: 1

Examples of iloc:

# Single selections using iloc and DataFrame
# Rows:
data.iloc[0] # first row of data frame. Note a Series data type output.
data.iloc[1] # second row of data frame
data.iloc[-1] # last row of data frame
# Columns:
data.iloc[:,0] # first column of data frame 
data.iloc[:,1] # second column of data frame 
data.iloc[:,-1] # last column of data frame

# Multiple row and column selections using iloc and DataFrame
data.iloc[0:5] # first five rows of dataframe
data.iloc[:, 0:2] # first two columns of data frame with all rows
data.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns.
data.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of data frame (county -> phone1).

Note that .iloc returns a Pandas Series when one row is selected, and a Pandas DataFrame when multiple rows are selected, or if any column in full is selected. To counter this, pass a single-valued list if you require DataFrame output.

# Get value from one row:
# From online: If you have a DataFrame with only one row, then access the first (only) row as a Series using iloc, and then the value using the column name:

sub_df

          A         B
2 -0.133653 -0.030854

sub_df.iloc[0]

A   -0.133653
B   -0.030854

sub_df.iloc[0]['A']
-0.13365288513107493

--
loc selectoins: position based selection:

data.loc[<row selection], <column selection>]

row selectoin and column selection: 
index/label value: 'john'
named column: 'first_name'
list of labels: ['john', 'sarah']
list of column names: ['first_name', 'age']
logical/boolean index: data['age'] == 10
slice of columns: 'first_name': 'address'

Examples of loc:

# Select rows with index values 'Andrade' and 'Veness', with all columns between 'city' and 'email'
data.loc[['Andrade', 'Veness'], 'city':'email']

# Select same rows, with just 'first_name', 'address' and 'city' columns
data.loc['Andrade':'Veness', ['first_name', 'address', 'city']]
 
# Change the index to be based on the 'id' column
data.set_index('id', inplace=True)

# select the row with 'id' = 487
data.loc[487]

# Select rows with first name Antonio, # and all columns between 'city' and 'email'
data.loc[data['first_name'] == 'Antonio', 'city':'email']
 
# Select rows where the email column ends with 'hotmail.com', include all columns
data.loc[data['email'].str.endswith("hotmail.com")]   
 
# Select rows with last_name equal to some values, all columns
data.loc[data['first_name'].isin(['France', 'Tyisha', 'Eric'])]   
       
# Select rows with first name Antonio AND hotmail email addresses
data.loc[data['email'].str.endswith("gmail.com") & (data['first_name'] == 'Antonio')] 
 
# select rows with id column between 100 and 200, and just return 'postal' and 'web' columns
data.loc[(data['id'] > 100) & (data['id'] <= 200), ['postal', 'web']] 
 
# A lambda function that yields True/False values can also be used.
# Select rows where the company name has 4 words in it.
data.loc[data['company_name'].apply(lambda x: len(x.split(' ')) == 4)] 
 
# Selections can be achieved outside of the main .loc for clarity:
# Form a separate variable with your selections:
idx = data['company_name'].apply(lambda x: len(x.split(' ')) == 4)
# Select only the True values in 'idx' and only the 3 columns specified:
data.loc[idx, ['email', 'first_name', 'company']]

==
(findslice)
(findselect)
Slice dataframe
Select rows and columns

Select rows:

df[10:21] # Data from index 10 to 20, because 21 is not inclusive in the range. This operation is called slicing and it is a very important operation in Python pandas

df.ix[10:21] # Equivalent as df[10:21], just looks more Pythonic and robust.

Select colums:
df['col1'] <- the returned type is not dataframe!
df[['A', 'B', 'C']]: returns a dataframe with columns A, B, C

print df['col1']

--
Select rows and columns:
df[1:5, ['A', 'B']] # Selects rows 1 to 4, columns A and B.
df.ix[1:5, ['A', 'B']] # Equivalent as above

--
df[df.A > 0]

                   A         B         C         D
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-04  0.721555 -0.706771 -1.039575  0.271860

--
# select * from a_df
# where label = 100

a_df[a_df.label == 100]

==
(findmax)
(findstatistics)
Max
Statistics functions

df['col1'].max() 

df.mean() # Return the mean of each column
df.median()
df.std() # Standard deviation

df.kurtosis() 

Kurtosis:

If we’ve got a positive kurtosis, that means we’ve got fat tails, there are more occurrences outside in the tails than would normally happen
with a Gaussian distribution. If negative.... less...

Correlation:
df.corr(method = 'pearson') # df only has two columns, this returns the correlation of the two columns.

--
sqrt, square, power

import numpy as np
df_sqrt = np.sqrt(df['col_a'])
df_square = np.power(df['col_a'], 2)

--
(findlinearregression)
(findpolyfit)
Linear Regression
Polyfit

import pandas as pd
import numpy as np

beta, alpha = np.polyfit(df['col1'], df['col2'], 1) 

1 means polynomial degree is 1 (linear).
So the line is y = beta * x + alpha

--
(findsort)
Sort

df.sort_index(axis=1, ascending=False)

                   D         C         B         A
2013-01-01 -1.135632 -1.509059 -0.282863  0.469112
2013-01-02 -1.044236  0.119209 -0.173215  1.212112
2013-01-03  1.071804 -0.494929 -2.104569 -0.861849
2013-01-04  0.271860 -1.039575 -0.706771  0.721555
2013-01-05 -1.087401  0.276232  0.567020 -0.424972
2013-01-06  0.524988 -1.478427  0.113648 -0.673690

--
df.sort_values(by='B')

                   A         B         C         D
2013-01-03 -0.861849 -2.104569 -0.494929  1.071804
2013-01-04  0.721555 -0.706771 -1.039575  0.271860
2013-01-01  0.469112 -0.282863 -1.509059 -1.135632
2013-01-02  1.212112 -0.173215  0.119209 -1.044236
2013-01-06 -0.673690  0.113648 -1.478427  0.524988
2013-01-05 -0.424972  0.567020  0.276232 -1.087401


--
(findisnull)
(findmissingvalues)
isnull or missing values

df['A'].isnull().sum(): returns number of missing values in column A.

Fill the missing data:

df.fillna()

df.fillna(method = 'ffill') # Forwad fill, ie, fill in the last, previous known value. <- Think of stock curve (price vs time).

df.fillna(method = 'bfill') # Backward fill.

df.fillna(method="ffill", inplace=True)

--
(findlen)
(findsize)
Number of rows in dataframe df:

len(df)

--
(findgroupby)
group by

# Now a new df:

df

     A      B         C         D
0  foo    one -1.202872 -0.055224
1  bar    one -1.814470  2.395985
2  foo    two  1.018601  1.552825
3  bar  three -0.595447  0.166599
4  foo    two  1.395433  0.047609
5  bar    two -0.392670 -0.136473
6  foo    one  0.007207 -0.561757
7  foo  three  1.928123 -1.623033

--
df.groupby('A').sum()

            C        D
A                     
bar -2.802588  2.42611
foo  3.146492 -0.63958

--
df.groupby(['A','B']).sum()

                  C         D
A   B                        
bar one   -1.814470  2.395985
    three -0.595447  0.166599
    two   -0.392670 -0.136473
foo one   -1.195665 -0.616981
    three  1.928123 -1.623033
    two    2.414034  1.600434

--
# group by, count

df

  col1 col2  col3  col4  col5  col6
0    A    B  0.20 -0.61 -0.49  1.49
1    A    B -1.53 -1.01 -0.39  1.82
2    A    B -0.44  0.27  0.72  0.11
3    A    B  0.28 -1.32  0.38  0.18
4    C    D  0.12  0.59  0.81  0.66
5    C    D -0.13 -1.65 -1.64  0.50
6    C    D -1.42 -0.11 -0.18 -0.44
7    E    F -0.00  1.42 -0.26  1.17
8    E    F  0.91 -0.47  1.35 -0.34
9    G    H  1.48 -0.63 -1.14  0.17

df.groupby(['col1', 'col2']).size()

col1  col2
A     B       4
C     D       3
E     F       2
G     H       1

--
# Sort within each group:

Sort the PVE score within each job_id:

score_df['rank'] = score_df.groupby(['job_id'])['score'].rank(ascending = True)

==
(findplot)
Plot in Python, using matplotlib

Tao's standard way:

tao_df is a DataFrame.

tao_df:

col_a  col_b  col_c
 1     0.1    0.3
 2     0.2    0.2
 3     0.3    0.1

The following code will make two curves in the same plot.
The first curve uses the values of col_a as x-axis, the values of col_b as y-axis.
The second curve uses the values of col_a as x-axis, the values of col_c as y-axis.

import pandas as pd
import matplotlib.pyplot as plt

# Plot curves:
plt.plot(tao_df['col_a'], tao_df['col_b'], label = 'Values of b', color = 'blue') # label sets the legend text
plt.plot(tao_df['col_a'], tao_df['col_c'], label = 'Values of c', color = 'red') # label sets the legend text
plt.xlabel('Values of a')
plt.ylabel('Magnitudes')
plt.title('Tao plot')
plt.legend()
plt.show()

# Plot scatters:
dot_size = 3
plt.scatter(tao_df['col_a'], tao_df['col_b'], label = 'Values of b', color = 'blue', s = dot_size) # label sets the legend text
plt.plot(tao_df['col_a'], tao_df['col_c'], label = 'Values of c', color = 'red', s = dot_size) # label sets the legend text
plt.xlabel('Values of a')
plt.ylabel('Magnitudes')
plt.title('Tao plot')
plt.legend()
plt.show()

--
Make multiple plots side-by-side:

Should use Python 3:

# One row, two columns:
from matplotlib import pyplot as plt
fig, axes = plt.subplots(1, 2)

# Sets size of each subplot. If axis text is hidden, the increase the height.
fig.set_figheight(15)
fig.set_figwidth(15)

axes[0].plot(data['row_num'], data['score_pve'], label = 'score_pve', color = 'blue')
axes[1].plot(data['row_num'], data['score_pve'], label = 'score_pve', color = 'blue')

# Two rows, two columns:
fig, axes = plt.subplots(2, 2)
axes[0, 0].plot(data['row_num'], data['score_pve_scaled'], label = 'score_pve', color = 'blue')
axes[0, 0].set_xlabel('user_id')
axes[0, 0].set_ylabel('score')
axes[0, 0].set_title('Hello')
axes[0, 0].text(1000, 0.5, "Helo", dict(size=10, color='black')) # Add text in each subplot
axes[0, 1].plot(data['row_num'], data['score_pve_scaled'], label = 'score_pve', color = 'blue')
axes[1, 0].plot(data['row_num'], data['score_pve_scaled'], label = 'score_pve', color = 'blue')
axes[1, 1].plot(data['row_num'], data['score_pve_scaled'], label = 'score_pve', color = 'blue')

--
Using dataframe.plot():

import pandas as pd
import matplotlib.pyplot as plot

# Make the plot and show it in a window:
df['col1'].plot()
plot.show() # Must be called to show plots

# Make the plot and save it to file:
df['col1'].plot()
plot.savefig('fig_1.png')

# Set the y axis range:
df1 = pd.DataFrame(data = dic1)
df1.plot()
plot.ylim(-256, 100)

# Scatter plot:
df.plot(kind = 'scatter', x = 'compay_1', y = 'compay_2')
plot.show()

# Plot histogram, set number of bins to 20:
df.hist(bins = 20)
plot.show()

# Add verticle line at the position x coordinate = 5, with white color:
plot.axvline(5, color = 'w', linestyle = 'dashed', linewidth = 2)
plot.show()

Add title and labels:

ax = df.plot(title = 'prices', fontsize = 2)
ax.set_xlabel("date")
ax.set_ylabel("price")
plot.show()

==
(finddates)
Dates in pandas

import pandas as pd

def test_run():
	start_date = '2010-01-22'
	end_date = '2010-01-26'
	dates = pd.date_range(start_date, end_date)
	print dates[0] # Output: 2010-01-22 00:00:00
	df1 = pd.DataFrame(index = dates)

We used pandas date range method which takes two parameters, that is start and end date. The output you see is not the list of strings, but the list of date time index objects. 

The output above: 2010-01-22 00:00:00:
This is the first element of the list which a date/time index object. The trailing zero zeros for each object is the default time stamp.

Next we define an empty dataframe df1 with these dates as index. We use the parameter index to supply the dates. Note that without this parameter the dataframe will have an index of integers 0,1,2 as seen before. So here's your DataFrame, DF1. It's an empty DataFrame with no columns. However, as we pass the index parameter, we have an index as dates. And you can see that it's a date time index object.

==
(findjoin)
Join

df_join = df1.join(df2) <- Left join, avadoles!
df_join = df1.join(df2, how = 'inner') <- Inner join

Avadoles! Different from Hive, Spark, SQL:
DataFrame.join does a left join by default. So if we write a.join b, it will read in all the rows from a, but only those rows from b whose index values are present in a's index.

--
(findmerge)
(findconcat)

Join, merge, concat:

From online:

Use merge, which is inner join by default:

pd.merge(df1, df2, left_index=True, right_index=True)
Or join, which is left join by default:

df1.join(df2)
Or concat, which is outer join by default:

pd.concat([df1, df2], axis=1)
Samples:

df1 = pd.DataFrame({'a':range(6),
                    'b':[5,3,6,9,2,4]}, index=list('abcdef'))

print (df1)
   a  b
a  0  5
b  1  3
c  2  6
d  3  9
e  4  2
f  5  4

df2 = pd.DataFrame({'c':range(4),
                    'd':[10,20,30, 40]}, index=list('abhi'))

print (df2)
   c   d
a  0  10
b  1  20
h  2  30
i  3  40

#default inner join
df3 = pd.merge(df1, df2, left_index=True, right_index=True)

print (df3)
   a  b  c   d
a  0  5  0  10
b  1  3  1  20

#default left join
df4 = df1.join(df2)

print (df4)
   a  b    c     d
a  0  5  0.0  10.0
b  1  3  1.0  20.0
c  2  6  NaN   NaN
d  3  9  NaN   NaN
e  4  2  NaN   NaN
f  5  4  NaN   NaN

#default outer join
df5 = pd.concat([df1, df2], axis=1)

print (df5)
     a    b    c     d
a  0.0  5.0  0.0  10.0
b  1.0  3.0  1.0  20.0
c  2.0  6.0  NaN   NaN
d  3.0  9.0  NaN   NaN
e  4.0  2.0  NaN   NaN
f  5.0  4.0  NaN   NaN
h  NaN  NaN  2.0  30.0
i  NaN  NaN  3.0  40.0

==
(findrenamecolumn)
Rename colum

df_new = df.rename(columns = {'old_name' : 'new_name'})

==
(findnormalize)
Normalize

df1 = df1 / df1[0] # Divide the entire dataframe by its first row. It is equivalent as below, but it is more elegant and much FASTER.

df1 = df1 / df1.ix[0,:] # Should be the same as above.

Does the same thing as above:

for date in df1.index:
    for s in symbols:
        df1[date, s] = df1[date, s] / df1[0, s]

==
(findsumcolumns)
(findmeancolumns)
Sum (or mean) of all columns into a new column

df2 = pd.DataFrame(data = dic2)
df2['sum'] = df2.iloc[:,-num_columns:].sum(axis=1) # Sum all columns
df2['mean'] = df2['sum'] / num_columns
df2['std'] = df2.iloc[:,-num_columns:].std(axis=1)

print df2.head(5)

   run_0  run_1  run_2  sum      mean       std
0      0      0      0    0  0.000000  0.000000
1      1      1     -1    1  0.333333  1.018350
2      2      0      1    3  1.000000  1.154701
3      1      2      2    5  1.666667  1.835857
4     -1      3      1    3  1.000000  1.154701



